import logging
import os
import re
import random
import urllib.parse
import requests
import string
import asyncio  
from docx.oxml import parse_xml
from docx.oxml.ns import nsdecls
from datetime import datetime
from typing import Optional, Dict, Any
from io import BytesIO
import requests
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup, InputFile
from telegram.ext import (
    Application, CommandHandler, CallbackQueryHandler,
    MessageHandler, filters, ContextTypes, ConversationHandler
)
from docx import Document
from docx.shared import Pt, Cm, Inches
from docx.enum.text import WD_ALIGN_PARAGRAPH
from docx.enum.style import WD_STYLE_TYPE
from pptx import Presentation
from pptx.util import Inches as PptxInches, Pt as PptxPt
from pptx.dml.color import RGBColor
from io import BytesIO
from duckduckgo_search import DDGS
from pptx.enum.text import PP_ALIGN
import openpyxl
from openpyxl.styles import Font, Alignment, Border, Side, PatternFill

USED_IMAGE_URLS = set()

logging.basicConfig(format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', level=logging.INFO)
logger = logging.getLogger(__name__)

BOT_TOKEN = "8536135266:AAGz9vM4M6-LiJJdxXJDduUGXZOh6O2w0N4"
ADMIN_ID = 6581335835
GEMINI_API_KEY = "AIzaSyDobeNv2ai8c0v2n32gwi4bj1FCbMZhrI4"
GROQ_API_KEY = "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"
PIXABAY_API_KEY = "54003630-714e9f86777060ab07858940b"

# BAÅDA goÅŸuÅˆ:
logger.info(f"ğŸ”‘ Gemini API Key: {GEMINI_API_KEY[:10]}...{GEMINI_API_KEY[-5:]}")
logger.info(f"ğŸ”‘ Groq API Key: {GROQ_API_KEY[:10]}...{GROQ_API_KEY[-5:]}")

HOLIDAY_PROMOS = {
    "NEWYEAR25": {"date": "01-01", "discount": 30, "name": "ĞĞ¾Ğ²Ñ‹Ğ¹ Ğ“Ğ¾Ğ´"},
    "WOMEN8": {"date": "03-08", "discount": 20, "name": "8 ĞœĞ°Ñ€Ñ‚Ğ°"},
    "NOWRUZ": {"date": "03-21", "discount": 25, "name": "ĞĞ¾Ğ²Ñ€ÑƒĞ· Ğ‘Ğ°Ğ¹Ñ€Ğ°Ğ¼"},
    "NEUTRALITY": {"date": "12-12", "discount": 20, "name": "Ğ”ĞµĞ½ÑŒ ĞĞµĞ¹Ñ‚Ñ€Ğ°Ğ»Ğ¸Ñ‚ĞµÑ‚Ğ°"},
    "STUDENT_DAY": {"date": "11-17", "discount": 15, "name": "Ğ”ĞµĞ½ÑŒ Ğ¡Ñ‚ÑƒĞ´ĞµĞ½Ñ‚Ğ°"},
    "JAN2TEST": {"date": "01-02", "discount": 50, "name": "Ğ¢ĞµÑÑ‚Ğ¾Ğ²Ñ‹Ğ¹ Ğ”ĞµĞ½ÑŒ"}
}

PAYMENTS = {
    "BY": {"card": "1234 5678 9012 3456", "name": "IVANOV IVAN", "bank": "Ğ‘ĞµĞ»Ğ°Ñ€ÑƒÑĞ±Ğ°Ğ½Ğº", "currency": "BYN"},
    "RU": {"card": "9876 5432 1098 7654", "name": "Ğ˜Ğ’ĞĞĞĞ’ Ğ˜Ğ’ĞĞ", "bank": "Ğ¡Ğ±ĞµÑ€Ğ±Ğ°Ğ½Ğº", "currency": "RUB"}
}

PRICES = {
    "BY": {
        "referat": {"min": 5, "max": 25, "price_per_page": 0.85},
        "doklad": {"min": 1, "max": 4, "price_per_page": 0.85},
        "esse": {"min": 1, "max": 6, "price_per_page": 0.85},
        "kursovaya": {"min": 25, "max": 50, "price_per_page": 0.95},
        "presentation": {"min": 5, "max": 20, "price_per_page": 0.85}
        # âŒ "table" AÃRYLDY!
    },
    "RU": {
        "referat": {"min": 5, "max": 25, "price_per_page": 18},
        "doklad": {"min": 1, "max": 4, "price_per_page": 18},
        "esse": {"min": 1, "max": 6, "price_per_page": 18},
        "kursovaya": {"min": 25, "max": 50, "price_per_page": 25},
        "presentation": {"min": 5, "max": 20, "price_per_page": 23}
        # âŒ "table" AÃRYLDY!
    }
}

WORK_TYPES = {
    "referat": {"ru": "Ğ ĞµÑ„ĞµÑ€Ğ°Ñ‚", "en": "Abstract/Report"},
    "doklad": {"ru": "Ğ”Ğ¾ĞºĞ»Ğ°Ğ´", "en": "Report/Presentation"},
    "esse": {"ru": "Ğ­ÑÑĞµ", "en": "Essay"},
    "kursovaya": {"ru": "ĞšÑƒÑ€ÑĞ¾Ğ²Ğ°Ñ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°", "en": "Term Paper"},
    "presentation": {"ru": "ĞŸÑ€ĞµĞ·ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ñ", "en": "Presentation"},
    "table": {"ru": "Ğ¢Ğ°Ğ±Ğ»Ğ¸Ñ†Ğ°", "en": "Table Work"}
}

PROMO_CODES = {"WELCOME": 20, "FRIEND": 20, "VIP2025": 8}

(SELECT_COUNTRY, SELECT_LANG, SELECT_WORK_TYPE, SELECT_PAGES, 
 ENTER_TOPIC, ENTER_UNIVERSITY, ENTER_FACULTY, ENTER_SUBJECT,
 ENTER_FULLNAME, ENTER_COURSE, ENTER_GROUP, ENTER_TEACHER,
 ENTER_CITY, ENTER_PHONE, UPLOAD_ZADANIE, PAYMENT_PHOTO) = range(16)

users_db: Dict[int, dict] = {}
orders_db: Dict[str, dict] = {}
pending_payments: Dict[str, dict] = {}

TEXTS = {
    "ru": {
        "welcome": """ğŸ“ *ĞĞšĞĞ”Ğ•ĞœĞ˜Ğ§Ğ•Ğ¡ĞšĞ˜Ğ™ ĞŸĞĞœĞĞ©ĞĞ˜Ğš*

Ğ”Ğ¾Ğ±Ñ€Ğ¾ Ğ¿Ğ¾Ğ¶Ğ°Ğ»Ğ¾Ğ²Ğ°Ñ‚ÑŒ! ğŸ‘‹
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ”¥ *ĞĞšĞ¦Ğ˜Ğ˜:*
ğŸ ĞšĞ°Ğ¶Ğ´Ñ‹Ğ¹ 8-Ğ¹ Ğ·Ğ°ĞºĞ°Ğ· Ğ‘Ğ•Ğ¡ĞŸĞ›ĞĞ¢ĞĞ!
â˜€ï¸ Ğ£Ñ‚Ñ€ĞµĞ½Ğ½ÑÑ ÑĞºĞ¸Ğ´ĞºĞ° (06:00-07:00): -10%
ğŸ‘¥ ĞŸÑ€Ğ¸Ğ²ĞµĞ´Ğ¸ Ğ´Ñ€ÑƒĞ³Ğ°: -30% ĞĞ‘ĞĞ˜Ğœ!
ğŸ‰ Ğ’Ñ‹Ñ…Ğ¾Ğ´Ğ½Ñ‹Ğµ: -10%
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
âœ… Ğ“Ğ°Ñ€Ğ°Ğ½Ñ‚Ğ¸Ñ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ°
âœ… Ğ‘Ñ‹ÑÑ‚Ñ€Ğ°Ñ Ğ´Ğ¾ÑÑ‚Ğ°Ğ²ĞºĞ°""",
        "select_country": "ğŸŒ *Ğ’Ñ‹Ğ±ĞµÑ€Ğ¸Ñ‚Ğµ Ğ²Ğ°ÑˆÑƒ ÑÑ‚Ñ€Ğ°Ğ½Ñƒ:*",
        "select_work_type": "ğŸ“ *Ğ’Ñ‹Ğ±ĞµÑ€Ğ¸Ñ‚Ğµ Ñ‚Ğ¸Ğ¿ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹:*",
        "select_pages": "ğŸ“„ *Ğ’Ñ‹Ğ±ĞµÑ€Ğ¸Ñ‚Ğµ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†:*",
        "enter_topic": "ğŸ“ *Ğ’Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ Ñ‚ĞµĞ¼Ñƒ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹:*",
        "enter_university": "ğŸ› *Ğ’Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğµ ÑƒĞ½Ğ¸Ğ²ĞµÑ€ÑĞ¸Ñ‚ĞµÑ‚Ğ°:*",
        "enter_faculty": "ğŸ“š *Ğ’Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ„Ğ°ĞºÑƒĞ»ÑŒÑ‚ĞµÑ‚Ğ°:*",
        "enter_subject": "ğŸ“– *Ğ’Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ñ€ĞµĞ´Ğ¼ĞµÑ‚Ğ°:*",
        "enter_fullname": "ğŸ‘¤ *Ğ’Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ Ğ²Ğ°ÑˆĞµ Ğ¤Ğ˜Ğ:*",
        "enter_course": "ğŸ“ *Ğ’Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ ĞºÑƒÑ€Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ:*",
        "enter_group": "ğŸ‘¥ *Ğ’Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ Ğ½Ğ¾Ğ¼ĞµÑ€ Ğ³Ñ€ÑƒĞ¿Ğ¿Ñ‹:*",
        "enter_teacher": "ğŸ‘¨â€ğŸ« *Ğ’Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ Ğ¤Ğ˜Ğ Ğ¿Ñ€ĞµĞ¿Ğ¾Ğ´Ğ°Ğ²Ğ°Ñ‚ĞµĞ»Ñ:*",
        "enter_city": "ğŸ™ *Ğ’Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ Ğ³Ğ¾Ñ€Ğ¾Ğ´:*",
        "enter_phone": "ğŸ“± *Ğ’Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ Ğ½Ğ¾Ğ¼ĞµÑ€ Ñ‚ĞµĞ»ĞµÑ„Ğ¾Ğ½Ğ°:*",
        "new_order": "ğŸ“ ĞĞ¾Ğ²Ñ‹Ğ¹ Ğ·Ğ°ĞºĞ°Ğ·",
        "promotions": "ğŸ ĞĞºÑ†Ğ¸Ğ¸",
        "promo_code": "ğŸ·ï¸ ĞŸÑ€Ğ¾Ğ¼Ğ¾ĞºĞ¾Ğ´",
        "my_account": "ğŸ“Š ĞœĞ¾Ğ¹ Ğ°ĞºĞºĞ°ÑƒĞ½Ñ‚",
        "referral": "ğŸ‘¥ Ğ ĞµÑ„ĞµÑ€Ğ°Ğ»",
        "help": "â“ ĞŸĞ¾Ğ¼Ğ¾Ñ‰ÑŒ",
        "back": "ğŸ”™ ĞĞ°Ğ·Ğ°Ğ´",
        "cancel": "âŒ ĞÑ‚Ğ¼ĞµĞ½Ğ°"
    },
    "en": {
        "welcome": """ğŸ“ *ACADEMIC ASSISTANT*

Welcome! ğŸ‘‹
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ”¥ *PROMOTIONS:*
ğŸ Every 8th order FREE!
â˜€ï¸ Morning (06:00-07:00): -10%
ğŸ‘¥ Refer friend: -30% FOR BOTH!
ğŸ‰ Weekend: -10%
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
âœ… Quality guaranteed
âœ… Fast delivery""",
        "select_country": "ğŸŒ *Select your country:*",
        "select_work_type": "ğŸ“ *Select work type:*",
        "select_pages": "ğŸ“„ *Select pages:*",
        "enter_topic": "ğŸ“ *Enter topic:*",
        "enter_university": "ğŸ› *Enter university:*",
        "enter_faculty": "ğŸ“š *Enter faculty:*",
        "enter_subject": "ğŸ“– *Enter subject:*",
        "enter_fullname": "ğŸ‘¤ *Enter full name:*",
        "enter_course": "ğŸ“ *Enter course:*",
        "enter_group": "ğŸ‘¥ *Enter group:*",
        "enter_teacher": "ğŸ‘¨â€ğŸ« *Enter teacher:*",
        "enter_city": "ğŸ™ *Enter city:*",
        "enter_phone": "ğŸ“± *Enter phone:*",
        "new_order": "ğŸ“ New Order",
        "promotions": "ğŸ Promotions",
        "promo_code": "ğŸ·ï¸ Promo",
        "my_account": "ğŸ“Š Account",
        "referral": "ğŸ‘¥ Referral",
        "help": "â“ Help",
        "back": "ğŸ”™ Back",
        "cancel": "âŒ Cancel"
    }
}

import random

def generate_ai_image_url(prompt: str) -> str:
    """
    âœ… Pollinations AI arkaly tÃ¤ze we Ã¼Ã½tgeÅŸik surat dÃ¶retmek.
    Mugt we hiÃ§ hili aÃ§ar (key) soraÃ½an dÃ¤l.
    """
    try:
        # SuratyÅˆ 100% Ã¼Ã½tgeÅŸik bolmagy Ã¼Ã§in tÃ¶tÃ¤nleÃ½in san (seed)
        random_seed = random.randint(1, 999999)
        
        # GÃ¶zleg sÃ¶zlerini arassalamak we iÅˆlis diline terjime etmek (AI iÅˆlisÃ§e gowy dÃ¼ÅŸÃ¼nÃ½Ã¤r)
        # Eger kodyÅˆyza terjimeÃ§i goÅŸmadyk bolsaÅˆyz, iÅˆ bolmanda sÃ¶zleri arassalaÅˆ
        clean_prompt = prompt.replace(" ", "%20")
        
        # Pollinations AI URL formaty
        # width=1024, height=768 (PrezentasiÃ½a Ã¼Ã§in laÃ½yk Ã¶lÃ§eg)
        image_url = f"https://pollinations.ai/p/{clean_prompt}?width=1024&height=768&seed={random_seed}&nologo=true"
        
        logger.info(f"ğŸ¨ AI Image Generated: {image_url}")
        return image_url
    except Exception as e:
        logger.error(f"âŒ AI Image Generation failed: {e}")
        return "https://images.pexels.com/photos/3183150/pexels-photo-3183150.jpeg" # Fallback

def generate_order_id() -> str:
    return "ORD" + ''.join(random.choices(string.ascii_uppercase + string.digits, k=8))

def get_user(user_id: int) -> dict:
    if user_id not in users_db:
        users_db[user_id] = {
            "orders_count": 0, "total_spent": 0, "bonus": 0,
            "used_promos": [], "referrals": [], "language": "ru",
            "country": None, "created": datetime.now().isoformat()
        }
    return users_db[user_id]

def get_text(user_id: int, key: str) -> str:
    user = get_user(user_id)
    return TEXTS.get(user.get("language", "ru"), TEXTS["ru"]).get(key, key)

def calculate_price(country: str, work_type: str, pages: int) -> float:
    price_info = PRICES[country][work_type]
    return pages * price_info.get("price_per_item" if work_type == "table" else "price_per_page")

def calculate_final_price(user_id: int, base_price: float, promo: str = None) -> tuple:
    user = get_user(user_id)
    discounts = []
    total_discount = 0
    
    if (user["orders_count"] + 1) % 8 == 0 and user["orders_count"] > 0:
        return 0, [("ğŸ 8-Ğ¹ Ğ·Ğ°ĞºĞ°Ğ· Ğ‘Ğ•Ğ¡ĞŸĞ›ĞĞ¢ĞĞ!", 100)]
    
    if user.get("referral_discount") == 30:
        discounts.append(("ğŸ‘¥ Ğ ĞµÑ„ĞµÑ€Ğ°Ğ»", 30))
        total_discount += 30
        user["referral_discount"] = 0
    
    if 6 <= datetime.now().hour < 7:
        discounts.append(("â˜€ï¸ Ğ£Ñ‚Ñ€Ğ¾ (06:00-07:00)", 10))
        total_discount += 10
    
    if datetime.now().weekday() >= 5:
        discounts.append(("ğŸ‰ Ğ’Ñ‹Ñ…Ğ¾Ğ´Ğ½Ñ‹Ğµ", 10))
        total_discount += 10
    
    if promo and promo.upper() in PROMO_CODES:
        if promo.upper() not in user["used_promos"]:
            disc = PROMO_CODES[promo.upper()]
            discounts.append((f"ğŸ·ï¸ {promo.upper()}", disc))
            total_discount += disc
    
    total_discount = min(total_discount, 50)
    final = base_price * (100 - total_discount) / 100
    return round(final, 2), discounts

def get_currency_symbol(country: str) -> str:
    return "BYN" if country == "BY" else "â‚½"

# ============== BOT HANDLERS ==============

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user = update.effective_user
    logger.info(f"ğŸ‘¤ User started: ID={user.id}, Name={user.full_name}")
    user_data = get_user(user.id)
    
    if context.args and len(context.args) > 0 and context.args[0].isdigit():
        ref_id = int(context.args[0])
        if ref_id != user.id and ref_id in users_db:
            ref_user = get_user(ref_id)
            if user.id not in ref_user["referrals"]:
                ref_user["referrals"].append(user.id)
                user_data["referral_discount"] = 30
                
                try:
                    await context.bot.send_message(user.id, "ğŸ‰ Ğ’Ñ‹ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ğ»Ğ¸ 30% ÑĞºĞ¸Ğ´ĞºÑƒ Ğ¾Ñ‚ Ñ€ĞµÑ„ĞµÑ€Ğ°Ğ»Ğ°!")
                    await context.bot.send_message(ref_id, f"ğŸ‘¥ Ğ’Ğ°Ñˆ Ğ´Ñ€ÑƒĞ³ {user.full_name} Ğ¿Ñ€Ğ¸ÑĞ¾ĞµĞ´Ğ¸Ğ½Ğ¸Ğ»ÑÑ! ĞĞ±Ğ° Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ğ»Ğ¸ 30%!")
                except:
                    pass
    
    text = "ğŸŒ *Ğ’Ñ‹Ğ±ĞµÑ€Ğ¸Ñ‚Ğµ ÑĞ·Ñ‹Ğº / Select language:*"
    keyboard = [[InlineKeyboardButton("ğŸ‡·ğŸ‡º Ğ ÑƒÑÑĞºĞ¸Ğ¹", callback_data="lang_ru"), InlineKeyboardButton("ğŸ‡¬ğŸ‡§ English", callback_data="lang_en")]]
    
    if update.message:
        await update.message.reply_text(text, reply_markup=InlineKeyboardMarkup(keyboard), parse_mode='Markdown')
    elif update.callback_query:
        await update.callback_query.edit_message_text(text, reply_markup=InlineKeyboardMarkup(keyboard), parse_mode='Markdown')

async def select_language(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    await query.answer()
    
    lang = query.data.split("_")[1]
    user = get_user(query.from_user.id)
    user["language"] = lang
    
    if user.get("referral_discount") == 30:
        bonus_msg = "ğŸ‰ Ğ£ Ğ²Ğ°Ñ 30% ÑĞºĞ¸Ğ´ĞºĞ°!" if lang == "ru" else "ğŸ‰ You have 30% discount!"
        try:
            await query.message.reply_text(bonus_msg)
        except:
            pass
    
    await show_main_menu(update, context)

async def show_main_menu(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    user_id = query.from_user.id
    user = get_user(user_id)
    lang = user.get("language", "ru")
    
    text = TEXTS[lang]["welcome"]
    keyboard = [
        [InlineKeyboardButton(TEXTS[lang]["new_order"], callback_data="new_order")],
        [InlineKeyboardButton(TEXTS[lang]["promotions"], callback_data="promotions"), InlineKeyboardButton(TEXTS[lang]["promo_code"], callback_data="enter_promo")],
        [InlineKeyboardButton(TEXTS[lang]["my_account"], callback_data="account"), InlineKeyboardButton(TEXTS[lang]["referral"], callback_data="referral")],
        [InlineKeyboardButton(TEXTS[lang]["help"], callback_data="help")],
        [InlineKeyboardButton("ğŸŒ Language", callback_data="change_lang")]
    ]
    
    if user_id == ADMIN_ID:
        keyboard.append([InlineKeyboardButton("ğŸ” ADMIN", callback_data="admin")])
    
    await query.edit_message_text(text, reply_markup=InlineKeyboardMarkup(keyboard), parse_mode='Markdown')

async def new_order(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    await query.answer()
    
    user_id = query.from_user.id
    lang = get_user(user_id).get("language", "ru")
    text = TEXTS[lang]["select_country"]
    
    keyboard = [
        [InlineKeyboardButton("ğŸ‡§ğŸ‡¾ Ğ‘ĞµĞ»Ğ°Ñ€ÑƒÑÑŒ", callback_data="country_BY"), InlineKeyboardButton("ğŸ‡·ğŸ‡º Ğ Ğ¾ÑÑĞ¸Ñ", callback_data="country_RU")],
        [InlineKeyboardButton(TEXTS[lang]["back"], callback_data="main_menu")]
    ]
    
    await query.edit_message_text(text, reply_markup=InlineKeyboardMarkup(keyboard), parse_mode='Markdown')
    return SELECT_COUNTRY

async def select_country(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    await query.answer()
    
    country = query.data.split("_")[1]
    context.user_data["country"] = country
    
    user_id = query.from_user.id
    user = get_user(user_id)
    user["country"] = country
    lang = user.get("language", "ru")
    
    currency = get_currency_symbol(country)
    prices = PRICES[country]
    
    text = f"""ğŸ“ *{TEXTS[lang]["select_work_type"]}*

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ’° *Ğ¦ĞµĞ½Ñ‹ ({currency}):*

ğŸ“„ Ğ ĞµÑ„ĞµÑ€Ğ°Ñ‚ â€” {prices['referat']['price_per_page']} {currency}/ÑÑ‚Ñ€.
ğŸ“‹ Ğ”Ğ¾ĞºĞ»Ğ°Ğ´ â€” {prices['doklad']['price_per_page']} {currency}/ÑÑ‚Ñ€.
âœï¸ Ğ­ÑÑĞµ â€” {prices['esse']['price_per_page']} {currency}/ÑÑ‚Ñ€.
ğŸ“š ĞšÑƒÑ€ÑĞ¾Ğ²Ğ°Ñ â€” {prices['kursovaya']['price_per_page']} {currency}/ÑÑ‚Ñ€.
ğŸ¬ ĞŸÑ€ĞµĞ·ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ñ â€” {prices['presentation']['price_per_page']} {currency}/ÑĞ».
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"""
    
    keyboard = [
        [InlineKeyboardButton("ğŸ“„ " + WORK_TYPES["referat"]["ru"], callback_data="work_referat"), 
         InlineKeyboardButton("ğŸ“‹ " + WORK_TYPES["doklad"]["ru"], callback_data="work_doklad")],
        [InlineKeyboardButton("âœï¸ " + WORK_TYPES["esse"]["ru"], callback_data="work_esse"), 
         InlineKeyboardButton("ğŸ“š " + WORK_TYPES["kursovaya"]["ru"], callback_data="work_kursovaya")],
        [InlineKeyboardButton("ğŸ¬ " + WORK_TYPES["presentation"]["ru"], callback_data="work_presentation")],
        # âŒ TABLE BUTTON AÃRYLDY!
        [InlineKeyboardButton(TEXTS[lang]["back"], callback_data="new_order")]
    ]
    
    await query.edit_message_text(text, reply_markup=InlineKeyboardMarkup(keyboard), parse_mode='Markdown')
    return SELECT_WORK_TYPE

async def select_work_type(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    await query.answer()
    
    # âœ… PARSE WORK TYPE
    work_type = query.data.split("_")[1]
    context.user_data["work_type"] = work_type  # âœ… SAKLA!
    
    user_id = query.from_user.id
    lang = get_user(user_id).get("language", "ru")
    country = context.user_data["country"]
    
    price_info = PRICES[country][work_type]
    min_pages = price_info["min"]
    max_pages = price_info["max"]
    currency = get_currency_symbol(country)
    
    price_key = "price_per_item" if work_type == "table" else "price_per_page"
    unit = "ÑˆÑ‚." if work_type == "table" else "ÑÑ‚Ñ€."
    price_per = price_info[price_key]
    
    text = f"ğŸ“„ *{TEXTS[lang]['select_pages']}*\n\nğŸ’° Ğ¦ĞµĞ½Ğ°: {price_per} {currency}/{unit}\nğŸ“ Ğ”Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½: {min_pages}-{max_pages} {unit}"
    
    keyboard = []
    row = []
    
    if work_type == "esse":
        # ESSE: 1-6
        for i in range(1, 7):
            price = i * price_per
            row.append(InlineKeyboardButton(f"{i} ({price} {currency})", callback_data=f"pages_{i}"))
            if len(row) == 3:
                keyboard.append(row)
                row = []
        if row:
            keyboard.append(row)
    
    elif work_type in ["doklad"]:
        # DOKLAD: 1-10
        for i in range(1, 11):
            price = i * price_per
            row.append(InlineKeyboardButton(f"{i} ({price} {currency})", callback_data=f"pages_{i}"))
            if len(row) == 3:
                keyboard.append(row)
                row = []
        if row:
            keyboard.append(row)
    
    else:
        # REFERAT, KURSOVAYA, PRESENTATION: step by 5
        step = 5
        for i in range(min_pages, max_pages + 1, step):
            price = i * price_per
            row.append(InlineKeyboardButton(f"{i} ({price} {currency})", callback_data=f"pages_{i}"))
            if len(row) == 3:
                keyboard.append(row)
                row = []
        if row:
            keyboard.append(row)
    
    keyboard.append([InlineKeyboardButton(TEXTS[lang]["back"], callback_data=f"country_{country}")])
    
    await query.edit_message_text(text, reply_markup=InlineKeyboardMarkup(keyboard), parse_mode='Markdown')
    return SELECT_PAGES

async def select_pages(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """âœ… Handle page selection"""
    query = update.callback_query
    await query.answer()
    
    pages = int(query.data.split("_")[1])
    context.user_data["pages"] = pages
    
    user_id = query.from_user.id
    lang = get_user(user_id).get("language", "ru")
    country = context.user_data["country"]
    work_type = context.user_data["work_type"]
    
    base_price = calculate_price(country, work_type, pages)
    context.user_data["base_price"] = base_price
    
    # âŒ TABLE SPECIAL CASE AÃRYLDY!
    # GÃ¶ni TOPIC soraÃ½ar
    
    text = TEXTS[lang]["enter_topic"]
    await query.edit_message_text(text, parse_mode='Markdown')
    return ENTER_TOPIC

async def receive_topic(update: Update, context: ContextTypes.DEFAULT_TYPE):
    context.user_data["topic"] = update.message.text.strip()
    user_id = update.effective_user.id
    lang = get_user(user_id).get("language", "ru")
    await update.message.reply_text(TEXTS[lang]["enter_university"], parse_mode='Markdown')
    return ENTER_UNIVERSITY

async def receive_university(update: Update, context: ContextTypes.DEFAULT_TYPE):
    context.user_data["university"] = update.message.text.strip()
    user_id = update.effective_user.id
    lang = get_user(user_id).get("language", "ru")
    await update.message.reply_text(TEXTS[lang]["enter_faculty"], parse_mode='Markdown')
    return ENTER_FACULTY

async def receive_faculty(update: Update, context: ContextTypes.DEFAULT_TYPE):
    context.user_data["faculty"] = update.message.text.strip()
    user_id = update.effective_user.id
    lang = get_user(user_id).get("language", "ru")
    await update.message.reply_text(TEXTS[lang]["enter_subject"], parse_mode='Markdown')
    return ENTER_SUBJECT

async def receive_subject(update: Update, context: ContextTypes.DEFAULT_TYPE):
    context.user_data["subject"] = update.message.text.strip()
    user_id = update.effective_user.id
    lang = get_user(user_id).get("language", "ru")
    await update.message.reply_text(TEXTS[lang]["enter_fullname"], parse_mode='Markdown')
    return ENTER_FULLNAME

async def receive_fullname(update: Update, context: ContextTypes.DEFAULT_TYPE):
    context.user_data["fullname"] = update.message.text.strip()
    user_id = update.effective_user.id
    lang = get_user(user_id).get("language", "ru")
    await update.message.reply_text(TEXTS[lang]["enter_course"], parse_mode='Markdown')
    return ENTER_COURSE

async def receive_course(update: Update, context: ContextTypes.DEFAULT_TYPE):
    context.user_data["course"] = update.message.text.strip()
    user_id = update.effective_user.id
    lang = get_user(user_id).get("language", "ru")
    await update.message.reply_text(TEXTS[lang]["enter_group"], parse_mode='Markdown')
    return ENTER_GROUP

async def receive_group(update: Update, context: ContextTypes.DEFAULT_TYPE):
    context.user_data["group"] = update.message.text.strip()
    user_id = update.effective_user.id
    lang = get_user(user_id).get("language", "ru")
    await update.message.reply_text(TEXTS[lang]["enter_teacher"], parse_mode='Markdown')
    return ENTER_TEACHER

async def receive_teacher(update: Update, context: ContextTypes.DEFAULT_TYPE):
    context.user_data["teacher"] = update.message.text.strip()
    user_id = update.effective_user.id
    lang = get_user(user_id).get("language", "ru")
    await update.message.reply_text(TEXTS[lang]["enter_city"], parse_mode='Markdown')
    return ENTER_CITY

async def receive_city(update: Update, context: ContextTypes.DEFAULT_TYPE):
    context.user_data["city"] = update.message.text.strip()
    user_id = update.effective_user.id
    lang = get_user(user_id).get("language", "ru")
    await update.message.reply_text(TEXTS[lang]["enter_phone"], parse_mode='Markdown')
    return ENTER_PHONE

async def receive_phone(update: Update, context: ContextTypes.DEFAULT_TYPE):
    context.user_data["phone"] = update.message.text.strip()
    
    user_id = update.effective_user.id
    lang = get_user(user_id).get("language", "ru")
    work_type = context.user_data.get("work_type")
    
    # âœ… KURSOVAYA Ã¼Ã§in ZADANIE soramaly
    if work_type == "kursovaya":
        text = "ğŸ“‹ *Ğ—ĞĞ”ĞĞĞ˜Ğ•*\n\nğŸ“¸ ĞÑ‚Ğ¿Ñ€Ğ°Ğ²ÑŒÑ‚Ğµ Ñ„Ğ¾Ñ‚Ğ¾ Ğ·Ğ°Ğ´Ğ°Ğ½Ğ¸Ñ\nâ­ï¸ Ğ˜Ğ»Ğ¸ Ğ½Ğ°Ğ¶Ğ¼Ğ¸Ñ‚Ğµ ĞŸÑ€Ğ¾Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚ÑŒ"
        keyboard = [[InlineKeyboardButton("â­ï¸ ĞŸÑ€Ğ¾Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚ÑŒ / Skip", callback_data="skip_zadanie")]]
        await update.message.reply_text(text, reply_markup=InlineKeyboardMarkup(keyboard), parse_mode='Markdown')
        return UPLOAD_ZADANIE
    
    # âœ… BEÃLEKILER - GÃ–NI ORDER SUMMARY
    else:
        context.user_data["zadanie_photo"] = None
        return await show_order_summary(update, context)

async def receive_zadanie(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if update.message.photo:
        context.user_data["zadanie_photo"] = update.message.photo[-1].file_id
        user_id = update.effective_user.id
        lang = get_user(user_id).get("language", "ru")
        msg = "âœ… Ğ—Ğ°Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¾!" if lang == "ru" else "âœ… Assignment received!"
        await update.message.reply_text(msg)
    return await show_order_summary(update, context)

async def skip_zadanie(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    await query.answer()
    context.user_data["zadanie_photo"] = None
    return await show_order_summary_from_callback(update, context)

async def show_order_summary(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user = update.effective_user
    user_id = user.id
    user_data = get_user(user_id)
    lang = user_data.get("language", "ru")
    return await _show_order_summary_common(update.message.reply_text, context, user_id, lang)

async def show_order_summary_from_callback(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    user_id = query.from_user.id
    user_data = get_user(user_id)
    lang = user_data.get("language", "ru")
    return await _show_order_summary_common(query.message.reply_text, context, user_id, lang)

async def _show_order_summary_common(reply_func, context: ContextTypes.DEFAULT_TYPE, user_id: int, lang: str):
    """âœ… Common logic for showing order summary - FIXED"""
    
    user_data = get_user(user_id)
    
    # âœ… GET ALL REQUIRED DATA FROM CONTEXT
    country = context.user_data.get("country")
    work_type = context.user_data.get("work_type")
    pages = context.user_data.get("pages")
    base_price = context.user_data.get("base_price")
    promo = context.user_data.get("promo_code")
    
    # âœ… VALIDATE DATA
    if not all([country, work_type, pages, base_price]):
        logger.error(f"âŒ Missing order data! country={country}, work_type={work_type}, pages={pages}, base_price={base_price}")
        error_msg = "âŒ ĞÑˆĞ¸Ğ±ĞºĞ°: Ğ½ĞµĞ¿Ğ¾Ğ»Ğ½Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ·Ğ°ĞºĞ°Ğ·Ğ°!" if lang == "ru" else "âŒ Error: incomplete order data!"
        await reply_func(error_msg)
        return PAYMENT_PHOTO
    
    # âœ… CALCULATE FINAL PRICE
    final_price, discounts = calculate_final_price(user_id, base_price, promo)
    context.user_data["final_price"] = final_price
    
    # âœ… GET CURRENCY & PAYMENT INFO
    currency = get_currency_symbol(country)
    payment = PAYMENTS[country]
    work_type_name = WORK_TYPES[work_type]["ru" if lang == "ru" else "en"]
    
    # âœ… DISCOUNT TEXT
    discount_text = ""
    if discounts:
        discount_text = "\nğŸ‰ *Ğ¡ĞºĞ¸Ğ´ĞºĞ¸:*\n" if lang == "ru" else "\nğŸ‰ *Discounts:*\n"
        for name, percent in discounts:
            discount_text += f"â€¢ {name}: -{percent}%\n"
    
    # âœ… FORMAT INFO
    if work_type == "presentation":
        format_info = "ğŸ“ PPTX"
    else:
        format_info = "ğŸ“ DOCX"
    
    # âœ… PAGE WORD
    page_word = "Ğ¡Ñ‚Ñ€Ğ°Ğ½Ğ¸Ñ†" if lang == "ru" else "Pages"
    if work_type == "presentation":
        page_word = "Ğ¡Ğ»Ğ°Ğ¹Ğ´Ğ¾Ğ²" if lang == "ru" else "Slides"
    
    # âœ… BUILD SUMMARY TEXT
    text = f"""ğŸ“‹ *{"Ğ˜Ğ¢ĞĞ“ Ğ—ĞĞšĞĞ—Ğ" if lang == "ru" else "ORDER SUMMARY"}*

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“ *{"Ğ Ğ°Ğ±Ğ¾Ñ‚Ğ°" if lang == "ru" else "Work"}:*
â€¢ {"Ğ¢Ğ¸Ğ¿" if lang == "ru" else "Type"}: {work_type_name}
â€¢ {"Ğ¢ĞµĞ¼Ğ°" if lang == "ru" else "Topic"}: {context.user_data.get('topic', '-')}
â€¢ {page_word}: {pages}
â€¢ {"Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚" if lang == "ru" else "Format"}: {format_info}

ğŸ‘¤ *{"Ğ¡Ñ‚ÑƒĞ´ĞµĞ½Ñ‚" if lang == "ru" else "Student"}:*
â€¢ {"Ğ¤Ğ˜Ğ" if lang == "ru" else "Full Name"}: {context.user_data.get('fullname', '-')}
â€¢ {"Ğ£Ğ½Ğ¸Ğ²ĞµÑ€ÑĞ¸Ñ‚ĞµÑ‚" if lang == "ru" else "University"}: {context.user_data.get('university', '-')}
â€¢ {"ĞšÑƒÑ€Ñ" if lang == "ru" else "Course"}: {context.user_data.get('course', '-')}
â€¢ {"Ğ“Ñ€ÑƒĞ¿Ğ¿Ğ°" if lang == "ru" else "Group"}: {context.user_data.get('group', '-')}
â€¢ {"Ğ“Ğ¾Ñ€Ğ¾Ğ´" if lang == "ru" else "City"}: {context.user_data.get('city', '-')}
{discount_text}
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ’° {"Ğ‘Ğ°Ğ·Ğ¾Ğ²Ğ°Ñ" if lang == "ru" else "Base"}: ~{base_price} {currency}~
ğŸ’µ *{"Ğ˜Ğ¢ĞĞ“Ğ" if lang == "ru" else "TOTAL"}: {final_price} {currency}*

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ’³ *{"ĞĞŸĞ›ĞĞ¢Ğ" if lang == "ru" else "PAYMENT"}:*
ğŸ¦ {payment['bank']}
ğŸ’³ `{payment['card']}`
ğŸ‘¤ {payment['name']}
ğŸ’µ {final_price} {currency}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“¸ *{"ĞÑ‚Ğ¿Ñ€Ğ°Ğ²ÑŒÑ‚Ğµ ÑĞºÑ€Ğ¸Ğ½ÑˆĞ¾Ñ‚ Ğ¾Ğ¿Ğ»Ğ°Ñ‚Ñ‹!" if lang == "ru" else "Send payment screenshot!"}*"""
    
    # âœ… KEYBOARD
    keyboard = [[InlineKeyboardButton(TEXTS[lang]["cancel"], callback_data="cancel_order")]]
    
    # âœ… SEND MESSAGE
    try:
        await reply_func(text, reply_markup=InlineKeyboardMarkup(keyboard), parse_mode='Markdown')
        logger.info(f"âœ… Order summary sent to user {user_id}")
    except Exception as e:
        logger.error(f"âŒ Failed to send order summary: {e}")
        raise
    
    return PAYMENT_PHOTO

async def receive_payment_photo(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """âœ… Receive payment screenshot and send to admin"""
    
    # âœ… CHECK IF PHOTO EXISTS
    if not update.message.photo:
        logger.warning("âš ï¸ No photo in message!")
        user_id = update.effective_user.id
        lang = get_user(user_id).get("language", "ru")
        msg = "âŒ ĞÑ‚Ğ¿Ñ€Ğ°Ğ²ÑŒÑ‚Ğµ *Ñ„Ğ¾Ñ‚Ğ¾* Ñ‡ĞµĞºĞ°!" if lang == "ru" else "âŒ Send *photo* of payment!"
        await update.message.reply_text(msg, parse_mode='Markdown')
        return PAYMENT_PHOTO
    
    # âœ… GET USER & PHOTO
    user = update.effective_user
    user_id = user.id
    user_data = get_user(user_id)
    lang = user_data.get("language", "ru")
    
    # âœ… GET PHOTO - DEFINE photo VARIABLE
    photo = update.message.photo[-1]  # âœ… SAKLA!
    photo_id = photo.file_id
    
    logger.info(f"ğŸ“¸ Payment photo received from user {user_id}: {photo_id}")
    
    # âœ… GENERATE ORDER ID
    order_id = generate_order_id()
    
    # âœ… CREATE ORDER DATA
    order_data = {
        "order_id": order_id,
        "user_id": user_id,
        "username": user.username or "N/A",
        "full_name": user.full_name,
        "language": lang,
        "country": context.user_data["country"],
        "work_type": context.user_data["work_type"],
        "pages": context.user_data["pages"],
        "topic": context.user_data.get("topic", "-"),
        "university": context.user_data.get("university", "-"),
        "faculty": context.user_data.get("faculty", "-"),
        "subject": context.user_data.get("subject", "-"),
        "fullname": context.user_data.get("fullname", "-"),
        "course": context.user_data.get("course", "-"),
        "group": context.user_data.get("group", "-"),
        "teacher": context.user_data.get("teacher", "-"),
        "city": context.user_data.get("city", "-"),
        "phone": context.user_data.get("phone", "-"),
        "base_price": context.user_data["base_price"],
        "final_price": context.user_data["final_price"],
        "promo_code": context.user_data.get("promo_code"),
        "payment_photo": photo_id,  # âœ… USE photo_id
        "zadanie_photo": context.user_data.get("zadanie_photo"),
        "status": "pending",
        "created_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    }
    
    # âœ… SAVE TO PENDING
    pending_payments[order_id] = order_data
    
    logger.info(f"âœ… Order {order_id} created and saved to pending_payments")
    
    # âœ… NOTIFY CUSTOMER
    currency = get_currency_symbol(order_data["country"])
    customer_msg = f"""âœ… <b>Ğ—ĞĞšĞĞ— ĞŸĞ Ğ˜ĞĞ¯Ğ¢!</b>

ğŸ“‹ ID: <code>{order_id}</code>
ğŸ’µ {order_data['final_price']} {currency}

â³ ĞĞ¶Ğ¸Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ¾Ğ´Ñ‚Ğ²ĞµÑ€Ğ¶Ğ´ĞµĞ½Ğ¸Ñ Ğ°Ğ´Ğ¼Ğ¸Ğ½Ğ¸ÑÑ‚Ñ€Ğ°Ñ‚Ğ¾Ñ€Ğ°..."""
    
    await update.message.reply_text(customer_msg, parse_mode='HTML')
    
    # âœ… PREPARE ADMIN MESSAGE
    work_type_name = WORK_TYPES[order_data["work_type"]]["ru"]
    country_name = "ğŸ‡§ğŸ‡¾ Ğ‘ĞµĞ»Ğ°Ñ€ÑƒÑÑŒ" if order_data["country"] == "BY" else "ğŸ‡·ğŸ‡º Ğ Ğ¾ÑÑĞ¸Ñ"
    
    admin_text = f"""ğŸ†• <b>ĞĞĞ’Ğ«Ğ™ Ğ—ĞĞšĞĞ—!</b>

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“‹ ID: <code>{order_id}</code>
ğŸŒ Ğ¡Ñ‚Ñ€Ğ°Ğ½Ğ°: {country_name}

ğŸ‘¤ <b>ĞšĞ»Ğ¸ĞµĞ½Ñ‚:</b>
â€¢ Ğ˜Ğ¼Ñ: {user.full_name}
â€¢ Username: @{user.username or 'N/A'}
â€¢ User ID: <code>{user_id}</code>
â€¢ Ğ¢ĞµĞ»ĞµÑ„Ğ¾Ğ½: {order_data['phone']}

ğŸ“ <b>Ğ Ğ°Ğ±Ğ¾Ñ‚Ğ°:</b>
â€¢ Ğ¢Ğ¸Ğ¿: {work_type_name}
â€¢ Ğ¢ĞµĞ¼Ğ°: {order_data['topic'][:50]}
â€¢ Ğ¡Ñ‚Ñ€Ğ°Ğ½Ğ¸Ñ†: {order_data['pages']}
â€¢ ĞŸÑ€ĞµĞ´Ğ¼ĞµÑ‚: {order_data['subject']}

ğŸ“ <b>Ğ”Ğ°Ğ½Ğ½Ñ‹Ğµ:</b>
â€¢ Ğ’Ğ£Ğ—: {order_data['university']}
â€¢ ĞšÑƒÑ€Ñ: {order_data['course']}
â€¢ Ğ“Ñ€ÑƒĞ¿Ğ¿Ğ°: {order_data['group']}

ğŸ’° <b>ĞĞ¿Ğ»Ğ°Ñ‚Ğ°:</b>
â€¢ Ğ¦ĞµĞ½Ğ°: {order_data['final_price']} {currency}
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

â¬‡ï¸ Ğ¡ĞºÑ€Ğ¸Ğ½ÑˆĞ¾Ñ‚ Ğ¾Ğ¿Ğ»Ğ°Ñ‚Ñ‹ Ğ½Ğ¸Ğ¶Ğµ"""
    
    # âœ… APPROVAL BUTTONS
    keyboard = [
        [
            InlineKeyboardButton("âœ… ĞŸĞĞ”Ğ¢Ğ’Ğ•Ğ Ğ”Ğ˜Ğ¢Ğ¬", callback_data=f"confirm_{order_id}"),
            InlineKeyboardButton("âŒ ĞĞ¢ĞšĞ›ĞĞĞ˜Ğ¢Ğ¬", callback_data=f"reject_{order_id}")
        ]
    ]
    
    # âœ… SEND TO ADMIN
    try:
        # First send text
        await context.bot.send_message(
            chat_id=ADMIN_ID,
            text=admin_text,
            parse_mode='HTML'
        )
        
        # Then send photo with buttons
        await context.bot.send_photo(
            chat_id=ADMIN_ID,
            photo=photo_id,  # âœ… USE photo_id
            caption=f"ğŸ“¸ Ğ¡ĞºÑ€Ğ¸Ğ½ÑˆĞ¾Ñ‚ Ğ¾Ğ¿Ğ»Ğ°Ñ‚Ñ‹\nğŸ“‹ Order: <code>{order_id}</code>",
            reply_markup=InlineKeyboardMarkup(keyboard),
            parse_mode='HTML'
        )
        
        logger.info(f"âœ… Order {order_id} sent to admin {ADMIN_ID}")
        
    except Exception as e:
        logger.error(f"âŒ Failed to send to admin: {e}")
        
        # Notify customer about error
        error_msg = "âš ï¸ Ğ¢ĞµÑ…Ğ½Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ğ¾ÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞµ Ğ°Ğ´Ğ¼Ğ¸Ğ½Ğ¸ÑÑ‚Ñ€Ğ°Ñ‚Ğ¾Ñ€Ñƒ. ĞŸĞ¾Ğ¿Ñ€Ğ¾Ğ±ÑƒĞ¹Ñ‚Ğµ ÑĞ½Ğ¾Ğ²Ğ° Ñ‡ĞµÑ€ĞµĞ· /start"
        await update.message.reply_text(error_msg)
        
        # Remove from pending
        if order_id in pending_payments:
            del pending_payments[order_id]
        
        return ConversationHandler.END
    
    # âœ… CLEAR USER DATA
    context.user_data.clear()
    
    return ConversationHandler.END
    
    # âœ… CLEAR USER DATA
    context.user_data.clear()
    
    return ConversationHandler.END

# ============== DOCUMENT GENERATION ==============

def create_title_page(doc: Document, order_data: dict, lang: str):
    section = doc.sections[0]
    section.top_margin = Cm(2)
    section.bottom_margin = Cm(2)
    section.left_margin = Cm(3)
    section.right_margin = Cm(1.5)
    
    ministry = doc.add_paragraph()
    ministry.alignment = WD_ALIGN_PARAGRAPH.CENTER
    ministry_text = "ĞœĞ˜ĞĞ˜Ğ¡Ğ¢Ğ•Ğ Ğ¡Ğ¢Ğ’Ğ ĞĞ‘Ğ ĞĞ—ĞĞ’ĞĞĞ˜Ğ¯ Ğ Ğ•Ğ¡ĞŸĞ£Ğ‘Ğ›Ğ˜ĞšĞ˜ Ğ‘Ğ•Ğ›ĞĞ Ğ£Ğ¡Ğ¬" if order_data["country"] == "BY" else "ĞœĞ˜ĞĞ˜Ğ¡Ğ¢Ğ•Ğ Ğ¡Ğ¢Ğ’Ğ ĞĞĞ£ĞšĞ˜ Ğ˜ Ğ’Ğ«Ğ¡Ğ¨Ğ•Ğ“Ğ ĞĞ‘Ğ ĞĞ—ĞĞ’ĞĞĞ˜Ğ¯ Ğ ĞĞ¡Ğ¡Ğ˜Ğ™Ğ¡ĞšĞĞ™ Ğ¤Ğ•Ğ”Ğ•Ğ ĞĞ¦Ğ˜Ğ˜"
    run = ministry.add_run(ministry_text)
    run.font.size = Pt(14)
    run.font.name = 'Times New Roman'
    
    uni = doc.add_paragraph()
    uni.alignment = WD_ALIGN_PARAGRAPH.CENTER
    run = uni.add_run(order_data["university"].upper())
    run.font.size = Pt(14)
    run.font.name = 'Times New Roman'
    run.bold = True
    
    faculty = doc.add_paragraph()
    faculty.alignment = WD_ALIGN_PARAGRAPH.CENTER
    run = faculty.add_run(order_data["faculty"])
    run.font.size = Pt(14)
    run.font.name = 'Times New Roman'
    
    for _ in range(4):
        doc.add_paragraph()
    
    work_type_name = WORK_TYPES[order_data["work_type"]]["ru"]
    wt = doc.add_paragraph()
    wt.alignment = WD_ALIGN_PARAGRAPH.CENTER
    run = wt.add_run(work_type_name.upper())
    run.font.size = Pt(16)
    run.font.name = 'Times New Roman'
    run.bold = True
    
    subj = doc.add_paragraph()
    subj.alignment = WD_ALIGN_PARAGRAPH.CENTER
    run = subj.add_run(f"Ğ¿Ğ¾ Ğ´Ğ¸ÑÑ†Ğ¸Ğ¿Ğ»Ğ¸Ğ½Ğµ Â«{order_data['subject']}Â»")
    run.font.size = Pt(14)
    run.font.name = 'Times New Roman'
    
    doc.add_paragraph()
    
    topic_p = doc.add_paragraph()
    topic_p.alignment = WD_ALIGN_PARAGRAPH.CENTER
    run = topic_p.add_run(f"Ğ½Ğ° Ñ‚ĞµĞ¼Ñƒ: Â«{order_data['topic']}Â»")
    run.font.size = Pt(14)
    run.font.name = 'Times New Roman'
    run.bold = True
    
    for _ in range(4):
        doc.add_paragraph()
    
    student_info = doc.add_paragraph()
    student_info.alignment = WD_ALIGN_PARAGRAPH.RIGHT
    text = f"""Ğ’Ñ‹Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ğ»(Ğ°):
ÑÑ‚ÑƒĞ´ĞµĞ½Ñ‚(ĞºĞ°) {order_data['course']} ĞºÑƒÑ€ÑĞ°
Ğ³Ñ€ÑƒĞ¿Ğ¿Ñ‹ {order_data['group']}
{order_data['fullname']}

ĞŸÑ€Ğ¾Ğ²ĞµÑ€Ğ¸Ğ»(Ğ°):
{order_data['teacher']}"""
    run = student_info.add_run(text)
    run.font.size = Pt(14)
    run.font.name = 'Times New Roman'
    
    for _ in range(4):
        doc.add_paragraph()
    
    city_year = doc.add_paragraph()
    city_year.alignment = WD_ALIGN_PARAGRAPH.CENTER
    run = city_year.add_run(f"{order_data['city']}, {datetime.now().year}")
    run.font.size = Pt(14)
    run.font.name = 'Times New Roman'
    
    doc.add_page_break()

def create_zadanie_page(doc: Document, order_data: dict):
    if order_data.get("zadanie_photo"):
        header = doc.add_paragraph()
        header.alignment = WD_ALIGN_PARAGRAPH.CENTER
        run = header.add_run("Ğ—ĞĞ”ĞĞĞ˜Ğ•")
        run.font.size = Pt(14)
        run.font.name = 'Times New Roman'
        run.bold = True
        
        doc.add_paragraph()
        
        note = doc.add_paragraph()
        note.alignment = WD_ALIGN_PARAGRAPH.CENTER
        run = note.add_run("(ÑĞ¼. Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ)")
        run.font.size = Pt(14)
        run.font.name = 'Times New Roman'
        run.italic = True
        
        doc.add_page_break()

def generate_chapter_title(chapter_num: int, topic: str) -> str:
    titles = [
        ["Ğ¢ĞµĞ¾Ñ€ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ¾ÑĞ½Ğ¾Ğ²Ñ‹", "ĞÑĞ½Ğ¾Ğ²Ğ½Ñ‹Ğµ Ğ¿Ğ¾Ğ½ÑÑ‚Ğ¸Ñ", "ĞĞ±Ñ‰Ğ¸Ğµ Ğ¿Ğ¾Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ"],
        ["ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹", "ĞŸÑ€Ğ°ĞºÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ°ÑĞ¿ĞµĞºÑ‚Ñ‹", "Ğ¡Ğ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾Ğµ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ"],
        ["ĞŸĞµÑ€ÑĞ¿ĞµĞºÑ‚Ğ¸Ğ²Ñ‹ Ñ€Ğ°Ğ·Ğ²Ğ¸Ñ‚Ğ¸Ñ", "Ğ ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¸", "ĞŸÑƒÑ‚Ğ¸ Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ"]
    ]
    return titles[chapter_num][0] if chapter_num < len(titles) else f"Ğ“Ğ»Ğ°Ğ²Ğ° {chapter_num + 1}"

def generate_subsection_title(content: str, chapter: int, subsection: int) -> str:
    words = re.findall(r'\b[Ğ-Ğ¯Ğ][Ğ°-ÑÑ‘]{4,}\b', content)
    if words and len(words) >= 2:
        return f"{words[0]} {words[1].lower()}"
    return f"ĞŸĞ¾Ğ´Ñ€Ğ°Ğ·Ğ´ĞµĞ» {chapter+1}.{subsection+1}"

def generate_references(order_data: dict, count: int) -> list:
    references = []
    current_year = datetime.now().year
    
    authors = ["Ğ˜Ğ²Ğ°Ğ½Ğ¾Ğ² Ğ˜.Ğ˜.", "ĞŸĞµÑ‚Ñ€Ğ¾Ğ² ĞŸ.ĞŸ.", "Ğ¡Ğ¸Ğ´Ğ¾Ñ€Ğ¾Ğ² Ğ¡.Ğ¡.", "ĞšĞ¾Ğ·Ğ»Ğ¾Ğ² Ğš.Ğš.", "ĞĞ¾Ğ²Ğ¸ĞºĞ¾Ğ² Ğ.Ğ.", "ĞœĞ¾Ñ€Ğ¾Ğ·Ğ¾Ğ² Ğœ.Ğœ."]
    publishers_by = ["Ğ’Ñ‹ÑˆÑĞ¹ÑˆĞ°Ñ ÑˆĞºĞ¾Ğ»Ğ°", "Ğ‘Ğ“Ğ£", "Ğ‘Ğ“Ğ£Ğ˜Ğ "]
    publishers_ru = ["ĞĞ°ÑƒĞºĞ°", "Ğ®Ñ€Ğ°Ğ¹Ñ‚", "Ğ˜ĞĞ¤Ğ Ğ-Ğœ"]
    cities_by = ["ĞœĞ¸Ğ½ÑĞº", "Ğ“Ğ¾Ğ¼ĞµĞ»ÑŒ", "Ğ‘Ñ€ĞµÑÑ‚"]
    cities_ru = ["ĞœĞ¾ÑĞºĞ²Ğ°", "Ğ¡Ğ°Ğ½ĞºÑ‚-ĞŸĞµÑ‚ĞµÑ€Ğ±ÑƒÑ€Ğ³"]
    
    country = order_data["country"]
    cities = cities_by if country == "BY" else cities_ru
    publishers = publishers_by if country == "BY" else publishers_ru
    
    for i in range(count):
        author = random.choice(authors)
        publisher = random.choice(publishers)
        city = random.choice(cities)
        year = random.randint(current_year - 8, current_year - 1)
        pages = random.randint(120, 450)
        
        topic_words = order_data["topic"].split()[:3]
        title = " ".join(topic_words) if topic_words else order_data["subject"]
        
        ref = f"{author} {title} / {author}. â€“ {city}: {publisher}, {year}. â€“ {pages} Ñ."
        references.append(ref)
    
    return references

def parse_content_structure(content: str, pages: int, order_data: dict) -> dict:
    structure = {"introduction": "", "chapters": [], "conclusion": "", "references": []}
    
    paragraphs = [p.strip() for p in content.split('\n\n') if p.strip()]
    
    intro_paras = max(2, pages // 10)
    conclusion_paras = max(2, pages // 10)
    chapter_paras = len(paragraphs) - intro_paras - conclusion_paras
    
    num_chapters = 2 if pages < 30 else 3
    paras_per_chapter = chapter_paras // num_chapters
    
    structure["introduction"] = "\n\n".join(paragraphs[:intro_paras])
    
    current_pos = intro_paras
    for i in range(num_chapters):
        num_subsections = random.randint(2, 4)
        subsection_size = paras_per_chapter // num_subsections
        
        subsections = []
        for j in range(num_subsections):
            start = current_pos + (j * subsection_size)
            end = start + subsection_size
            subsection_text = "\n\n".join(paragraphs[start:end])
            
            if subsection_text:
                subsections.append({
                    "number": f"{i+1}.{j+1}",
                    "title": generate_subsection_title(subsection_text, i, j),
                    "content": subsection_text
                })
        
        structure["chapters"].append({
            "number": i + 1,
            "title": generate_chapter_title(i, order_data.get("topic", "Ğ¢ĞµĞ¼Ğ°")),
            "subsections": subsections
        })
        
        current_pos += paras_per_chapter
    
    structure["conclusion"] = "\n\n".join(paragraphs[current_pos:current_pos + conclusion_paras])
    structure["references"] = generate_references(order_data, random.randint(6, 13))
    
    return structure

def create_document(order_data: dict, content: str, lang: str) -> BytesIO:
    doc = Document()
    
    for section in doc.sections:
        section.top_margin = Cm(2)
        section.bottom_margin = Cm(2)
        section.left_margin = Cm(3)
        section.right_margin = Cm(1.5)
    
    create_title_page(doc, order_data, lang)
    
    if order_data.get("zadanie_photo"):
        create_zadanie_page(doc, order_data)
    
    structure = parse_content_structure(content, order_data["pages"], order_data)
    
    toc_header = doc.add_paragraph()
    toc_header.alignment = WD_ALIGN_PARAGRAPH.CENTER
    run = toc_header.add_run("Ğ¡ĞĞ”Ğ•Ğ Ğ–ĞĞĞ˜Ğ•")
    run.font.size = Pt(14)
    run.font.name = 'Times New Roman'
    run.bold = True
    toc_header.paragraph_format.space_after = Pt(18)
    
    toc_entries = [("Ğ’Ğ’Ğ•Ğ”Ğ•ĞĞ˜Ğ•", 3)]
    page_num = 4
    
    for chapter in structure["chapters"]:
        toc_entries.append((f"Ğ“Ğ›ĞĞ’Ğ {chapter['number']} {chapter['title'].upper()}", page_num))
        page_num += 1
        for subsection in chapter["subsections"]:
            toc_entries.append((f"{subsection['number']} {subsection['title']}", page_num))
            page_num += 1
    
    toc_entries.append(("Ğ—ĞĞšĞ›Ğ®Ğ§Ğ•ĞĞ˜Ğ•", page_num))
    page_num += 1
    toc_entries.append(("Ğ¡ĞŸĞ˜Ğ¡ĞĞš Ğ˜Ğ¡ĞŸĞĞ›Ğ¬Ğ—ĞĞ’ĞĞĞĞ«Ğ¥ Ğ˜Ğ¡Ğ¢ĞĞ§ĞĞ˜ĞšĞĞ’", page_num))
    
    for title, page in toc_entries:
        p = doc.add_paragraph()
        is_main = title.isupper() or title.startswith("Ğ“Ğ›ĞĞ’Ğ")
        
        if is_main:
            p.alignment = WD_ALIGN_PARAGRAPH.CENTER
            run = p.add_run(title)
            run.font.bold = True
        else:
            p.paragraph_format.left_indent = Cm(1.25)
            p.alignment = WD_ALIGN_PARAGRAPH.LEFT
            dots_count = 80 - len(title) - len(str(page))
            full_text = f"{title}{'.' * dots_count}{page}"
            run = p.add_run(full_text)
        
        run.font.size = Pt(14)
        run.font.name = 'Times New Roman'
        p.paragraph_format.space_after = Pt(6)
    
    doc.add_page_break()
    
    intro_header = doc.add_paragraph()
    intro_header.alignment = WD_ALIGN_PARAGRAPH.CENTER
    run = intro_header.add_run("Ğ’Ğ’Ğ•Ğ”Ğ•ĞĞ˜Ğ•")
    run.font.size = Pt(14)
    run.font.name = 'Times New Roman'
    run.bold = True
    intro_header.paragraph_format.space_before = Pt(18)
    intro_header.paragraph_format.space_after = Pt(18)
    
    intro_paragraphs = structure["introduction"].split('\n\n')
    for para_text in intro_paragraphs:
        if para_text.strip():
            p = doc.add_paragraph()
            p.alignment = WD_ALIGN_PARAGRAPH.JUSTIFY
            p.paragraph_format.first_line_indent = Cm(1.25)
            p.paragraph_format.line_spacing = Pt(18)
            clean_text = re.sub(r'[#\*_]', '', para_text.strip())
            run = p.add_run(clean_text)
            run.font.size = Pt(14)
            run.font.name = 'Times New Roman'
    
    doc.add_page_break()
    
    for chapter in structure["chapters"]:
        ch_header = doc.add_paragraph()
        ch_header.alignment = WD_ALIGN_PARAGRAPH.CENTER
        run = ch_header.add_run(f"Ğ“Ğ›ĞĞ’Ğ {chapter['number']} {chapter['title'].upper()}")
        run.font.size = Pt(14)
        run.font.name = 'Times New Roman'
        run.bold = True
        ch_header.paragraph_format.space_before = Pt(18)
        ch_header.paragraph_format.space_after = Pt(18)
        
        doc.add_page_break()
        
        for subsection in chapter["subsections"]:
            sub_header = doc.add_paragraph()
            sub_header.alignment = WD_ALIGN_PARAGRAPH.CENTER
            run = sub_header.add_run(f"{subsection['number']} {subsection['title']}")
            run.font.size = Pt(14)
            run.font.name = 'Times New Roman'
            run.bold = True
            sub_header.paragraph_format.space_before = Pt(18)
            sub_header.paragraph_format.space_after = Pt(18)
            
            sub_paragraphs = subsection["content"].split('\n\n')
            for para_text in sub_paragraphs:
                if para_text.strip():
                    p = doc.add_paragraph()
                    p.alignment = WD_ALIGN_PARAGRAPH.JUSTIFY
                    p.paragraph_format.first_line_indent = Cm(1.25)
                    p.paragraph_format.line_spacing = Pt(18)
                    clean_text = re.sub(r'[#\*_]', '', para_text.strip())
                    run = p.add_run(clean_text)
                    run.font.size = Pt(14)
                    run.font.name = 'Times New Roman'
    
    doc.add_page_break()
    concl_header = doc.add_paragraph()
    concl_header.alignment = WD_ALIGN_PARAGRAPH.CENTER
    run = concl_header.add_run("Ğ—ĞĞšĞ›Ğ®Ğ§Ğ•ĞĞ˜Ğ•")
    run.font.size = Pt(14)
    run.font.name = 'Times New Roman'
    run.bold = True
    concl_header.paragraph_format.space_before = Pt(18)
    concl_header.paragraph_format.space_after = Pt(18)
    
    concl_paragraphs = structure["conclusion"].split('\n\n')
    for para_text in concl_paragraphs:
        if para_text.strip():
            p = doc.add_paragraph()
            p.alignment = WD_ALIGN_PARAGRAPH.JUSTIFY
            p.paragraph_format.first_line_indent = Cm(1.25)
            p.paragraph_format.line_spacing = Pt(18)
            clean_text = re.sub(r'[#\*_]', '', para_text.strip())
            run = p.add_run(clean_text)
            run.font.size = Pt(14)
            run.font.name = 'Times New Roman'
    
    doc.add_page_break()
    ref_header = doc.add_paragraph()
    ref_header.alignment = WD_ALIGN_PARAGRAPH.CENTER
    run = ref_header.add_run("Ğ¡ĞŸĞ˜Ğ¡ĞĞš Ğ˜Ğ¡ĞŸĞĞ›Ğ¬Ğ—ĞĞ’ĞĞĞĞ«Ğ¥ Ğ˜Ğ¡Ğ¢ĞĞ§ĞĞ˜ĞšĞĞ’")
    run.font.size = Pt(14)
    run.font.name = 'Times New Roman'
    run.bold = True
    ref_header.paragraph_format.space_before = Pt(18)
    ref_header.paragraph_format.space_after = Pt(18)
    
    for i, ref in enumerate(structure["references"], 1):
        p = doc.add_paragraph()
        p.alignment = WD_ALIGN_PARAGRAPH.JUSTIFY
        p.paragraph_format.left_indent = Cm(1.25)
        p.paragraph_format.first_line_indent = Cm(-1.25)
        p.paragraph_format.line_spacing = Pt(18)
        run = p.add_run(f"{i}. {ref}")
        run.font.size = Pt(14)
        run.font.name = 'Times New Roman'
    
    buffer = BytesIO()
    doc.save(buffer)
    buffer.seek(0)
    return buffer

# ============== PRESENTATION ==============

PRESENTATION_THEMES = [
    {"name": "Modern Blue", "bg": "0a1929", "title": "90caf9", "text": "e3f2fd", "accent": "42a5f5"},
    {"name": "Corporate Red", "bg": "1a1a2e", "title": "ff6b6b", "text": "f8f9fa", "accent": "ee5a6f"},
    {"name": "Nature Green", "bg": "1b4332", "title": "95d5b2", "text": "d8f3dc", "accent": "52b788"},
    {"name": "Royal Purple", "bg": "2d1b69", "title": "b794f6", "text": "e9d8fd", "accent": "9f7aea"},
    {"name": "Ocean Teal", "bg": "004d61", "title": "4dd0e1", "text": "e0f7fa", "accent": "00acc1"}
]

def hex_to_rgb(hex_color: str):
    hex_color = hex_color.lstrip('#')
    return RGBColor(int(hex_color[0:2], 16), int(hex_color[2:4], 16), int(hex_color[4:6], 16))

def search_images(query: str, num_images: int = 10) -> list:
    """âœ… Pixabay-dan birnÃ¤Ã§e surat netijesini alÃ½ar"""
    try:
        clean_query = re.sub(r'[^a-zA-Z\s]', '', query).strip()
        
        params = {
            'key': PIXABAY_API_KEY,
            'q': clean_query,
            'image_type': 'photo',
            'orientation': 'horizontal',
            'safesearch': 'true',
            'per_page': 20, # âœ… Has kÃ¶p netije soraÃ½arys (20 sany)
            'lang': 'en'
        }
        
        response = requests.get('https://pixabay.com/api/', params=params, timeout=10)
        
        if response.status_code == 200:
            hits = response.json().get('hits', [])
            if hits:
                # SuratlaryÅˆ URL-lerini sanaw hÃ¶kmÃ¼nde yzyna berÃ½Ã¤ris
                return [h['largeImageURL'] for h in hits if h['imageWidth'] > 1000]
        
        return []
    except Exception as e:
        logger.error(f"âŒ Image search error: {e}")
        return []

def download_image(url: str):
    """âœ… Suraty internetden gÃ¶Ã§Ã¼rip alÃ½ar we BytesIO gÃ¶rnÃ¼ÅŸinde gaÃ½tarÃ½ar"""
    try:
        # Brauzer Ã½aly gÃ¶rÃ¼nmek Ã¼Ã§in header goÅŸÃ½arys
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36"
        }
        response = requests.get(url, headers=headers, timeout=10)
        if response.status_code == 200 and len(response.content) > 10000: # 10KB-dan uly bolmaly
            return BytesIO(response.content)
    except Exception as e:
        logger.error(f"âŒ Surat gÃ¶Ã§Ã¼rmekde Ã½alÅˆyÅŸlyk ({url[:30]}...): {e}")
    return None

def get_unique_image(query: str):
    """âœ… Internetden tÃ¤ze we ulanylmadyk suraty tapyp getirÃ½Ã¤r"""
    global USED_IMAGE_URLS
    try:
        with DDGS() as ddgs:
            # GÃ¶zleg sÃ¶zÃ¼ne professional sypatlar goÅŸÃ½arys
            search_query = f"{query} professional photography high resolution"
            logger.info(f"ğŸ” GÃ¶zleg baÅŸlandy: {search_query}")
            
            # GÃ¶zleg netijeleri (Uly we giÅˆ formatly suratlar)
            results = ddgs.images(
                keywords=search_query,
                region="wt-wt",
                safesearch="on",
                size="Large",
                layout="Wide"
            )
            
            # Tapylan suratlaryÅˆ iÃ§inden tÃ¤zesini saÃ½laÃ½arys
            count = 0
            for r in results:
                url = r['image']
                if url not in USED_IMAGE_URLS:
                    image_data = download_image(url)
                    if image_data:
                        USED_IMAGE_URLS.add(url)
                        return image_data
                
                count += 1
                if count > 15: # Ilkinji 15 suraty barlap gÃ¶rÃ½Ã¤ris
                    break
    except Exception as e:
        logger.error(f"âŒ GÃ¶zleg ulgamynda Ã½alÅˆyÅŸlyk: {e}")
    
    return None

def parse_presentation_content(content: str, num_slides: int) -> list:
    """âœ… SlaÃ½dyÅˆ adyny we punktlaryny dogry bÃ¶lÃ¼p alÃ½ar"""
    slides = [{"type": "title"}]
    
    # SlaÃ½dlary bÃ¶lmek
    raw_slides = [s.strip() for s in content.split('\n\n') if len(s.strip()) > 50]
    
    for slide_text in raw_slides:
        lines = [l.strip() for l in slide_text.split('\n') if l.strip()]
        if not lines: continue

        # ğŸ” IMAGE_KEYWORD-y gÃ¶zlemek we arassalamak
        img_keyword = "business professional"
        filtered_lines = []
        for l in lines:
            if "IMAGE_KEYWORD:" in l:
                img_keyword = l.split("IMAGE_KEYWORD:")[1].strip().replace('"', '')
            else:
                filtered_lines.append(l)

        if not filtered_lines: continue

        # âœ… BIZIN DÃœZELDIÅIMIZ:
        # Birinji setiri Title hÃ¶kmÃ¼nde alÃ½arys, galanlary Bullets
        title = filtered_lines[0].replace('#', '').strip()
        bullets = [p.replace('â€¢ ', '').replace('-', '').strip() for p in filtered_lines[1:] if len(p) > 5]
        
        # Eger hiÃ§ hili punkt Ã½ok bolsa, birinji setiri bullet edip, title-y boÅŸ goÃ½Ã½arys
        if not bullets and len(filtered_lines) > 0:
            bullets = [title]
            title = ""

        slides.append({
            "type": "content",
            "title": title,         # Indi title boÅŸ dÃ¤l
            "bullets": bullets[:5],
            "search_query": img_keyword
        })
            
    slides.append({"type": "final"})
    return slides

def create_title_slide(slide, order_data: dict, theme: dict):
    """âœ… Title slide - STAYS THE SAME"""
    
    # âœ… TOPIC (main title)
    title_box = slide.shapes.add_textbox(PptxInches(0.5), PptxInches(2), PptxInches(12.333), PptxInches(1.5))
    tf = title_box.text_frame
    tf.word_wrap = True
    p = tf.paragraphs[0]
    p.text = order_data['topic'].upper()
    p.font.size = PptxPt(44)
    p.font.bold = True
    p.font.color.rgb = hex_to_rgb(theme["title"])
    p.alignment = PP_ALIGN.CENTER
    
    # âœ… WORK TYPE
    work_type_name = WORK_TYPES[order_data["work_type"]]["ru"]
    sub_box = slide.shapes.add_textbox(PptxInches(0.5), PptxInches(3.5), PptxInches(12.333), PptxInches(0.5))
    tf = sub_box.text_frame
    p = tf.paragraphs[0]
    p.text = work_type_name
    p.font.size = PptxPt(28)
    p.font.color.rgb = hex_to_rgb(theme["accent"])
    p.alignment = PP_ALIGN.CENTER
    
    # âœ… AUTHOR INFO
    author_box = slide.shapes.add_textbox(PptxInches(0.5), PptxInches(5.5), PptxInches(12.333), PptxInches(1))
    tf = author_box.text_frame
    p = tf.paragraphs[0]
    p.text = f"Ğ’Ñ‹Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ğ»(Ğ°): {order_data['fullname']}"
    p.font.size = PptxPt(20)
    p.font.color.rgb = hex_to_rgb(theme["text"])
    p.alignment = PP_ALIGN.CENTER
    
    p = tf.add_paragraph()
    p.text = f"{order_data['university']}, {order_data['city']}, {datetime.now().year}"
    p.font.size = PptxPt(18)
    p.font.color.rgb = hex_to_rgb(theme["text"])
    p.alignment = PP_ALIGN.CENTER

def create_content_slide(slide, slide_data: dict, theme: dict):
    title_box = slide.shapes.add_textbox(PptxInches(0.5), PptxInches(0.3), PptxInches(12.333), PptxInches(1))
    tf = title_box.text_frame
    p = tf.paragraphs[0]
    p.text = slide_data.get("title", "").upper()
    p.font.size = PptxPt(36)
    p.font.bold = True
    p.font.color.rgb = hex_to_rgb(theme["title"])
    p.alignment = PP_ALIGN.CENTER
    
    content_box = slide.shapes.add_textbox(
        PptxInches(1.0),      # Left margin
        PptxInches(1.5),      # Top margin
        PptxInches(11.333),   # Width (almost full)
        PptxInches(5.5)       # Height
    )
    tf = content_box.text_frame
    tf.word_wrap = True
    tf.vertical_anchor = 1  # Center vertically
    
    bullets = slide_data.get("bullets", [])
    
    # âœ… Show all bullets (max 5)
    for i, bullet in enumerate(bullets[:5]):
        if i == 0:
            p = tf.paragraphs[0]
        else:
            p = tf.add_paragraph()
        
        # âœ… Full bullet text
        bullet_text = bullet.strip()
        
        p.text = f"â€¢ {bullet_text}"
        p.font.size = PptxPt(24)  # âœ… Bigger font (no title means more space)
        p.font.color.rgb = hex_to_rgb(theme["text"])
        p.space_after = PptxPt(20)  # More spacing
        p.line_spacing = 1.3
        p.alignment = PP_ALIGN.LEFT

def create_content_slide_with_image(slide, slide_data, theme, image_stream):
    """âœ… SlaÃ½dyÅˆ dizaÃ½ny: "Maglumat" sÃ¶zi aÃ½ryldy"""
    from pptx.util import Inches, Pt
    from pptx.dml.color import RGBColor

    # --- 1. SlaÃ½dyÅˆ adyny (Title) goÃ½mak ---
    # "Maglumat" sÃ¶zi aÃ½ryldy, diÅˆe slide_data-dan gelÃ½Ã¤n title ulanylÃ½ar
    title_str = slide_data.get("title", "").upper()
    
    if title_str: # DiÅˆe title bar bolsa tekst gutusyny dÃ¶ret
        title_box = slide.shapes.add_textbox(Inches(0.5), Inches(0.3), Inches(12), Inches(1))
        title_frame = title_box.text_frame
        title_p = title_frame.paragraphs[0]
        title_p.text = title_str
        title_p.font.bold = True
        title_p.font.size = Pt(32)
        title_p.font.color.rgb = hex_to_rgb(theme["title"])

    # --- 2. Ã‡ep tarapda tekstleri (Bullets) Ã½erleÅŸdirmek ---
    text_box = slide.shapes.add_textbox(Inches(0.5), Inches(1.5), Inches(6.5), Inches(5))
    text_frame = text_box.text_frame
    text_frame.word_wrap = True

    bullets = slide_data.get("bullets", [])
    for point in bullets:
        p = text_frame.add_paragraph()
        p.text = f"â€¢ {point}"
        p.font.size = Pt(20)
        p.font.color.rgb = hex_to_rgb(theme["text"])
        p.space_after = Pt(12)

    # --- 3. Sag tarapda suraty Ã½erleÅŸdirmek ---
    try:
        picture = slide.shapes.add_picture(image_stream, Inches(7.2), Inches(1.5), width=Inches(5.5), height=Inches(5.0))
        # Surata professional Ã§arÃ§uwa
        picture.line.color.rgb = RGBColor(255, 255, 255)
        picture.line.width = Pt(1)
    except Exception as e:
        logger.error(f"âŒ Surat goÃ½up bolmady: {e}")
        text_box.width = Inches(12) # Surat Ã½ok bolsa teksti giÅˆelt

def create_final_slide(slide, theme: dict):
    title_box = slide.shapes.add_textbox(PptxInches(0.5), PptxInches(2.5), PptxInches(12.333), PptxInches(2))
    tf = title_box.text_frame
    p = tf.paragraphs[0]
    p.text = "Ğ¡ĞŸĞĞ¡Ğ˜Ğ‘Ğ Ğ—Ğ Ğ’ĞĞ˜ĞœĞĞĞ˜Ğ•!"
    p.font.size = PptxPt(54)
    p.font.bold = True
    p.font.color.rgb = hex_to_rgb(theme["title"])
    p.alignment = PP_ALIGN.CENTER
    
    q_box = slide.shapes.add_textbox(PptxInches(0.5), PptxInches(4.5), PptxInches(12.333), PptxInches(1))
    tf = q_box.text_frame
    p = tf.paragraphs[0]
    p.font.size = PptxPt(32)
    p.font.color.rgb = hex_to_rgb(theme["accent"])
    p.alignment = PP_ALIGN.CENTER

def create_presentation(order_data: dict, content: str) -> BytesIO:
    """âœ… Web-den suratly we professional prezentasiÃ½a dÃ¶retmek"""
    from pptx import Presentation
    from pptx.util import Inches as PptxInches
    
    # Her tÃ¤ze prezentasiÃ½a baÅŸlanda ulanylan suratlaryÅˆ sanawyny arassalaÃ½arys
    global USED_IMAGE_URLS
    USED_IMAGE_URLS.clear()

    prs = Presentation()
    prs.slide_width = PptxInches(13.333) # 16:9 format
    prs.slide_height = PptxInches(7.5)
    
    theme = random.choice(PRESENTATION_THEMES)
    slides_content = parse_presentation_content(content, order_data['pages'])
    
    total_slides = len(slides_content)
    logger.info(f"ğŸ¬ PrezentasiÃ½a dÃ¶redilÃ½Ã¤r: {total_slides} slaÃ½d.")

    for idx, slide_data in enumerate(slides_content):
        slide_layout = prs.slide_layouts[6] 
        slide = prs.slides.add_slide(slide_layout)
        
        # Fon reÅˆki
        background = slide.background
        fill = background.fill
        fill.solid()
        fill.fore_color.rgb = hex_to_rgb(theme["bg"])
        
        if idx == 0:
            create_title_slide(slide, order_data, theme)
        elif idx == total_slides - 1:
            create_final_slide(slide, theme)
        else:
            # SlaÃ½dyÅˆ temasyna gÃ¶rÃ¤ surat gÃ¶zlemek
            search_query = slide_data.get("search_query")
            image_stream = None
            
            if search_query:
                # âœ… TÃ¤ze gÃ¶zleg funksiÃ½asyny Ã§agyrÃ½arys
                image_stream = get_unique_image(search_query)

            if image_stream:
                # Surat tapyldy: Suratly slaÃ½d dizaÃ½ny
                create_content_slide_with_image(slide, slide_data, theme, image_stream)
                logger.info(f"âœ… SlaÃ½d {idx+1}: Web surat goÃ½uldy.")
            else:
                # Surat tapylmady: DiÅˆe tekstli slaÃ½d
                create_content_slide(slide, slide_data, theme)
                logger.warning(f"âš ï¸ SlaÃ½d {idx+1}: Surat tapylmady, diÅˆe tekst.")

    buffer = BytesIO()
    prs.save(buffer)
    buffer.seek(0)
    return buffer


# ============== AI FUNCTIONS ==============



def extend_content_to_required_pages(content: str, order_data: dict) -> str:
    """âœ… Extend content to EXACTLY match ordered pages - SIMPLE & ACCURATE"""
    
    work_type = order_data.get('work_type')
    pages = order_data['pages']
    
    # âœ… CALCULATE WORDS NEEDED
    if work_type == 'referat':
        # Title + TOC + References = 3 pages without content
        # So for 15 pages ordered â†’ need 12 pages of text
        content_pages = max(pages - 3, 1)
        words_per_page = 550
        required_words = content_pages * words_per_page
        
    elif work_type == 'kursovaya':
        # Title + Zadanie + TOC + References = 4 pages without content
        content_pages = max(pages - 4, 1)
        words_per_page = 550
        required_words = content_pages * words_per_page
        
    elif work_type == 'esse':
        # Title only = 1 page without content
        content_pages = max(pages - 1, 1)
        words_per_page = 450
        required_words = content_pages * words_per_page
        
    elif work_type == 'doklad':
        # No title page! All pages are content
        words_per_page = 450
        required_words = pages * words_per_page
        
    elif work_type == 'presentation':
        # Not applicable for presentations
        return content
        
    else:
        # Fallback
        words_per_page = 450
        required_words = pages * words_per_page
    
    current_words = len(content.split())
    
    logger.info(f"ğŸ“Š {work_type.upper()}: Current={current_words} words | Required={required_words} words | Pages={pages}")
    
    # âœ… CHECK IF OK
    tolerance = 0.1  # 10% tolerance
    min_acceptable = int(required_words * (1 - tolerance))
    max_acceptable = int(required_words * (1 + tolerance))
    
    if min_acceptable <= current_words <= max_acceptable:
        logger.info(f"âœ… Content is OK: {current_words} words (range: {min_acceptable}-{max_acceptable})")
        return content
    
    # âœ… TOO SHORT - EXTEND
    if current_words < min_acceptable:
        missing_words = required_words - current_words
        logger.warning(f"âš ï¸ TOO SHORT by {missing_words} words! Extending...")
        
        topic = order_data['topic']
        subject = order_data['subject']
        
        # âœ… Extensions (each â‰ˆ150 words)
        extensions = [
            f"""Ğ”ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ Ñ€Ğ°ÑÑĞ¼Ğ¾Ñ‚Ñ€ĞµĞ½Ğ¸Ğµ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹ {topic} Ñ‚Ñ€ĞµĞ±ÑƒĞµÑ‚ Ğ²ÑĞµÑÑ‚Ğ¾Ñ€Ğ¾Ğ½Ğ½ĞµĞ³Ğ¾ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° Ñ‚ĞµĞ¾Ñ€ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ¸ Ğ¿Ñ€Ğ°ĞºÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ°ÑĞ¿ĞµĞºÑ‚Ğ¾Ğ² Ğ² ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğµ {subject}. Ğ¡Ğ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚ Ğ¼Ğ½Ğ¾Ğ³Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ½Ğ¾ÑÑ‚ÑŒ Ğ´Ğ°Ğ½Ğ½Ğ¾Ğ¹ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ°Ñ‚Ğ¸ĞºĞ¸ Ğ¸ Ğ½ĞµĞ¾Ğ±Ñ…Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ ĞºĞ¾Ğ¼Ğ¿Ğ»ĞµĞºÑĞ½Ğ¾Ğ³Ğ¾ Ğ¼ĞµĞ¶Ğ´Ğ¸ÑÑ†Ğ¸Ğ¿Ğ»Ğ¸Ğ½Ğ°Ñ€Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´Ğ°. Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ½Ğ°ĞºĞ¾Ğ¿Ğ»ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ Ğ½Ğ°ÑƒÑ‡Ğ½Ğ¾Ğ³Ğ¾ Ğ·Ğ½Ğ°Ğ½Ğ¸Ñ Ğ¸ Ğ¿Ñ€Ğ°ĞºÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ Ğ¾Ğ¿Ñ‹Ñ‚Ğ° Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ğ²Ñ‹ÑĞ²Ğ¸Ñ‚ÑŒ ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ğµ Ğ·Ğ°ĞºĞ¾Ğ½Ğ¾Ğ¼ĞµÑ€Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¸ Ñ‚ĞµĞ½Ğ´ĞµĞ½Ñ†Ğ¸Ğ¸ Ñ€Ğ°Ğ·Ğ²Ğ¸Ñ‚Ğ¸Ñ. Ğ’Ğ°Ğ¶Ğ½Ğ¾ Ğ¾Ñ‚Ğ¼ĞµÑ‚Ğ¸Ñ‚ÑŒ, Ñ‡Ñ‚Ğ¾ Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ñ Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´Ğ¾Ğ² Ğ¾Ğ±ĞµÑĞ¿ĞµÑ‡Ğ¸Ğ²Ğ°ĞµÑ‚ Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ±Ğ¾Ğ»ĞµĞµ Ğ¿Ğ¾Ğ»Ğ½Ğ¾Ğ³Ğ¾ Ğ¸ Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ¾Ğ± Ğ¸Ğ·ÑƒÑ‡Ğ°ĞµĞ¼Ğ¾Ğ¼ ÑĞ²Ğ»ĞµĞ½Ğ¸Ğ¸.""",
            
            f"""ĞŸÑ€Ğ°ĞºÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ² Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¹ Ğ² Ğ¾Ğ±Ğ»Ğ°ÑÑ‚Ğ¸ {topic} Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ¸Ñ€ÑƒĞµÑ‚ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ½Ğ½Ñ‹Ñ… Ñ‚ĞµĞ¾Ñ€ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ¿Ğ¾Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğ¹ Ğ¸ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¹ Ğ² ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğµ {subject}. ĞĞ½Ğ°Ğ»Ğ¸Ğ· ĞºĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½Ñ‹Ñ… Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ¾Ğ² Ğ¸Ğ· Ğ¿Ñ€Ğ°ĞºÑ‚Ğ¸ĞºĞ¸ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ğ¿Ñ€Ğ¸ Ğ²Ğ½ĞµĞ´Ñ€ĞµĞ½Ğ¸Ğ¸ ÑĞ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ñ… Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´Ğ¾Ğ² Ğ¸ Ñ‚ĞµÑ…Ğ½Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ğ¹. ĞĞ±Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ Ğ¿Ñ€Ğ°ĞºÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ Ğ¾Ğ¿Ñ‹Ñ‚Ğ° ÑĞ¾Ğ·Ğ´Ğ°ĞµÑ‚ Ğ¾ÑĞ½Ğ¾Ğ²Ñƒ Ğ´Ğ»Ñ Ñ„Ğ¾Ñ€Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ğ¹ Ğ´Ğ°Ğ»ÑŒĞ½ĞµĞ¹ÑˆĞµĞ³Ğ¾ Ñ€Ğ°Ğ·Ğ²Ğ¸Ñ‚Ğ¸Ñ Ğ¸ ÑĞ¾Ğ²ĞµÑ€ÑˆĞµĞ½ÑÑ‚Ğ²Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ñ… Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ² Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹.""",
            
            f"""ĞœĞµÑ‚Ğ¾Ğ´Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ°ÑĞ¿ĞµĞºÑ‚Ñ‹ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ {topic} Ğ¸Ğ³Ñ€Ğ°ÑÑ‚ ĞºĞ»ÑÑ‡ĞµĞ²ÑƒÑ Ñ€Ğ¾Ğ»ÑŒ Ğ² Ğ¾Ğ±ĞµÑĞ¿ĞµÑ‡ĞµĞ½Ğ¸Ğ¸ Ğ½Ğ°ÑƒÑ‡Ğ½Ğ¾Ğ¹ ÑÑ‚Ñ€Ğ¾Ğ³Ğ¾ÑÑ‚Ğ¸ Ğ¸ Ğ´Ğ¾ÑÑ‚Ğ¾Ğ²ĞµÑ€Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼Ñ‹Ñ… Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ² Ğ² Ğ¾Ğ±Ğ»Ğ°ÑÑ‚Ğ¸ {subject}. Ğ’Ñ‹Ğ±Ğ¾Ñ€ Ğ°Ğ´ĞµĞºĞ²Ğ°Ñ‚Ğ½Ñ‹Ñ… Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ² Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµÑ‚ÑÑ ÑĞ¿ĞµÑ†Ğ¸Ñ„Ğ¸ĞºĞ¾Ğ¹ Ğ¸Ğ·ÑƒÑ‡Ğ°ĞµĞ¼Ğ¾Ğ³Ğ¾ Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ°, Ğ¿Ğ¾ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ½Ñ‹Ğ¼Ğ¸ Ñ†ĞµĞ»ÑĞ¼Ğ¸ Ğ¸ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ğ¼Ğ¸. ĞšĞ¾Ğ¼Ğ¿Ğ»ĞµĞºÑĞ½Ğ¾Ğµ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğµ Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ² Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ²ÑĞµÑÑ‚Ğ¾Ñ€Ğ¾Ğ½Ğ½ĞµĞµ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ¾ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğµ Ğ¸ Ğ¾Ğ±ĞµÑĞ¿ĞµÑ‡Ğ¸Ñ‚ÑŒ Ğ²Ñ‹ÑĞ¾ĞºĞ¾Ğµ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ.""",
            
            f"""Ğ¡Ñ€Ğ°Ğ²Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´Ğ¾Ğ² Ğº Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹ {topic} Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ğ²Ñ‹ÑĞ²Ğ¸Ñ‚ÑŒ Ğ¿Ñ€ĞµĞ¸Ğ¼ÑƒÑ‰ĞµÑÑ‚Ğ²Ğ° Ğ¸ Ğ½ĞµĞ´Ğ¾ÑÑ‚Ğ°Ñ‚ĞºĞ¸ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ° Ğ² ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğµ {subject}. Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ² ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ñ ÑĞ¾Ğ·Ğ´Ğ°ĞµÑ‚ Ğ¾ÑĞ½Ğ¾Ğ²Ñƒ Ğ´Ğ»Ñ Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾Ğ¹ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ğ¸, ÑƒÑ‡Ğ¸Ñ‚Ñ‹Ğ²Ğ°ÑÑ‰ĞµĞ¹ ÑĞ¿ĞµÑ†Ğ¸Ñ„Ğ¸ĞºÑƒ ĞºĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½Ñ‹Ñ… ÑƒÑĞ»Ğ¾Ğ²Ğ¸Ğ¹ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ñ. ĞšÑ€Ğ¸Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ° ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ñ… Ñ€ĞµÑˆĞµĞ½Ğ¸Ğ¹ ÑĞ¿Ğ¾ÑĞ¾Ğ±ÑÑ‚Ğ²ÑƒĞµÑ‚ Ñ„Ğ¾Ñ€Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ±Ğ¾Ğ»ĞµĞµ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ñ… Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´Ğ¾Ğ².""",
            
            f"""Ğ¢ĞµĞ¾Ñ€ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ Ğ¾ÑĞ¼Ñ‹ÑĞ»ĞµĞ½Ğ¸Ğµ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹ {topic} Ñ‚Ñ€ĞµĞ±ÑƒĞµÑ‚ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° Ñ„ÑƒĞ½Ğ´Ğ°Ğ¼ĞµĞ½Ñ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… ĞºĞ¾Ğ½Ñ†ĞµĞ¿Ñ†Ğ¸Ğ¹ Ğ¸ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´Ğ¾Ğ², Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ² Ñ€Ğ°Ğ¼ĞºĞ°Ñ… {subject}. Ğ˜Ğ·ÑƒÑ‡ĞµĞ½Ğ¸Ğµ ĞºĞ»Ğ°ÑÑĞ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ¸ ÑĞ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ñ… Ñ€Ğ°Ğ±Ğ¾Ñ‚ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ğ¿Ñ€Ğ¾ÑĞ»ĞµĞ´Ğ¸Ñ‚ÑŒ ÑĞ²Ğ¾Ğ»ÑÑ†Ğ¸Ñ Ğ½Ğ°ÑƒÑ‡Ğ½Ñ‹Ñ… Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğ¹ Ğ¸ Ğ²Ñ‹ÑĞ²Ğ¸Ñ‚ÑŒ Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ñ‹Ğµ Ñ‚ĞµĞ½Ğ´ĞµĞ½Ñ†Ğ¸Ğ¸ Ñ€Ğ°Ğ·Ğ²Ğ¸Ñ‚Ğ¸Ñ. ĞšÑ€Ğ¸Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ñ‚ĞµĞ¾Ñ€ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ¿Ğ¾ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ¸Ğ¹ ÑĞ¿Ğ¾ÑĞ¾Ğ±ÑÑ‚Ğ²ÑƒĞµÑ‚ ÑĞ¾Ğ²ĞµÑ€ÑˆĞµĞ½ÑÑ‚Ğ²Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ½Ğ°ÑƒÑ‡Ğ½Ğ¾Ğ³Ğ¾ Ğ·Ğ½Ğ°Ğ½Ğ¸Ñ Ğ¸ Ñ„Ğ¾Ñ€Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ±Ğ¾Ğ»ĞµĞµ Ğ°Ğ´ĞµĞºĞ²Ğ°Ñ‚Ğ½Ñ‹Ñ… Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğ¹.""",
            
            f"""ĞŸĞµÑ€ÑĞ¿ĞµĞºÑ‚Ğ¸Ğ²Ñ‹ Ğ´Ğ°Ğ»ÑŒĞ½ĞµĞ¹ÑˆĞµĞ³Ğ¾ Ñ€Ğ°Ğ·Ğ²Ğ¸Ñ‚Ğ¸Ñ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¹ Ğ² Ğ¾Ğ±Ğ»Ğ°ÑÑ‚Ğ¸ {topic} ÑĞ²ÑĞ·Ğ°Ğ½Ñ‹ Ñ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ĞµĞ½Ğ¸ĞµĞ¼ Ğ¸Ğ½Ğ½Ğ¾Ğ²Ğ°Ñ†Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ñ… Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´Ğ¾Ğ² Ğ² ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğµ {subject}. Ğ’Ğ½ĞµĞ´Ñ€ĞµĞ½Ğ¸Ğµ ÑĞ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ñ… Ñ‚ĞµÑ…Ğ½Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° Ğ¾Ñ‚ĞºÑ€Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ğµ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ´Ğ»Ñ ÑƒĞ³Ğ»ÑƒĞ±Ğ»ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¸Ğ·ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹. Ğ Ğ°Ğ·Ğ²Ğ¸Ñ‚Ğ¸Ğµ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒÑĞºĞ¾Ğ¹ Ğ±Ğ°Ğ·Ñ‹ ÑĞ¿Ğ¾ÑĞ¾Ğ±ÑÑ‚Ğ²ÑƒĞµÑ‚ Ğ¿Ğ¾Ğ²Ñ‹ÑˆĞµĞ½Ğ¸Ñ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ° Ğ¸ Ğ´Ğ¾ÑÑ‚Ğ¾Ğ²ĞµÑ€Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼Ñ‹Ñ… Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ²."""
        ]
        
        # âœ… Add needed extensions
        paragraphs_needed = (missing_words // 150) + 1
        added_extensions = []
        
        for i in range(min(paragraphs_needed, len(extensions) * 5)):
            ext_index = i % len(extensions)
            added_extensions.append(extensions[ext_index])
        
        extended_content = content + "\n\n" + "\n\n".join(added_extensions)
        
        final_words = len(extended_content.split())
        logger.info(f"âœ… Extended from {current_words} to {final_words} words")
        
        return extended_content
    
    # âœ… TOO LONG - TRIM
    else:
        logger.warning(f"âš ï¸ TOO LONG by {current_words - max_acceptable} words! Trimming...")
        
        paragraphs = content.split('\n\n')
        # Calculate percentage to keep
        keep_ratio = required_words / current_words
        target_para_count = int(len(paragraphs) * keep_ratio)
        
        trimmed_content = '\n\n'.join(paragraphs[:target_para_count])
        
        final_words = len(trimmed_content.split())
        logger.info(f"âœ… Trimmed from {current_words} to {final_words} words")
        
        return trimmed_content


def add_table_to_docx(doc, table_text):
    """Markdown tablisasyny professional 14 Pt Word tablisasyna Ã¶wÃ¼rÃ½Ã¤r"""
    try:
        raw_lines = table_text.strip().split('\n')
        lines = []
        for line in raw_lines:
            if '|' in line:
                if re.search(r'^[|\s:-]+$', line): continue
                cols = [c.strip() for c in line.split('|') if c.strip()]
                if cols: lines.append(cols)

        if len(lines) < 2: return

        num_rows = len(lines)
        num_cols = max(len(row) for row in lines)
        table = doc.add_table(rows=num_rows, cols=num_cols)
        table.style = 'Table Grid'
        table.alignment = WD_ALIGN_PARAGRAPH.CENTER

        for row_idx, row_data in enumerate(lines):
            row_cells = table.rows[row_idx].cells
            for col_idx, cell_value in enumerate(row_data):
                if col_idx < num_cols:
                    cell = row_cells[col_idx]
                    p = cell.paragraphs[0]
                    p.alignment = WD_ALIGN_PARAGRAPH.CENTER
                    run = p.add_run(cell_value)
                    run.font.name = 'Times New Roman'
                    run.font.size = Pt(14) # âœ… Tablisa 14 Pt

                    if row_idx == 0: # SÃ¶zbaÅŸy bezegi
                        run.bold = True
                        shading_elm = parse_xml(r'<w:shd {} w:fill="E7E6E6"/>'.format(nsdecls('w')))
                        cell._element.get_or_add_tcPr().append(shading_elm)
        doc.add_paragraph()
    except Exception as e:
        logger.error(f"Tablisa hatasy: {e}")

def insert_smart_content(doc, content):
    """Ã„hli tekstleri we media elementleri 14 Pt Times New Roman gÃ¶rnÃ¼ÅŸinde Ã½azÃ½ar"""
    parts = re.split(r'(\[IMAGE:.*?\]|\[SCHEMA:.*?\]|(?:\n|^)\|.*?\|.*?\|(?:\n|$))', content, flags=re.DOTALL)
    for part in parts:
        part = part.strip()
        if not part: continue
        if part.startswith('[IMAGE:'):
            q = part.replace('[IMAGE:', '').replace(']', '').strip()
            add_image_to_docx(doc, q)
        elif part.startswith('[SCHEMA:'):
            s = part.replace('[SCHEMA:', '').replace(']', '').strip()
            add_schema_placeholder(doc, s)
        elif '|' in part and '-' in part:
            add_table_to_docx(doc, part)
        else:
            paragraphs = part.split('\n')
            for para_text in paragraphs:
                if para_text.strip():
                    p = doc.add_paragraph()
                    p.alignment = WD_ALIGN_PARAGRAPH.JUSTIFY
                    p.paragraph_format.first_line_indent = Cm(1.25)
                    p.paragraph_format.line_spacing = Pt(18)
                    run = p.add_run(re.sub(r'[#\*_]', '', para_text.strip()))
                    run.font.size = Pt(14) # âœ… Adaty tekst 14 Pt
                    run.font.name = 'Times New Roman'

def add_image_to_docx(doc, query):
    """Internetden surat tapyp Word-a goÅŸÃ½ar"""
    image_stream = get_unique_image(query) # SiziÅˆ Ã¶Åˆki funksiÃ½aÅˆyz
    if image_stream:
        try:
            doc.add_picture(image_stream, width=Inches(5.5))
            last_p = doc.paragraphs[-1]
            last_p.alignment = WD_ALIGN_PARAGRAPH.CENTER
            # SuratyÅˆ aÅŸagyna dÃ¼ÅŸÃ¼ndiriÅŸ
            caption = doc.add_paragraph(f"Ğ Ğ¸ÑÑƒĞ½Ğ¾Ğº â€” {query}")
            caption.alignment = WD_ALIGN_PARAGRAPH.CENTER
            caption.font.italic = True
        except:
            pass

def add_schema_placeholder(doc, schema_desc):
    """Shemany owadan ramka we tekst hÃ¶kmÃ¼nde goÅŸÃ½ar"""
    table = doc.add_table(rows=1, cols=1)
    table.style = 'Light Shading Accent 1'
    cell = table.rows[0].cells[0]
    p = cell.paragraphs[0]
    p.alignment = WD_ALIGN_PARAGRAPH.CENTER
    run = p.add_run(f"Ğ›ĞĞ“Ğ˜Ğ§Ğ•Ğ¡ĞšĞĞ¯ Ğ¡Ğ¥Ğ•ĞœĞ:\n{schema_desc}")
    run.bold = True
    run.font.size = Pt(14)
    doc.add_paragraph()

def insert_smart_content(doc, content):
    """Teksti parse edip, media we 14 Pt tekstleri goÅŸÃ½ar"""
    parts = re.split(r'(\[IMAGE:.*?\]|\[SCHEMA:.*?\]|(?:\n|^)\|.*?\|.*?\|(?:\n|$))', content, flags=re.DOTALL)

    for part in parts:
        part = part.strip()
        if not part: continue

        if part.startswith('[IMAGE:'):
            q = part.replace('[IMAGE:', '').replace(']', '').strip()
            add_image_to_docx(doc, q)
        elif part.startswith('[SCHEMA:'):
            s = part.replace('[SCHEMA:', '').replace(']', '').strip()
            add_schema_placeholder(doc, s)
        elif '|' in part and '-' in part:
            add_table_to_docx(doc, part)
        else:
            paragraphs = part.split('\n')
            for para_text in paragraphs:
                if para_text.strip():
                    p = doc.add_paragraph()
                    p.alignment = WD_ALIGN_PARAGRAPH.JUSTIFY
                    p.paragraph_format.first_line_indent = Cm(1.25)
                    p.paragraph_format.line_spacing = Pt(18)
                    clean_text = re.sub(r'[#\*_]', '', para_text.strip())
                    run = p.add_run(clean_text)
                    run.font.size = Pt(14)  # âœ… Tekst 14 Pt
                    run.font.name = 'Times New Roman'

def add_page_numbers_referat(doc: Document):
    from docx.oxml import OxmlElement
    from docx.oxml.ns import qn
    
    sections = doc.sections
    first_section = sections[0]
    first_section.different_first_page_header_footer = True
    
    for section in sections:
        footer = section.footer
        
        for para in footer.paragraphs:
            para.clear()
        
        footer_para = footer.paragraphs[0] if footer.paragraphs else footer.add_paragraph()
        footer_para.alignment = WD_ALIGN_PARAGRAPH.CENTER
        
        run = footer_para.add_run()
        
        fldChar1 = OxmlElement('w:fldChar')
        fldChar1.set(qn('w:fldCharType'), 'begin')
        
        instrText = OxmlElement('w:instrText')
        instrText.set(qn('xml:space'), 'preserve')
        instrText.text = 'PAGE'
        
        fldChar2 = OxmlElement('w:fldChar')
        fldChar2.set(qn('w:fldCharType'), 'end')
        
        run._r.append(fldChar1)
        run._r.append(instrText)
        run._r.append(fldChar2)
        
        run.font.size = Pt(12)
        run.font.name = 'Times New Roman'

def parse_content_structure_referat(content: str, pages: int, order_data: dict) -> dict:
    structure = {"introduction": "", "chapters": [], "conclusion": "", "references": []}
    
    paragraphs = [p.strip() for p in content.split('\n\n') if p.strip()]
    total_paras = len(paragraphs)
    
    intro_count = max(3, int(total_paras * 0.12))
    chapter1_count = int(total_paras * 0.35)
    chapter2_count = int(total_paras * 0.35)
    conclusion_count = max(3, int(total_paras * 0.12))
    
    structure["introduction"] = "\n\n".join(paragraphs[:intro_count])
    
    current_pos = intro_count
    
    chapter1_paras = paragraphs[current_pos:current_pos + chapter1_count]
    subsection_size = len(chapter1_paras) // 4
    
    subsections1 = []
    for j in range(4):
        start = j * subsection_size
        end = start + subsection_size if j < 3 else len(chapter1_paras)
        subsection_text = "\n\n".join(chapter1_paras[start:end])
        
        if subsection_text:
            titles1 = ["ĞÑĞ½Ğ¾Ğ²Ğ½Ñ‹Ğµ Ğ¿Ğ¾Ğ½ÑÑ‚Ğ¸Ñ Ğ¸ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ñ", "Ğ˜ÑÑ‚Ğ¾Ñ€Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ°ÑĞ¿ĞµĞºÑ‚", "ĞšĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ Ğ¸ Ğ²Ğ¸Ğ´Ñ‹", "Ğ¡Ğ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´Ñ‹"]
            subsections1.append({
                "number": f"1.{j+1}",
                "title": titles1[j],
                "content": subsection_text
            })
    
    structure["chapters"].append({
        "number": 1,
        "title": "Ğ¢ĞµĞ¾Ñ€ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ¾ÑĞ½Ğ¾Ğ²Ñ‹",
        "subsections": subsections1
    })
    
    current_pos += chapter1_count
    
    chapter2_paras = paragraphs[current_pos:current_pos + chapter2_count]
    subsection_size2 = len(chapter2_paras) // 4
    
    subsections2 = []
    for j in range(4):
        start = j * subsection_size2
        end = start + subsection_size2 if j < 3 else len(chapter2_paras)
        subsection_text = "\n\n".join(chapter2_paras[start:end])
        
        if subsection_text:
            titles2 = ["Ğ¢ĞµĞºÑƒÑ‰ĞµĞµ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹", "ĞĞ½Ğ°Ğ»Ğ¸Ğ· ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ñ… Ñ€ĞµÑˆĞµĞ½Ğ¸Ğ¹", "Ğ¡Ñ€Ğ°Ğ²Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·", "ĞŸÑ€Ğ¸Ğ¼ĞµÑ€Ñ‹ Ğ¸Ğ· Ğ¿Ñ€Ğ°ĞºÑ‚Ğ¸ĞºĞ¸"]
            subsections2.append({
                "number": f"2.{j+1}",
                "title": titles2[j],
                "content": subsection_text
            })
    
    structure["chapters"].append({
        "number": 2,
        "title": "ĞŸÑ€Ğ°ĞºÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·",
        "subsections": subsections2
    })
    
    current_pos += chapter2_count
    
    structure["conclusion"] = "\n\n".join(paragraphs[current_pos:current_pos + conclusion_count])
    structure["references"] = generate_references(order_data, random.randint(8, 12))
    
    return structure

def calculate_actual_page_numbers(structure: dict, order_data: dict) -> dict:
    page_map = {}
    current_page = 1
    
    current_page += 1
    
    if order_data.get("zadanie_photo"):
        current_page += 1
    
    page_map["toc"] = current_page
    current_page += 1
    
    page_map["introduction"] = current_page
    intro_words = len(structure["introduction"].split())
    intro_pages = max(1, intro_words // 400)
    current_page += intro_pages
    
    page_map["chapters"] = {}
    for chapter in structure["chapters"]:
        chapter_num = chapter["number"]
        page_map["chapters"][chapter_num] = current_page
        
        chapter_words = 0
        for subsection in chapter["subsections"]:
            chapter_words += len(subsection["content"].split())
        
        chapter_pages = max(1, chapter_words // 400)
        current_page += chapter_pages
    
    page_map["conclusion"] = current_page
    concl_words = len(structure["conclusion"].split())
    concl_pages = max(1, concl_words // 400)
    current_page += concl_pages
    
    page_map["references"] = current_page
    
    return page_map

def create_toc_referat(doc: Document, structure: dict, order_data: dict):
    toc_header = doc.add_paragraph()
    toc_header.alignment = WD_ALIGN_PARAGRAPH.CENTER
    run = toc_header.add_run("Ğ¡ĞĞ”Ğ•Ğ Ğ–ĞĞĞ˜Ğ•")
    run.font.size = Pt(14)
    run.font.name = 'Times New Roman'
    run.bold = True
    toc_header.paragraph_format.space_after = Pt(18)
    toc_header.paragraph_format.space_before = Pt(0)
    
    doc.add_paragraph()
    
    page_map = calculate_actual_page_numbers(structure, order_data)
    
    toc_entries = []
    
    toc_entries.append(("Ğ’Ğ’Ğ•Ğ”Ğ•ĞĞ˜Ğ•", page_map["introduction"], False))
    
    for chapter in structure["chapters"]:
        chapter_num = chapter["number"]
        page_num = page_map["chapters"][chapter_num]
        
        toc_entries.append((f"Ğ“Ğ›ĞĞ’Ğ {chapter_num} {chapter['title'].upper()}", page_num, False))
        
        for subsection in chapter["subsections"]:
            toc_entries.append((f"{subsection['number']} {subsection['title']}", page_num, True))
    
    toc_entries.append(("Ğ—ĞĞšĞ›Ğ®Ğ§Ğ•ĞĞ˜Ğ•", page_map["conclusion"], False))
    toc_entries.append(("Ğ¡ĞŸĞ˜Ğ¡ĞĞš Ğ˜Ğ¡ĞŸĞĞ›Ğ¬Ğ—ĞĞ’ĞĞĞĞ«Ğ¥ Ğ˜Ğ¡Ğ¢ĞĞ§ĞĞ˜ĞšĞĞ’", page_map["references"], False))
    
    for title, page, is_subsection in toc_entries:
        p = doc.add_paragraph()
        p.paragraph_format.space_after = Pt(0)
        p.paragraph_format.line_spacing = Pt(18)
        
        if is_subsection:
            p.paragraph_format.left_indent = Cm(1.25)
        
        from docx.oxml import OxmlElement
        from docx.oxml.ns import qn
        
        tab_stops_element = p._element.get_or_add_pPr().get_or_add_tabs()
        tab_stop = OxmlElement('w:tab')
        tab_stop.set(qn('w:val'), 'right')
        tab_stop.set(qn('w:leader'), 'dot')
        tab_stop.set(qn('w:pos'), str(int(Cm(16.5).twips)))
        tab_stops_element.append(tab_stop)
        
        run_title = p.add_run(title)
        run_title.font.size = Pt(14)
        run_title.font.name = 'Times New Roman'
        
        if not is_subsection:
            run_title.font.bold = True
        
        p.add_run('\t')
        
        run_page = p.add_run(str(page))
        run_page.font.size = Pt(14)
        run_page.font.name = 'Times New Roman'
        
        if not is_subsection:
            run_page.font.bold = True

def create_document_referat(order_data: dict, content: str, lang: str) -> BytesIO:
    doc = Document()
    create_title_page(doc, order_data, lang)
    if order_data.get("zadanie_photo"): create_zadanie_page(doc, order_data)

    content = extend_content_to_required_pages(content, order_data)
    structure = parse_content_structure_referat(content, order_data["pages"], order_data)
    create_toc_referat(doc, structure, order_data)
    doc.add_page_break()

    # Ğ’Ğ’Ğ•Ğ”Ğ•ĞĞ˜Ğ•
    intro_h = doc.add_paragraph()
    intro_h.alignment = WD_ALIGN_PARAGRAPH.CENTER
    run = intro_h.add_run("Ğ’Ğ’Ğ•Ğ”Ğ•ĞĞ˜Ğ•")
    run.font.size = Pt(14) # âœ… 14 Pt
    run.font.name = 'Times New Roman'
    run.bold = True
    insert_smart_content(doc, structure["introduction"])
    doc.add_page_break()

    for chapter in structure["chapters"]:
        ch_header = doc.add_paragraph()
        ch_header.alignment = WD_ALIGN_PARAGRAPH.CENTER
        run = ch_header.add_run(f"Ğ“Ğ›ĞĞ’Ğ {chapter['number']} {chapter['title'].upper()}")
        run.font.size = Pt(14) # âœ… 14 Pt
        run.font.name = 'Times New Roman'
        run.bold = True
        
        for subsection in chapter["subsections"]:
            sub_h = doc.add_paragraph()
            sub_h.paragraph_format.left_indent = Cm(1.25)
            run = sub_h.add_run(f"{subsection['number']} {subsection['title']}")
            run.font.size = Pt(14) # âœ… 14 Pt
            run.font.name = 'Times New Roman'
            run.bold = True
            insert_smart_content(doc, subsection["content"])
        doc.add_page_break()

    concl_h = doc.add_paragraph()
    concl_h.alignment = WD_ALIGN_PARAGRAPH.CENTER
    run = concl_h.add_run("Ğ—ĞĞšĞ›Ğ®Ğ§Ğ•ĞĞ˜Ğ•")
    run.font.size = Pt(14) # âœ… 14 Pt
    run.font.name = 'Times New Roman'
    run.bold = True
    insert_smart_content(doc, structure["conclusion"])
    
    # Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ¾Ğ² (EÃ½Ã½Ã¤m kodyÅˆyzda bar, ÅŸol galybermeli)
    # ...
    add_page_numbers_referat(doc)
    buffer = BytesIO(); doc.save(buffer); buffer.seek(0)
    return buffer

# ============== ESSE FUNCTIONS ==============



def parse_content_structure_esse(content: str, pages: int, order_data: dict) -> dict:
    """âœ… ESSE structure"""
    structure = {"introduction": "", "main_part": "", "conclusion": "", "references": []}
    
    paragraphs = [p.strip() for p in content.split('\n\n') if p.strip()]
    total_paras = len(paragraphs)
    
    intro_count = max(2, int(total_paras * 0.15))
    main_count = int(total_paras * 0.70)
    conclusion_count = max(2, int(total_paras * 0.15))
    
    structure["introduction"] = "\n\n".join(paragraphs[:intro_count])
    structure["main_part"] = "\n\n".join(paragraphs[intro_count:intro_count + main_count])
    structure["conclusion"] = "\n\n".join(paragraphs[intro_count + main_count:intro_count + main_count + conclusion_count])
    structure["references"] = generate_references(order_data, random.randint(5, 8))
    
    return structure


def create_toc_esse(doc: Document, structure: dict, order_data: dict):
    """âœ… TOC for ESSE"""
    toc_header = doc.add_paragraph()
    toc_header.alignment = WD_ALIGN_PARAGRAPH.CENTER
    run = toc_header.add_run("Ğ¡ĞĞ”Ğ•Ğ Ğ–ĞĞĞ˜Ğ•")
    run.font.size = Pt(14)
    run.font.name = 'Times New Roman'
    run.bold = True
    toc_header.paragraph_format.space_after = Pt(18)
    
    doc.add_paragraph()
    
    current_page = 2
    toc_page = current_page
    current_page += 1
    
    intro_page = current_page
    intro_words = len(structure["introduction"].split())
    current_page += max(1, intro_words // 400)
    
    main_page = current_page
    main_words = len(structure["main_part"].split())
    current_page += max(1, main_words // 400)
    
    conclusion_page = current_page
    concl_words = len(structure["conclusion"].split())
    current_page += max(1, concl_words // 400)
    
    ref_page = current_page
    
    toc_entries = [
        ("Ğ’Ğ’Ğ•Ğ”Ğ•ĞĞ˜Ğ•", intro_page),
        ("ĞĞ¡ĞĞĞ’ĞĞĞ¯ Ğ§ĞĞ¡Ğ¢Ğ¬", main_page),
        ("Ğ—ĞĞšĞ›Ğ®Ğ§Ğ•ĞĞ˜Ğ•", conclusion_page),
        ("Ğ¡ĞŸĞ˜Ğ¡ĞĞš Ğ›Ğ˜Ğ¢Ğ•Ğ ĞĞ¢Ğ£Ğ Ğ«", ref_page)
    ]
    
    from docx.oxml import OxmlElement
    from docx.oxml.ns import qn
    
    for title, page in toc_entries:
        p = doc.add_paragraph()
        p.paragraph_format.space_after = Pt(0)
        p.paragraph_format.line_spacing = Pt(18)
        
        tab_stops_element = p._element.get_or_add_pPr().get_or_add_tabs()
        tab_stop = OxmlElement('w:tab')
        tab_stop.set(qn('w:val'), 'right')
        tab_stop.set(qn('w:leader'), 'dot')
        tab_stop.set(qn('w:pos'), str(int(Cm(16.5).twips)))
        tab_stops_element.append(tab_stop)
        
        run_title = p.add_run(title)
        run_title.font.size = Pt(14)
        run_title.font.name = 'Times New Roman'
        run_title.font.bold = True
        
        p.add_run('\t')
        
        run_page = p.add_run(str(page))
        run_page.font.size = Pt(14)
        run_page.font.name = 'Times New Roman'
        run_page.font.bold = True


def create_document_esse(order_data: dict, content: str, lang: str) -> BytesIO:
    """âœ… ESSE document"""
    doc = Document()
    
    for section in doc.sections:
        section.top_margin = Cm(2)
        section.bottom_margin = Cm(2)
        section.left_margin = Cm(3)
        section.right_margin = Cm(1.5)
    
    create_title_page(doc, order_data, lang)
    content = extend_content_to_required_pages(content, order_data)
    structure = parse_content_structure_esse(content, order_data["pages"], order_data)
    
    create_toc_esse(doc, structure, order_data)
    doc.add_page_break()
    
    # Ğ’Ğ’Ğ•Ğ”Ğ•ĞĞ˜Ğ•
    intro_header = doc.add_paragraph()
    intro_header.alignment = WD_ALIGN_PARAGRAPH.CENTER
    run = intro_header.add_run("Ğ’Ğ’Ğ•Ğ”Ğ•ĞĞ˜Ğ•")
    run.font.size = Pt(14)
    run.font.name = 'Times New Roman'
    run.bold = True
    intro_header.paragraph_format.space_after = Pt(18)
    
    for para_text in structure["introduction"].split('\n\n'):
        if para_text.strip():
            p = doc.add_paragraph()
            p.alignment = WD_ALIGN_PARAGRAPH.JUSTIFY
            p.paragraph_format.first_line_indent = Cm(1.25)
            p.paragraph_format.line_spacing = Pt(18)
            run = p.add_run(re.sub(r'[#\*_]', '', para_text.strip()))
            run.font.size = Pt(14)
            run.font.name = 'Times New Roman'
    
    doc.add_page_break()
    
    # ĞĞ¡ĞĞĞ’ĞĞĞ¯ Ğ§ĞĞ¡Ğ¢Ğ¬
    main_header = doc.add_paragraph()
    main_header.alignment = WD_ALIGN_PARAGRAPH.CENTER
    run = main_header.add_run("ĞĞ¡ĞĞĞ’ĞĞĞ¯ Ğ§ĞĞ¡Ğ¢Ğ¬")
    run.font.size = Pt(14)
    run.font.name = 'Times New Roman'
    run.bold = True
    main_header.paragraph_format.space_after = Pt(18)
    
    for para_text in structure["main_part"].split('\n\n'):
        if para_text.strip():
            p = doc.add_paragraph()
            p.alignment = WD_ALIGN_PARAGRAPH.JUSTIFY
            p.paragraph_format.first_line_indent = Cm(1.25)
            p.paragraph_format.line_spacing = Pt(18)
            run = p.add_run(re.sub(r'[#\*_]', '', para_text.strip()))
            run.font.size = Pt(14)
            run.font.name = 'Times New Roman'
    
    doc.add_page_break()
    
    # Ğ—ĞĞšĞ›Ğ®Ğ§Ğ•ĞĞ˜Ğ•
    concl_header = doc.add_paragraph()
    concl_header.alignment = WD_ALIGN_PARAGRAPH.CENTER
    run = concl_header.add_run("Ğ—ĞĞšĞ›Ğ®Ğ§Ğ•ĞĞ˜Ğ•")
    run.font.size = Pt(14)
    run.font.name = 'Times New Roman'
    run.bold = True
    concl_header.paragraph_format.space_after = Pt(18)
    
    for para_text in structure["conclusion"].split('\n\n'):
        if para_text.strip():
            p = doc.add_paragraph()
            p.alignment = WD_ALIGN_PARAGRAPH.JUSTIFY
            p.paragraph_format.first_line_indent = Cm(1.25)
            p.paragraph_format.line_spacing = Pt(18)
            run = p.add_run(re.sub(r'[#\*_]', '', para_text.strip()))
            run.font.size = Pt(14)
            run.font.name = 'Times New Roman'
    
    doc.add_page_break()
    
    # Ğ¡ĞŸĞ˜Ğ¡ĞĞš Ğ›Ğ˜Ğ¢Ğ•Ğ ĞĞ¢Ğ£Ğ Ğ«
    ref_header = doc.add_paragraph()
    ref_header.alignment = WD_ALIGN_PARAGRAPH.CENTER
    run = ref_header.add_run("Ğ¡ĞŸĞ˜Ğ¡ĞĞš Ğ›Ğ˜Ğ¢Ğ•Ğ ĞĞ¢Ğ£Ğ Ğ«")
    run.font.size = Pt(14)
    run.font.name = 'Times New Roman'
    run.bold = True
    ref_header.paragraph_format.space_after = Pt(18)
    
    for i, ref in enumerate(structure["references"], 1):
        p = doc.add_paragraph()
        p.alignment = WD_ALIGN_PARAGRAPH.JUSTIFY
        p.paragraph_format.left_indent = Cm(1.25)
        p.paragraph_format.first_line_indent = Cm(-1.25)
        p.paragraph_format.line_spacing = Pt(18)
        run = p.add_run(f"{i}. {ref}")
        run.font.size = Pt(14)
        run.font.name = 'Times New Roman'
    
    add_page_numbers_referat(doc)
    
    buffer = BytesIO()
    doc.save(buffer)
    buffer.seek(0)
    return buffer


# ============== DOKLAD FUNCTIONS ==============



def parse_content_structure_doklad(content: str, pages: int, order_data: dict) -> dict:
    """âœ… DOKLAD - 2 chapters"""
    structure = {"introduction": "", "chapters": [], "conclusion": "", "references": []}
    
    paragraphs = [p.strip() for p in content.split('\n\n') if p.strip()]
    total_paras = len(paragraphs)
    
    intro_count = max(2, int(total_paras * 0.10))
    chapter1_count = int(total_paras * 0.40)
    chapter2_count = int(total_paras * 0.40)
    conclusion_count = max(2, int(total_paras * 0.10))
    
    structure["introduction"] = "\n\n".join(paragraphs[:intro_count])
    
    current_pos = intro_count
    
    chapter1_paras = paragraphs[current_pos:current_pos + chapter1_count]
    structure["chapters"].append({
        "number": 1,
        "title": "Ğ¢ĞµĞ¾Ñ€ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ°ÑĞ¿ĞµĞºÑ‚Ñ‹",
        "content": "\n\n".join(chapter1_paras)
    })
    
    current_pos += chapter1_count
    
    chapter2_paras = paragraphs[current_pos:current_pos + chapter2_count]
    structure["chapters"].append({
        "number": 2,
        "title": "ĞŸÑ€Ğ°ĞºÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹",
        "content": "\n\n".join(chapter2_paras)
    })
    
    current_pos += chapter2_count
    
    structure["conclusion"] = "\n\n".join(paragraphs[current_pos:current_pos + conclusion_count])
    structure["references"] = generate_references(order_data, random.randint(6, 10))
    
    return structure


def create_toc_doklad(doc: Document, structure: dict, order_data: dict):
    """âœ… TOC for DOKLAD"""
    toc_header = doc.add_paragraph()
    toc_header.alignment = WD_ALIGN_PARAGRAPH.CENTER
    run = toc_header.add_run("Ğ¡ĞĞ”Ğ•Ğ Ğ–ĞĞĞ˜Ğ•")
    run.font.size = Pt(14)
    run.font.name = 'Times New Roman'
    run.bold = True
    toc_header.paragraph_format.space_after = Pt(18)
    
    doc.add_paragraph()
    
    current_page = 2
    current_page += 1
    
    intro_page = current_page
    intro_words = len(structure["introduction"].split())
    current_page += max(1, intro_words // 400)
    
    chapter_pages = {}
    for chapter in structure["chapters"]:
        chapter_pages[chapter["number"]] = current_page
        chapter_words = len(chapter["content"].split())
        current_page += max(1, chapter_words // 400)
    
    conclusion_page = current_page
    current_page += max(1, len(structure["conclusion"].split()) // 400)
    
    ref_page = current_page
    
    toc_entries = [("Ğ’Ğ’Ğ•Ğ”Ğ•ĞĞ˜Ğ•", intro_page, False)]
    
    for chapter in structure["chapters"]:
        toc_entries.append((f"{chapter['number']}. {chapter['title'].upper()}", chapter_pages[chapter['number']], False))
    
    toc_entries.append(("Ğ—ĞĞšĞ›Ğ®Ğ§Ğ•ĞĞ˜Ğ•", conclusion_page, False))
    toc_entries.append(("Ğ¡ĞŸĞ˜Ğ¡ĞĞš Ğ›Ğ˜Ğ¢Ğ•Ğ ĞĞ¢Ğ£Ğ Ğ«", ref_page, False))
    
    from docx.oxml import OxmlElement
    from docx.oxml.ns import qn
    
    for title, page, is_sub in toc_entries:
        p = doc.add_paragraph()
        p.paragraph_format.space_after = Pt(0)
        p.paragraph_format.line_spacing = Pt(18)
        
        tab_stops_element = p._element.get_or_add_pPr().get_or_add_tabs()
        tab_stop = OxmlElement('w:tab')
        tab_stop.set(qn('w:val'), 'right')
        tab_stop.set(qn('w:leader'), 'dot')
        tab_stop.set(qn('w:pos'), str(int(Cm(16.5).twips)))
        tab_stops_element.append(tab_stop)
        
        run_title = p.add_run(title)
        run_title.font.size = Pt(14)
        run_title.font.name = 'Times New Roman'
        run_title.font.bold = True
        
        p.add_run('\t')
        
        run_page = p.add_run(str(page))
        run_page.font.size = Pt(14)
        run_page.font.name = 'Times New Roman'
        run_page.font.bold = True


# ============== KURSOVAYA FUNCTIONS ==============

def generate_content_kursovaya(order_data: dict) -> Optional[str]:
    """âœ… Generate KURSOVAYA with GROQ ONLY"""
    
    try:
        logger.info("ğŸš€ Generating with GROQ...")
        url = "https://api.groq.com/openai/v1/chat/completions"
        
        pages = order_data['pages']
        total_words = pages * 500
        
        prompt = f"""ĞĞ°Ğ¿Ğ¸ÑˆĞ¸ Ğ¿Ğ¾Ğ´Ñ€Ğ¾Ğ±Ğ½ÑƒÑ ĞºÑƒÑ€ÑĞ¾Ğ²ÑƒÑ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñƒ Ğ½Ğ° Ñ‚ĞµĞ¼Ñƒ: "{order_data['topic']}"

ĞŸÑ€ĞµĞ´Ğ¼ĞµÑ‚: {order_data['subject']}
Ğ£Ğ½Ğ¸Ğ²ĞµÑ€ÑĞ¸Ñ‚ĞµÑ‚: {order_data['university']}

Ğ¡Ğ¢Ğ Ğ£ĞšĞ¢Ğ£Ğ Ğ (Ğ¼Ğ¸Ğ½Ğ¸Ğ¼ÑƒĞ¼ {total_words} ÑĞ»Ğ¾Ğ²):

Ğ’Ğ’Ğ•Ğ”Ğ•ĞĞ˜Ğ• (10%):
- ĞĞºÑ‚ÑƒĞ°Ğ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ñ‚ĞµĞ¼Ñ‹
- Ğ¦ĞµĞ»ÑŒ Ğ¸ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹
- ĞšÑ€Ğ°Ñ‚ĞºĞ¸Ğ¹ Ğ¾Ğ±Ğ·Ğ¾Ñ€ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñ‹

Ğ“Ğ›ĞĞ’Ğ 1. Ğ¢Ğ•ĞĞ Ğ•Ğ¢Ğ˜Ğ§Ğ•Ğ¡ĞšĞĞ¯ Ğ§ĞĞ¡Ğ¢Ğ¬ (30%):
1.1 Ğ¢ĞµĞ¾Ñ€ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ¾ÑĞ½Ğ¾Ğ²Ñ‹ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹
1.2 ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ½Ğ°ÑƒÑ‡Ğ½Ğ¾Ğ¹ Ğ»Ğ¸Ñ‚ĞµÑ€Ğ°Ñ‚ÑƒÑ€Ñ‹ Ğ¿Ğ¾ Ñ‚ĞµĞ¼Ğµ
1.3 ĞœĞµÑ‚Ğ¾Ğ´Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ñ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ

Ğ“Ğ›ĞĞ’Ğ 2. ĞŸĞ ĞĞšĞ¢Ğ˜Ğ§Ğ•Ğ¡ĞšĞĞ¯ Ğ§ĞĞ¡Ğ¢Ğ¬ (30%):
2.1 ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ñ‚ĞµĞºÑƒÑ‰ĞµĞ³Ğ¾ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ñ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹
2.2 Ğ’Ñ‹ÑĞ²Ğ»ĞµĞ½Ğ½Ñ‹Ğµ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹ Ğ¸ Ğ¸Ñ… Ğ¿Ñ€Ğ¸Ñ‡Ğ¸Ğ½Ñ‹
2.3 ĞŸÑ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ĞµĞ¼Ñ‹Ğµ Ğ¿ÑƒÑ‚Ğ¸ Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ

Ğ“Ğ›ĞĞ’Ğ 3. Ğ Ğ•Ğ—Ğ£Ğ›Ğ¬Ğ¢ĞĞ¢Ğ« Ğ˜ Ğ’Ğ«Ğ’ĞĞ”Ğ« (20%):
3.1 Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ
3.2 ĞŸÑ€Ğ°ĞºÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¸

Ğ—ĞĞšĞ›Ğ®Ğ§Ğ•ĞĞ˜Ğ• (10%):
- ĞÑĞ½Ğ¾Ğ²Ğ½Ñ‹Ğµ Ğ²Ñ‹Ğ²Ğ¾Ğ´Ñ‹
- Ğ”Ğ¾ÑÑ‚Ğ¸Ğ¶ĞµĞ½Ğ¸Ğµ Ğ¿Ğ¾ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ½Ğ¾Ğ¹ Ñ†ĞµĞ»Ğ¸
- ĞŸÑ€Ğ°ĞºÑ‚Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ

Ğ¢Ğ Ğ•Ğ‘ĞĞ’ĞĞĞ˜Ğ¯:
âœ… ĞœĞ¸Ğ½Ğ¸Ğ¼ÑƒĞ¼ {total_words} ÑĞ»Ğ¾Ğ²
âœ… Ğ‘Ğ•Ğ— Ğ·Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²ĞºĞ¾Ğ² Ğ² ÑĞ°Ğ¼Ğ¾Ğ¼ Ñ‚ĞµĞºÑÑ‚Ğµ
âœ… Ğ¢ĞĞ›Ğ¬ĞšĞ Ñ€ÑƒÑÑĞºĞ¸Ğ¹ ÑĞ·Ñ‹Ğº
âœ… Ğ‘Ğ•Ğ— ÑĞ¿Ğ¸ÑĞºĞ¾Ğ², Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ ÑĞ²ÑĞ·Ğ½Ñ‹Ğ¹ Ñ‚ĞµĞºÑÑ‚
âœ… ĞšĞ°Ğ¶Ğ´Ñ‹Ğ¹ Ğ°Ğ±Ğ·Ğ°Ñ† Ğ¼Ğ¸Ğ½Ğ¸Ğ¼ÑƒĞ¼ 5-7 Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğ¹
âœ… ĞĞºĞ°Ğ´ĞµĞ¼Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ ÑÑ‚Ğ¸Ğ»ÑŒ

ĞĞ°Ñ‡Ğ¸Ğ½Ğ°Ğ¹ Ğ¿Ğ¸ÑĞ°Ñ‚ÑŒ Ñ‚ĞµĞºÑÑ‚ ÑÑ€Ğ°Ğ·Ñƒ. Ğ Ğ°Ğ·Ğ´ĞµĞ»ÑĞ¹ Ñ‡Ğ°ÑÑ‚Ğ¸ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹ Ğ´Ğ²Ğ¾Ğ¹Ğ½Ñ‹Ğ¼ Ğ¿ĞµÑ€ĞµĞ²Ğ¾Ğ´Ğ¾Ğ¼ ÑÑ‚Ñ€Ğ¾ĞºĞ¸."""

        headers = {
            "Authorization": f"Bearer {GROQ_API_KEY}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "model": "llama-3.3-70b-versatile",
            "messages": [{"role": "user", "content": prompt}],
            "temperature": 0.85,
            "max_tokens": 16000,
            "top_p": 0.95
        }
        
        response = requests.post(url, json=payload, headers=headers, timeout=300)
        
        if response.status_code == 200:
            data = response.json()
            content = data["choices"][0]["message"]["content"]
            word_count = len(content.split())
            logger.info(f"âœ… Groq KURSOVAYA: {word_count} words")
            return content
        else:
            logger.error(f"âŒ Groq error: {response.status_code} - {response.text[:200]}")
            return None
            
    except Exception as e:
        logger.error(f"âŒ Groq exception: {e}")
        return None


def parse_content_structure_kursovaya(content: str, pages: int, order_data: dict) -> dict:
    """âœ… KURSOVAYA - 3 chapters with subsections"""
    structure = {"introduction": "", "chapters": [], "conclusion": "", "references": []}
    
    paragraphs = [p.strip() for p in content.split('\n\n') if p.strip()]
    total_paras = len(paragraphs)
    
    intro_count = max(3, int(total_paras * 0.10))
    chapter1_count = int(total_paras * 0.30)
    chapter2_count = int(total_paras * 0.30)
    chapter3_count = int(total_paras * 0.20)
    conclusion_count = max(3, int(total_paras * 0.10))
    
    structure["introduction"] = "\n\n".join(paragraphs[:intro_count])
    
    current_pos = intro_count
    
    # CHAPTER 1
    chapter1_paras = paragraphs[current_pos:current_pos + chapter1_count]
    subsection_size1 = len(chapter1_paras) // 3
    
    subsections1 = []
    titles1 = ["Ğ¢ĞµĞ¾Ñ€ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ¾ÑĞ½Ğ¾Ğ²Ñ‹", "ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ»Ğ¸Ñ‚ĞµÑ€Ğ°Ñ‚ÑƒÑ€Ñ‹", "ĞœĞµÑ‚Ğ¾Ğ´Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ñ"]
    for j in range(3):
        start = j * subsection_size1
        end = start + subsection_size1 if j < 2 else len(chapter1_paras)
        subsection_text = "\n\n".join(chapter1_paras[start:end])
        
        if subsection_text:
            subsections1.append({
                "number": f"1.{j+1}",
                "title": titles1[j],
                "content": subsection_text
            })
    
    structure["chapters"].append({
        "number": 1,
        "title": "Ğ¢ĞµĞ¾Ñ€ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ñ‡Ğ°ÑÑ‚ÑŒ",
        "subsections": subsections1
    })
    
    current_pos += chapter1_count
    
    # CHAPTER 2
    chapter2_paras = paragraphs[current_pos:current_pos + chapter2_count]
    subsection_size2 = len(chapter2_paras) // 3
    
    subsections2 = []
    titles2 = ["ĞĞ½Ğ°Ğ»Ğ¸Ğ· ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ñ", "Ğ’Ñ‹ÑĞ²Ğ»ĞµĞ½Ğ½Ñ‹Ğµ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹", "Ğ ĞµÑˆĞµĞ½Ğ¸Ñ"]
    for j in range(3):
        start = j * subsection_size2
        end = start + subsection_size2 if j < 2 else len(chapter2_paras)
        subsection_text = "\n\n".join(chapter2_paras[start:end])
        
        if subsection_text:
            subsections2.append({
                "number": f"2.{j+1}",
                "title": titles2[j],
                "content": subsection_text
            })
    
    structure["chapters"].append({
        "number": 2,
        "title": "ĞŸÑ€Ğ°ĞºÑ‚Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ñ‡Ğ°ÑÑ‚ÑŒ",
        "subsections": subsections2
    })
    
    current_pos += chapter2_count
    
    # CHAPTER 3
    chapter3_paras = paragraphs[current_pos:current_pos + chapter3_count]
    subsection_size3 = len(chapter3_paras) // 2
    
    subsections3 = []
    titles3 = ["Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹", "Ğ ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¸"]
    for j in range(2):
        start = j * subsection_size3
        end = start + subsection_size3 if j < 1 else len(chapter3_paras)
        subsection_text = "\n\n".join(chapter3_paras[start:end])
        
        if subsection_text:
            subsections3.append({
                "number": f"3.{j+1}",
                "title": titles3[j],
                "content": subsection_text
            })
    
    structure["chapters"].append({
        "number": 3,
        "title": "Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹",
        "subsections": subsections3
    })
    
    current_pos += chapter3_count
    
    structure["conclusion"] = "\n\n".join(paragraphs[current_pos:current_pos + conclusion_count])
    structure["references"] = generate_references(order_data, random.randint(15, 25))
    
    return structure


def create_toc_kursovaya(doc: Document, structure: dict, order_data: dict):
    """âœ… TOC for KURSOVAYA"""
    toc_header = doc.add_paragraph()
    toc_header.alignment = WD_ALIGN_PARAGRAPH.CENTER
    run = toc_header.add_run("Ğ¡ĞĞ”Ğ•Ğ Ğ–ĞĞĞ˜Ğ•")
    run.font.size = Pt(14)
    run.font.name = 'Times New Roman'
    run.bold = True
    toc_header.paragraph_format.space_after = Pt(18)
    
    doc.add_paragraph()
    
    current_page = 2
    
    if order_data.get("zadanie_photo"):
        current_page += 1
    
    current_page += 1
    
    intro_page = current_page
    intro_words = len(structure["introduction"].split())
    current_page += max(1, intro_words // 400)
    
    toc_entries = [("Ğ’Ğ’Ğ•Ğ”Ğ•ĞĞ˜Ğ•", intro_page, False)]
    
    for chapter in structure["chapters"]:
        chapter_page = current_page
        toc_entries.append((f"Ğ“Ğ›ĞĞ’Ğ {chapter['number']}. {chapter['title'].upper()}", chapter_page, False))
        
        for subsection in chapter["subsections"]:
            toc_entries.append((f"{subsection['number']} {subsection['title']}", chapter_page, True))
        
        chapter_words = sum(len(sub["content"].split()) for sub in chapter["subsections"])
        current_page += max(1, chapter_words // 400)
    
    conclusion_page = current_page
    current_page += max(1, len(structure["conclusion"].split()) // 400)
    
    ref_page = current_page
    
    toc_entries.append(("Ğ—ĞĞšĞ›Ğ®Ğ§Ğ•ĞĞ˜Ğ•", conclusion_page, False))
    toc_entries.append(("Ğ¡ĞŸĞ˜Ğ¡ĞĞš Ğ˜Ğ¡ĞŸĞĞ›Ğ¬Ğ—ĞĞ’ĞĞĞĞ«Ğ¥ Ğ˜Ğ¡Ğ¢ĞĞ§ĞĞ˜ĞšĞĞ’", ref_page, False))
    
    from docx.oxml import OxmlElement
    from docx.oxml.ns import qn
    
    for title, page, is_subsection in toc_entries:
        p = doc.add_paragraph()
        p.paragraph_format.space_after = Pt(0)
        p.paragraph_format.line_spacing = Pt(18)
        
        if is_subsection:
            p.paragraph_format.left_indent = Cm(1.25)
        
        tab_stops_element = p._element.get_or_add_pPr().get_or_add_tabs()
        tab_stop = OxmlElement('w:tab')
        tab_stop.set(qn('w:val'), 'right')
        tab_stop.set(qn('w:leader'), 'dot')
        tab_stop.set(qn('w:pos'), str(int(Cm(16.5).twips)))
        tab_stops_element.append(tab_stop)
        
        run_title = p.add_run(title)
        run_title.font.size = Pt(14)
        run_title.font.name = 'Times New Roman'
        
        if not is_subsection:
            run_title.font.bold = True
        
        p.add_run('\t')
        
        run_page = p.add_run(str(page))
        run_page.font.size = Pt(14)
        run_page.font.name = 'Times New Roman'
        
        if not is_subsection:
            run_page.font.bold = True


def create_document_kursovaya(order_data: dict, content: str, lang: str) -> BytesIO:
    doc = Document()
    create_title_page(doc, order_data, lang)
    if order_data.get("zadanie_photo"): create_zadanie_page(doc, order_data)
    
    content = extend_content_to_required_pages(content, order_data)
    structure = parse_content_structure_kursovaya(content, order_data["pages"], order_data)
    create_toc_kursovaya(doc, structure, order_data)
    doc.add_page_break()

    # --- BÃ–LÃœMLER (14 Pt Bold Headers) ---
    sections = [("introduction", "Ğ’Ğ’Ğ•Ğ”Ğ•ĞĞ˜Ğ•")] + \
               [(ch, f"Ğ“Ğ›ĞĞ’Ğ {ch['number']}. {ch['title'].upper()}") for ch in structure["chapters"]] + \
               [("conclusion", "Ğ—ĞĞšĞ›Ğ®Ğ§Ğ•ĞĞ˜Ğ•")]

    for key, title in sections:
        h = doc.add_paragraph()
        h.alignment = WD_ALIGN_PARAGRAPH.CENTER
        run = h.add_run(title)
        run.font.size = Pt(14) # âœ… BaÅŸlyk 14 Pt
        run.font.name = 'Times New Roman'
        run.bold = True
        
        if key == "introduction":
            insert_smart_content(doc, structure["introduction"])
        elif key == "conclusion":
            insert_smart_content(doc, structure["conclusion"])
        else: # Chapters
            for sub in key["subsections"]:
                sh = doc.add_paragraph()
                sh.paragraph_format.left_indent = Cm(1.25)
                run_sub = sh.add_run(f"{sub['number']} {sub['title']}")
                run_sub.font.size = Pt(14) # âœ… Podrazdel 14 Pt
                run_sub.font.name = 'Times New Roman'
                run_sub.bold = True
                insert_smart_content(doc, sub["content"])
        doc.add_page_break()

    # Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº Ğ»Ğ¸Ñ‚ĞµÑ€Ğ°Ñ‚ÑƒÑ€Ñ‹ (14 Pt)
    ref_h = doc.add_paragraph()
    ref_h.alignment = WD_ALIGN_PARAGRAPH.CENTER
    run = ref_h.add_run("Ğ¡ĞŸĞ˜Ğ¡ĞĞš Ğ˜Ğ¡ĞŸĞĞ›Ğ¬Ğ—ĞĞ’ĞĞĞĞ«Ğ¥ Ğ˜Ğ¡Ğ¢ĞĞ§ĞĞ˜ĞšĞĞ’")
    run.font.size = Pt(14); run.font.bold = True; run.font.name = 'Times New Roman'
    for i, ref in enumerate(structure["references"], 1):
        p = doc.add_paragraph()
        run = p.add_run(f"{i}. {ref}")
        run.font.size = Pt(14); run.font.name = 'Times New Roman'
    
    add_page_numbers_referat(doc)
    buffer = BytesIO(); doc.save(buffer); buffer.seek(0)
    return buffer



def parse_content_structure_esse(content: str, pages: int, order_data: dict) -> dict:
    """âœ… ESSE - NO intro/conclusion/references structure"""
    structure = {"main_content": content}  # Ğ’ĞµÑÑŒ Ñ‚ĞµĞºÑÑ‚ - ÑÑ‚Ğ¾ Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ğ°Ñ Ñ‡Ğ°ÑÑ‚ÑŒ
    return structure


def create_document_esse(order_data: dict, content: str, lang: str) -> BytesIO:
    """âœ… ESSE document - Ğ‘Ğ•Ğ— TOC, Ğ‘Ğ•Ğ— Ğ²Ğ²ĞµĞ´ĞµĞ½Ğ¸Ñ/Ğ·Ğ°ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ñ/ÑĞ¿Ğ¸ÑĞºĞ°"""
    doc = Document()
    
    for section in doc.sections:
        section.top_margin = Cm(2)
        section.bottom_margin = Cm(2)
        section.left_margin = Cm(3)
        section.right_margin = Cm(1.5)
    
    # Title page
    create_title_page(doc, order_data, lang)
    
    # Extend content
    content = extend_content_to_required_pages(content, order_data)
    
    # NO TOC, NO structure parsing
    # Just write the content directly
    
    paragraphs = content.split('\n\n')
    for para_text in paragraphs:
        if para_text.strip():
            p = doc.add_paragraph()
            p.alignment = WD_ALIGN_PARAGRAPH.JUSTIFY
            p.paragraph_format.first_line_indent = Cm(1.25)
            p.paragraph_format.line_spacing = Pt(18)
            p.paragraph_format.space_after = Pt(0)
            
            clean_text = re.sub(r'[#\*_]', '', para_text.strip())
            run = p.add_run(clean_text)
            run.font.size = Pt(14)
            run.font.name = 'Times New Roman'
    
    # Page numbers
    add_page_numbers_referat(doc)
    
    buffer = BytesIO()
    doc.save(buffer)
    buffer.seek(0)
    return buffer


def create_toc_esse(doc: Document, structure: dict, order_data: dict):
    """âœ… TOC for ESSE"""
    
    toc_header = doc.add_paragraph()
    toc_header.alignment = WD_ALIGN_PARAGRAPH.CENTER
    run = toc_header.add_run("Ğ¡ĞĞ”Ğ•Ğ Ğ–ĞĞĞ˜Ğ•")
    run.font.size = Pt(14)
    run.font.name = 'Times New Roman'
    run.bold = True
    toc_header.paragraph_format.space_after = Pt(18)
    toc_header.paragraph_format.space_before = Pt(0)
    
    doc.add_paragraph()
    
    # Calculate pages
    current_page = 2  # After title
    
    toc_page = current_page
    current_page += 1
    
    intro_page = current_page
    intro_words = len(structure["introduction"].split())
    current_page += max(1, intro_words // 400)
    
    main_page = current_page
    main_words = len(structure["main_part"].split())
    current_page += max(1, main_words // 400)
    
    conclusion_page = current_page
    concl_words = len(structure["conclusion"].split())
    current_page += max(1, concl_words // 400)
    
    ref_page = current_page
    
    toc_entries = [
        ("Ğ’Ğ’Ğ•Ğ”Ğ•ĞĞ˜Ğ•", intro_page),
        ("ĞĞ¡ĞĞĞ’ĞĞĞ¯ Ğ§ĞĞ¡Ğ¢Ğ¬", main_page),
        ("Ğ—ĞĞšĞ›Ğ®Ğ§Ğ•ĞĞ˜Ğ•", conclusion_page),
        ("Ğ¡ĞŸĞ˜Ğ¡ĞĞš Ğ›Ğ˜Ğ¢Ğ•Ğ ĞĞ¢Ğ£Ğ Ğ«", ref_page)
    ]
    
    for title, page in toc_entries:
        p = doc.add_paragraph()
        p.paragraph_format.space_after = Pt(0)
        p.paragraph_format.line_spacing = Pt(18)
        
        from docx.oxml import OxmlElement
        from docx.oxml.ns import qn
        
        tab_stops_element = p._element.get_or_add_pPr().get_or_add_tabs()
        tab_stop = OxmlElement('w:tab')
        tab_stop.set(qn('w:val'), 'right')
        tab_stop.set(qn('w:leader'), 'dot')
        tab_stop.set(qn('w:pos'), str(int(Cm(16.5).twips)))
        tab_stops_element.append(tab_stop)
        
        run_title = p.add_run(title)
        run_title.font.size = Pt(14)
        run_title.font.name = 'Times New Roman'
        run_title.font.bold = True
        
        p.add_run('\t')
        
        run_page = p.add_run(str(page))
        run_page.font.size = Pt(14)
        run_page.font.name = 'Times New Roman'
        run_page.font.bold = True

def parse_content_structure_doklad(content: str, pages: int, order_data: dict) -> dict:
    """âœ… DOKLAD - simple 2-part structure, NO intro/conclusion"""
    structure = {"parts": []}
    
    paragraphs = [p.strip() for p in content.split('\n\n') if p.strip()]
    
    # Split into 2 equal parts
    mid_point = len(paragraphs) // 2
    
    structure["parts"].append({
        "title": "Ğ¢Ğ•ĞĞ Ğ•Ğ¢Ğ˜Ğ§Ğ•Ğ¡ĞšĞĞ¯ Ğ§ĞĞ¡Ğ¢Ğ¬",
        "content": "\n\n".join(paragraphs[:mid_point])
    })
    
    structure["parts"].append({
        "title": "ĞŸĞ ĞĞšĞ¢Ğ˜Ğ§Ğ•Ğ¡ĞšĞĞ¯ Ğ§ĞĞ¡Ğ¢Ğ¬",
        "content": "\n\n".join(paragraphs[mid_point:])
    })
    
    return structure


def create_document_doklad(order_data: dict, content: str, lang: str) -> BytesIO:
    """âœ… DOKLAD - Ğ‘Ğ•Ğ— Ñ‚Ğ¸Ñ‚ÑƒĞ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ»Ğ¸ÑÑ‚Ğ°, header ÑĞ¿Ñ€Ğ°Ğ²Ğ° + Ñ‚ĞµĞ¼Ğ° Ğ¿Ğ¾ Ñ†ĞµĞ½Ñ‚Ñ€Ñƒ"""
    doc = Document()
    
    for section in doc.sections:
        section.top_margin = Cm(2)
        section.bottom_margin = Cm(2)
        section.left_margin = Cm(3)
        section.right_margin = Cm(1.5)
    
    # âœ… NO TITLE PAGE! Start with header
    
    # âœ… HEADER - Ãokarda sagda FIO + Ğ³Ñ€ÑƒĞ¿Ğ¿Ğ°
    header_para = doc.add_paragraph()
    header_para.alignment = WD_ALIGN_PARAGRAPH.RIGHT
    run = header_para.add_run(f"{order_data['fullname']}\nĞ³Ñ€ÑƒĞ¿Ğ¿Ğ° {order_data['group']}")
    run.font.size = Pt(12)
    run.font.name = 'Times New Roman'
    header_para.paragraph_format.space_after = Pt(24)
    
    # âœ… TEMA - Ortada
    topic_para = doc.add_paragraph()
    topic_para.alignment = WD_ALIGN_PARAGRAPH.CENTER
    run = topic_para.add_run(order_data['topic'])
    run.font.size = Pt(16)
    run.font.name = 'Times New Roman'
    run.bold = True
    topic_para.paragraph_format.space_after = Pt(24)
    
    # âœ… CONTENT - Extend
    content = extend_content_to_required_pages(content, order_data)
    
    structure = parse_content_structure_doklad(content, order_data["pages"], order_data)
    
    # âœ… Write parts
    for part in structure["parts"]:
        # Part header
        part_header = doc.add_paragraph()
        part_header.alignment = WD_ALIGN_PARAGRAPH.CENTER
        run = part_header.add_run(part["title"])
        run.font.size = Pt(14)
        run.font.name = 'Times New Roman'
        run.bold = True
        part_header.paragraph_format.space_before = Pt(18)
        part_header.paragraph_format.space_after = Pt(18)
        
        # Part content
        paragraphs = part["content"].split('\n\n')
        for para_text in paragraphs:
            if para_text.strip():
                p = doc.add_paragraph()
                p.alignment = WD_ALIGN_PARAGRAPH.JUSTIFY
                p.paragraph_format.first_line_indent = Cm(1.25)
                p.paragraph_format.line_spacing = Pt(18)
                p.paragraph_format.space_after = Pt(0)
                
                clean_text = re.sub(r'[#\*_]', '', para_text.strip())
                run = p.add_run(clean_text)
                run.font.size = Pt(14)
                run.font.name = 'Times New Roman'
    
    # âœ… Page numbers
    add_page_numbers_referat(doc)
    
    buffer = BytesIO()
    doc.save(buffer)
    buffer.seek(0)
    return buffer


def create_toc_doklad(doc: Document, structure: dict, order_data: dict):
    """âœ… TOC for DOKLAD"""
    
    toc_header = doc.add_paragraph()
    toc_header.alignment = WD_ALIGN_PARAGRAPH.CENTER
    run = toc_header.add_run("Ğ¡ĞĞ”Ğ•Ğ Ğ–ĞĞĞ˜Ğ•")
    run.font.size = Pt(14)
    run.font.name = 'Times New Roman'
    run.bold = True
    toc_header.paragraph_format.space_after = Pt(18)
    toc_header.paragraph_format.space_before = Pt(0)
    
    doc.add_paragraph()
    
    current_page = 2
    toc_page = current_page
    current_page += 1
    
    intro_page = current_page
    intro_words = len(structure["introduction"].split())
    current_page += max(1, intro_words // 400)
    
    chapter_pages = {}
    for chapter in structure["chapters"]:
        chapter_pages[chapter["number"]] = current_page
        chapter_words = len(chapter["content"].split())
        current_page += max(1, chapter_words // 400)
    
    conclusion_page = current_page
    concl_words = len(structure["conclusion"].split())
    current_page += max(1, concl_words // 400)
    
    ref_page = current_page
    
    toc_entries = [("Ğ’Ğ’Ğ•Ğ”Ğ•ĞĞ˜Ğ•", intro_page, False)]
    
    for chapter in structure["chapters"]:
        toc_entries.append((f"{chapter['number']}. {chapter['title'].upper()}", chapter_pages[chapter['number']], False))
    
    toc_entries.append(("Ğ—ĞĞšĞ›Ğ®Ğ§Ğ•ĞĞ˜Ğ•", conclusion_page, False))
    toc_entries.append(("Ğ¡ĞŸĞ˜Ğ¡ĞĞš Ğ›Ğ˜Ğ¢Ğ•Ğ ĞĞ¢Ğ£Ğ Ğ«", ref_page, False))
    
    for title, page, is_sub in toc_entries:
        p = doc.add_paragraph()
        p.paragraph_format.space_after = Pt(0)
        p.paragraph_format.line_spacing = Pt(18)
        
        from docx.oxml import OxmlElement
        from docx.oxml.ns import qn
        
        tab_stops_element = p._element.get_or_add_pPr().get_or_add_tabs()
        tab_stop = OxmlElement('w:tab')
        tab_stop.set(qn('w:val'), 'right')
        tab_stop.set(qn('w:leader'), 'dot')
        tab_stop.set(qn('w:pos'), str(int(Cm(16.5).twips)))
        tab_stops_element.append(tab_stop)
        
        run_title = p.add_run(title)
        run_title.font.size = Pt(14)
        run_title.font.name = 'Times New Roman'
        run_title.font.bold = True
        
        p.add_run('\t')
        
        run_page = p.add_run(str(page))
        run_page.font.size = Pt(14)
        run_page.font.name = 'Times New Roman'
        run_page.font.bold = True

def extend_content_if_short(content: str, order_data: dict) -> str:
    words = len(content.split())
    required_words = order_data['pages'] * 350
    
    logger.info(f"Content: {words} words, required: {required_words}")
    
    if words < required_words:
        logger.warning("Content too short! Extending...")
        extensions = f"""

Ğ”ĞĞŸĞĞ›ĞĞ˜Ğ¢Ğ•Ğ›Ğ¬ĞĞ«Ğ™ ĞĞĞĞ›Ğ˜Ğ—

Ğ Ğ°ÑÑĞ¼Ğ°Ñ‚Ñ€Ğ¸Ğ²Ğ°Ñ Ğ´Ğ°Ğ½Ğ½ÑƒÑ Ñ‚ĞµĞ¼Ñƒ Ğ±Ğ¾Ğ»ĞµĞµ Ğ¿Ğ¾Ğ´Ñ€Ğ¾Ğ±Ğ½Ğ¾, Ğ½ĞµĞ¾Ğ±Ñ…Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ Ğ¾Ñ‚Ğ¼ĞµÑ‚Ğ¸Ñ‚ÑŒ ÑĞ»ĞµĞ´ÑƒÑÑ‰Ğ¸Ğµ Ğ°ÑĞ¿ĞµĞºÑ‚Ñ‹. 
{order_data['topic']} ÑĞ²Ğ»ÑĞµÑ‚ÑÑ ĞºĞ¾Ğ¼Ğ¿Ğ»ĞµĞºÑĞ½Ğ¾Ğ¹ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ¾Ğ¹, Ñ‚Ñ€ĞµĞ±ÑƒÑÑ‰ĞµĞ¹ Ğ²ÑĞµÑÑ‚Ğ¾Ñ€Ğ¾Ğ½Ğ½ĞµĞ³Ğ¾ Ğ¸Ğ·ÑƒÑ‡ĞµĞ½Ğ¸Ñ.

ĞœĞ•Ğ¢ĞĞ”ĞĞ›ĞĞ“Ğ˜Ğ§Ğ•Ğ¡ĞšĞ˜Ğ• ĞĞ¡ĞĞĞ’Ğ«

ĞŸÑ€Ğ¸ Ğ¸Ğ·ÑƒÑ‡ĞµĞ½Ğ¸Ğ¸ Ñ‚ĞµĞ¼Ñ‹ {order_data['topic']} Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ÑÑÑ‚ÑÑ Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ğµ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ.
Ğ¢ĞµĞ¾Ñ€ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹ Ğ²ĞºĞ»ÑÑ‡Ğ°ÑÑ‚ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·, ÑĞ¸Ğ½Ñ‚ĞµĞ·, Ğ¾Ğ±Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ Ğ¸ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹.

ĞŸĞ ĞĞšĞ¢Ğ˜Ğ§Ğ•Ğ¡ĞšĞĞ• ĞŸĞ Ğ˜ĞœĞ•ĞĞ•ĞĞ˜Ğ•

Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¹ Ğ² Ğ¾Ğ±Ğ»Ğ°ÑÑ‚Ğ¸ {order_data['subject']} Ğ½Ğ°Ñ…Ğ¾Ğ´ÑÑ‚ ÑˆĞ¸Ñ€Ğ¾ĞºĞ¾Ğµ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğµ Ğ½Ğ° Ğ¿Ñ€Ğ°ĞºÑ‚Ğ¸ĞºĞµ.
Ğ’Ğ½ĞµĞ´Ñ€ĞµĞ½Ğ¸Ğµ ÑĞ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ñ… Ñ‚ĞµÑ…Ğ½Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ğ¹ Ğ¸ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ² Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ğ¿Ğ¾Ğ²Ñ‹ÑĞ¸Ñ‚ÑŒ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹."""
        content += extensions
    
    return content



def parse_content_structure_kursovaya(content: str, pages: int, order_data: dict) -> dict:
    """âœ… KURSOVAYA - detailed 3-chapter structure"""
    
    structure = {"introduction": "", "chapters": [], "conclusion": "", "references": []}
    
    paragraphs = [p.strip() for p in content.split('\n\n') if p.strip()]
    total_paras = len(paragraphs)
    
    intro_count = max(3, int(total_paras * 0.10))
    chapter1_count = int(total_paras * 0.30)
    chapter2_count = int(total_paras * 0.30)
    chapter3_count = int(total_paras * 0.20)
    conclusion_count = max(3, int(total_paras * 0.10))
    
    structure["introduction"] = "\n\n".join(paragraphs[:intro_count])
    
    current_pos = intro_count
    
    # CHAPTER 1 - Theory
    chapter1_paras = paragraphs[current_pos:current_pos + chapter1_count]
    subsection_size1 = len(chapter1_paras) // 3
    
    subsections1 = []
    for j in range(3):
        start = j * subsection_size1
        end = start + subsection_size1 if j < 2 else len(chapter1_paras)
        subsection_text = "\n\n".join(chapter1_paras[start:end])
        
        if subsection_text:
            titles1 = ["Ğ¢ĞµĞ¾Ñ€ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ¾ÑĞ½Ğ¾Ğ²Ñ‹", "ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ»Ğ¸Ñ‚ĞµÑ€Ğ°Ñ‚ÑƒÑ€Ñ‹", "ĞœĞµÑ‚Ğ¾Ğ´Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ñ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ"]
            subsections1.append({
                "number": f"1.{j+1}",
                "title": titles1[j],
                "content": subsection_text
            })
    
    structure["chapters"].append({
        "number": 1,
        "title": "Ğ¢ĞµĞ¾Ñ€ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ñ‡Ğ°ÑÑ‚ÑŒ",
        "subsections": subsections1
    })
    
    current_pos += chapter1_count
    
    # CHAPTER 2 - Practice
    chapter2_paras = paragraphs[current_pos:current_pos + chapter2_count]
    subsection_size2 = len(chapter2_paras) // 3
    
    subsections2 = []
    for j in range(3):
        start = j * subsection_size2
        end = start + subsection_size2 if j < 2 else len(chapter2_paras)
        subsection_text = "\n\n".join(chapter2_paras[start:end])
        
        if subsection_text:
            titles2 = ["ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ñ‚ĞµĞºÑƒÑ‰ĞµĞ³Ğ¾ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ñ", "Ğ’Ñ‹ÑĞ²Ğ»ĞµĞ½Ğ½Ñ‹Ğµ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹", "ĞŸÑ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ĞµĞ¼Ñ‹Ğµ Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ"]
            subsections2.append({
                "number": f"2.{j+1}",
                "title": titles2[j],
                "content": subsection_text
            })
    
    structure["chapters"].append({
        "number": 2,
        "title": "ĞŸÑ€Ğ°ĞºÑ‚Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ñ‡Ğ°ÑÑ‚ÑŒ",
        "subsections": subsections2
    })
    
    current_pos += chapter2_count
    
    # CHAPTER 3 - Results
    chapter3_paras = paragraphs[current_pos:current_pos + chapter3_count]
    subsection_size3 = len(chapter3_paras) // 2
    
    subsections3 = []
    for j in range(2):
        start = j * subsection_size3
        end = start + subsection_size3 if j < 1 else len(chapter3_paras)
        subsection_text = "\n\n".join(chapter3_paras[start:end])
        
        if subsection_text:
            titles3 = ["Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ", "Ğ ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¸ Ğ¸ Ğ²Ñ‹Ğ²Ğ¾Ğ´Ñ‹"]
            subsections3.append({
                "number": f"3.{j+1}",
                "title": titles3[j],
                "content": subsection_text
            })
    
    structure["chapters"].append({
        "number": 3,
        "title": "Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ¸ Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¸",
        "subsections": subsections3
    })
    
    current_pos += chapter3_count
    
    structure["conclusion"] = "\n\n".join(paragraphs[current_pos:current_pos + conclusion_count])
    structure["references"] = generate_references(order_data, random.randint(15, 25))
    
    return structure


def create_document_kursovaya(order_data: dict, content: str, lang: str) -> BytesIO:
    """âœ… KURSOVAYA - full structure like referat"""
    doc = Document()
    
    for section in doc.sections:
        section.top_margin = Cm(2)
        section.bottom_margin = Cm(2)
        section.left_margin = Cm(3)
        section.right_margin = Cm(1.5)
    
    create_title_page(doc, order_data, lang)
    
    # ZADANIE page (REQUIRED for kursovaya)
    if order_data.get("zadanie_photo"):
        create_zadanie_page(doc, order_data)
    
    content = extend_content_to_required_pages(content, order_data)
    
    structure = parse_content_structure_kursovaya(content, order_data["pages"], order_data)
    
    create_toc_kursovaya(doc, structure, order_data)
    
    doc.add_page_break()
    
    # Ğ’Ğ’Ğ•Ğ”Ğ•ĞĞ˜Ğ•
    intro_header = doc.add_paragraph()
    intro_header.alignment = WD_ALIGN_PARAGRAPH.CENTER
    run = intro_header.add_run("Ğ’Ğ’Ğ•Ğ”Ğ•ĞĞ˜Ğ•")
    run.font.size = Pt(14)
    run.font.name = 'Times New Roman'
    run.bold = True
    intro_header.paragraph_format.space_before = Pt(0)
    intro_header.paragraph_format.space_after = Pt(18)
    
    intro_paragraphs = structure["introduction"].split('\n\n')
    for para_text in intro_paragraphs:
        if para_text.strip():
            p = doc.add_paragraph()
            p.alignment = WD_ALIGN_PARAGRAPH.JUSTIFY
            p.paragraph_format.first_line_indent = Cm(1.25)
            p.paragraph_format.line_spacing = Pt(18)
            p.paragraph_format.space_after = Pt(0)
            
            clean_text = re.sub(r'[#\*_]', '', para_text.strip())
            run = p.add_run(clean_text)
            run.font.size = Pt(14)
            run.font.name = 'Times New Roman'
    
    doc.add_page_break()
    
    # CHAPTERS
    for chapter in structure["chapters"]:
        ch_header = doc.add_paragraph()
        ch_header.alignment = WD_ALIGN_PARAGRAPH.CENTER
        run = ch_header.add_run(f"Ğ“Ğ›ĞĞ’Ğ {chapter['number']}. {chapter['title'].upper()}")
        
        # âœ… ÅU ÃERDE ÅRIFTI BERKIDÃÃ„RIS:
        run.font.size = Pt(14)  # 11 Pt-den 14 Pt-e Ã¼Ã½tgedildi
        run.font.name = 'Times New Roman'
        run.bold = True
        ch_header.paragraph_format.space_before = Pt(12)
        ch_header.paragraph_format.space_after = Pt(18)
        
        for subsection in chapter["subsections"]:
            sub_header = doc.add_paragraph()
            sub_header.alignment = WD_ALIGN_PARAGRAPH.LEFT
            sub_header.paragraph_format.left_indent = Cm(1.25)
            
            run = sub_header.add_run(f"{subsection['number']} {subsection['title']}")
            
            # âœ… KIÃ‡I BÃ–LÃœM ÅRIFTI HEM 14 PT:
            run.font.size = Pt(14) # 11 Pt-den 14 Pt-e Ã¼Ã½tgedildi
            run.font.name = 'Times New Roman'
            run.bold = True
            sub_header.paragraph_format.space_before = Pt(12)
            sub_header.paragraph_format.space_after = Pt(12)
            
            # Mazmuny (Media elementleri bilen) goÅŸmak
            insert_smart_content(doc, subsection["content"])
            
            sub_paragraphs = subsection["content"].split('\n\n')
            for para_text in sub_paragraphs:
                if para_text.strip():
                    p = doc.add_paragraph()
                    p.alignment = WD_ALIGN_PARAGRAPH.JUSTIFY
                    p.paragraph_format.first_line_indent = Cm(1.25)
                    p.paragraph_format.line_spacing = Pt(18)
                    p.paragraph_format.space_after = Pt(0)
                    
                    clean_text = re.sub(r'[#\*_]', '', para_text.strip())
                    run = p.add_run(clean_text)
                    run.font.size = Pt(14)
                    run.font.name = 'Times New Roman'
        
        doc.add_page_break()
    
    # Ğ—ĞĞšĞ›Ğ®Ğ§Ğ•ĞĞ˜Ğ•
    concl_header = doc.add_paragraph()
    concl_header.alignment = WD_ALIGN_PARAGRAPH.CENTER
    run = concl_header.add_run("Ğ—ĞĞšĞ›Ğ®Ğ§Ğ•ĞĞ˜Ğ•")
    run.font.size = Pt(14)
    run.font.name = 'Times New Roman'
    run.bold = True
    concl_header.paragraph_format.space_before = Pt(0)
    concl_header.paragraph_format.space_after = Pt(18)
    
    concl_paragraphs = structure["conclusion"].split('\n\n')
    for para_text in concl_paragraphs:
        if para_text.strip():
            p = doc.add_paragraph()
            p.alignment = WD_ALIGN_PARAGRAPH.JUSTIFY
            p.paragraph_format.first_line_indent = Cm(1.25)
            p.paragraph_format.line_spacing = Pt(18)
            p.paragraph_format.space_after = Pt(0)
            
            clean_text = re.sub(r'[#\*_]', '', para_text.strip())
            run = p.add_run(clean_text)
            run.font.size = Pt(14)
            run.font.name = 'Times New Roman'
    
    doc.add_page_break()
    
    # Ğ¡ĞŸĞ˜Ğ¡ĞĞš Ğ›Ğ˜Ğ¢Ğ•Ğ ĞĞ¢Ğ£Ğ Ğ«
    ref_header = doc.add_paragraph()
    ref_header.alignment = WD_ALIGN_PARAGRAPH.CENTER
    run = ref_header.add_run("Ğ¡ĞŸĞ˜Ğ¡ĞĞš Ğ˜Ğ¡ĞŸĞĞ›Ğ¬Ğ—ĞĞ’ĞĞĞĞ«Ğ¥ Ğ˜Ğ¡Ğ¢ĞĞ§ĞĞ˜ĞšĞĞ’")
    run.font.size = Pt(14)
    run.font.name = 'Times New Roman'
    run.bold = True
    ref_header.paragraph_format.space_before = Pt(0)
    ref_header.paragraph_format.space_after = Pt(18)
    
    for i, ref in enumerate(structure["references"], 1):
        p = doc.add_paragraph()
        p.alignment = WD_ALIGN_PARAGRAPH.JUSTIFY
        p.paragraph_format.left_indent = Cm(1.25)
        p.paragraph_format.first_line_indent = Cm(-1.25)
        p.paragraph_format.line_spacing = Pt(18)
        p.paragraph_format.space_after = Pt(0)
        
        run = p.add_run(f"{i}. {ref}")
        run.font.size = Pt(14)
        run.font.name = 'Times New Roman'
    
    add_page_numbers_referat(doc)
    
    buffer = BytesIO()
    doc.save(buffer)
    buffer.seek(0)
    return buffer


def create_toc_kursovaya(doc: Document, structure: dict, order_data: dict):
    """âœ… TOC for KURSOVAYA"""
    
    toc_header = doc.add_paragraph()
    toc_header.alignment = WD_ALIGN_PARAGRAPH.CENTER
    run = toc_header.add_run("Ğ¡ĞĞ”Ğ•Ğ Ğ–ĞĞĞ˜Ğ•")
    run.font.size = Pt(14)
    run.font.name = 'Times New Roman'
    run.bold = True
    toc_header.paragraph_format.space_after = Pt(18)
    toc_header.paragraph_format.space_before = Pt(0)
    
    doc.add_paragraph()
    
    current_page = 2
    
    if order_data.get("zadanie_photo"):
        current_page += 1  # Zadanie page
    
    toc_page = current_page
    current_page += 1
    
    intro_page = current_page
    intro_words = len(structure["introduction"].split())
    current_page += max(1, intro_words // 400)
    
    toc_entries = [("Ğ’Ğ’Ğ•Ğ”Ğ•ĞĞ˜Ğ•", intro_page, False)]
    
    for chapter in structure["chapters"]:
        chapter_page = current_page
        toc_entries.append((f"Ğ“Ğ›ĞĞ’Ğ {chapter['number']}. {chapter['title'].upper()}", chapter_page, False))
        
        for subsection in chapter["subsections"]:
            toc_entries.append((f"{subsection['number']} {subsection['title']}", chapter_page, True))
        
        chapter_words = sum(len(sub["content"].split()) for sub in chapter["subsections"])
        current_page += max(1, chapter_words // 400)
    
    conclusion_page = current_page
    concl_words = len(structure["conclusion"].split())
    current_page += max(1, concl_words // 400)
    
    ref_page = current_page
    
    toc_entries.append(("Ğ—ĞĞšĞ›Ğ®Ğ§Ğ•ĞĞ˜Ğ•", conclusion_page, False))
    toc_entries.append(("Ğ¡ĞŸĞ˜Ğ¡ĞĞš Ğ˜Ğ¡ĞŸĞĞ›Ğ¬Ğ—ĞĞ’ĞĞĞĞ«Ğ¥ Ğ˜Ğ¡Ğ¢ĞĞ§ĞĞ˜ĞšĞĞ’", ref_page, False))
    
    for title, page, is_subsection in toc_entries:
        p = doc.add_paragraph()
        p.paragraph_format.space_after = Pt(0)
        p.paragraph_format.line_spacing = Pt(18)
        
        if is_subsection:
            p.paragraph_format.left_indent = Cm(1.25)
        
        from docx.oxml import OxmlElement
        from docx.oxml.ns import qn
        
        tab_stops_element = p._element.get_or_add_pPr().get_or_add_tabs()
        tab_stop = OxmlElement('w:tab')
        tab_stop.set(qn('w:val'), 'right')
        tab_stop.set(qn('w:leader'), 'dot')
        tab_stop.set(qn('w:pos'), str(int(Cm(16.5).twips)))
        tab_stops_element.append(tab_stop)
        
        run_title = p.add_run(title)
        run_title.font.size = Pt(14)
        run_title.font.name = 'Times New Roman'
        
        if not is_subsection:
            run_title.font.bold = True
        
        p.add_run('\t')
        
        run_page = p.add_run(str(page))
        run_page.font.size = Pt(14)
        run_page.font.name = 'Times New Roman'
        
        if not is_subsection:
            run_page.font.bold = True

# ============== ADMIN FUNCTIONS ==============

async def admin_confirm_payment(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """âœ… Admin confirms payment - COMPLETE WORKING VERSION"""
    query = update.callback_query
    
    if query.from_user.id != ADMIN_ID:
        await query.answer("â›” Ğ”Ğ¾ÑÑ‚ÑƒĞ¿ Ğ·Ğ°Ğ¿Ñ€ĞµÑ‰ĞµĞ½!", show_alert=True)
        return
    
    order_id = query.data.split("_", 1)[1]
    
    if order_id not in pending_payments:
        await query.answer("âŒ Ğ—Ğ°ĞºĞ°Ğ· Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½!", show_alert=True)
        return
    
    await query.answer("âœ… ĞĞ°Ñ‡Ğ¸Ğ½Ğ°Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºÑƒ...")
    
    order = pending_payments[order_id]
    user_id = order["user_id"]
    lang = order["language"]
    work_type = order["work_type"]
    currency = get_currency_symbol(order["country"])
    
    order["status"] = "processing"
    
    processing_msg = f"""âœ… *ĞĞŸĞ›ĞĞ¢Ğ ĞŸĞĞ”Ğ¢Ğ’Ğ•Ğ Ğ–Ğ”Ğ•ĞĞ!*

ğŸ“‹ Ğ—Ğ°ĞºĞ°Ğ·: `{order_id}`
ğŸ’µ Ğ¡ÑƒĞ¼Ğ¼Ğ°: {order['final_price']} {currency}

ğŸš€ ĞĞ°Ñ‡Ğ¸Ğ½Ğ°Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹...
â±ï¸ Ğ­Ñ‚Ğ¾ Ğ·Ğ°Ğ¹Ğ¼Ñ‘Ñ‚ 2-5 Ğ¼Ğ¸Ğ½ÑƒÑ‚

ĞĞµ Ğ·Ğ°ĞºÑ€Ñ‹Ğ²Ğ°Ğ¹Ñ‚Ğµ Ñ‡Ğ°Ñ‚, Ñ„Ğ°Ğ¹Ğ» Ğ¿Ñ€Ğ¸Ğ´Ñ‘Ñ‚ ÑÑĞ´Ğ°!"""
    
    try:
        await context.bot.send_message(user_id, processing_msg, parse_mode='Markdown')
    except Exception as e:
        logger.error(f"Failed to notify user {user_id}: {e}")
    
    await query.edit_message_caption(f"â³ Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹: {order_id}...")
    
    try:
        logger.info(f"[{order_id}] Starting generation for {work_type}...")
        
        # âœ… GENERATE AI CONTENT
        content = generate_ai_content(order, work_type)
        
        if not content:
            raise Exception("AI generation returned empty content")
        
        content_length = len(content)
        word_count = len(content.split())
        logger.info(f"[{order_id}] Generated: {content_length} chars, {word_count} words")
        
        # âœ… EXTEND IF SHORT
        if work_type not in ["presentation", "table"]:
            content = extend_content_to_required_pages(content, order)
            logger.info(f"[{order_id}] After extension: {len(content)} chars, {len(content.split())} words")
        
        work_type_name = WORK_TYPES[work_type]["ru"]
        safe_topic = re.sub(r'[^\w\s-]', '', order["topic"])[:30]
        
        file_buffer = None
        filename = None
        file_format = None
        
        # âœ… GENERATE FILE BY TYPE
        logger.info(f"[{order_id}] Creating {work_type} file...")
        
        if work_type == "presentation":
            file_buffer = create_presentation(order, content)
            filename = f"{work_type_name}_{safe_topic}_{order_id}.pptx"
            file_format = "PPTX"
                      
        elif work_type == "referat":
            file_buffer = create_document_referat(order, content, lang)
            filename = f"{work_type_name}_{safe_topic}_{order_id}.docx"
            file_format = "DOCX"
            
        elif work_type == "esse":
            file_buffer = create_document_esse(order, content, lang)
            filename = f"{work_type_name}_{safe_topic}_{order_id}.docx"
            file_format = "DOCX"
            
        elif work_type == "doklad":
            file_buffer = create_document_doklad(order, content, lang)
            filename = f"{work_type_name}_{safe_topic}_{order_id}.docx"
            file_format = "DOCX"
            
        elif work_type == "kursovaya":
            file_buffer = create_document_kursovaya(order, content, lang)
            filename = f"{work_type_name}_{safe_topic}_{order_id}.docx"
            file_format = "DOCX"
            
        else:
            # Fallback to basic document
            file_buffer = create_document(order, content, lang)
            filename = f"{work_type_name}_{safe_topic}_{order_id}.docx"
            file_format = "DOCX"
        
        if not file_buffer:
            raise Exception("File buffer is empty")
        
        file_buffer.seek(0, 2)
        file_size = file_buffer.tell()
        file_buffer.seek(0)
        
        logger.info(f"[{order_id}] File created: {filename}, {file_size} bytes")
        
        if file_size < 5000:  # Less than 5KB is suspicious
            raise Exception(f"File too small: {file_size} bytes")
        
        # âœ… SEND FILE TO CUSTOMER
        caption = f"""ğŸ“š *Ğ’ĞĞ¨Ğ Ğ ĞĞ‘ĞĞ¢Ğ Ğ“ĞĞ¢ĞĞ’Ğ!*

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“‹ Ğ—Ğ°ĞºĞ°Ğ·: `{order_id}`
ğŸ“ Ğ¢ĞµĞ¼Ğ°: {order['topic'][:50]}
ğŸ“„ Ğ¡Ñ‚Ñ€Ğ°Ğ½Ğ¸Ñ†: {order['pages']}
ğŸ“ Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚: {file_format}
ğŸ’¾ Ğ Ğ°Ğ·Ğ¼ĞµÑ€: {file_size // 1024} KB

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
âœ… Ğ Ğ°Ğ±Ğ¾Ñ‚Ğ° Ğ¿Ğ¾Ğ»Ğ½Ğ¾ÑÑ‚ÑŒÑ Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ°!
ğŸ“ ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑŒÑ‚Ğµ ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ°Ğ½Ğ¸Ğµ
ğŸ ĞšĞ°Ğ¶Ğ´Ñ‹Ğ¹ 8-Ğ¹ Ğ·Ğ°ĞºĞ°Ğ· Ğ‘Ğ•Ğ¡ĞŸĞ›ĞĞ¢ĞĞ!

ĞĞ¾Ğ²Ñ‹Ğ¹ Ğ·Ğ°ĞºĞ°Ğ·: /start"""
        
        max_retries = 3
        send_success = False
        
        for attempt in range(max_retries):
            try:
                file_buffer.seek(0)  # Reset position
                
                await context.bot.send_document(
                    chat_id=user_id,
                    document=InputFile(file_buffer, filename=filename),
                    caption=caption,
                    parse_mode='Markdown',
                    read_timeout=180,
                    write_timeout=180,
                    connect_timeout=90
                )
                
                logger.info(f"[{order_id}] âœ… File sent to customer!")
                send_success = True
                break
                
            except Exception as send_error:
                logger.error(f"[{order_id}] Send attempt {attempt + 1} failed: {send_error}")
                if attempt < max_retries - 1:
                    await asyncio.sleep(3)
                else:
                    raise send_error
        
        if not send_success:
            raise Exception("Failed to send file after 3 attempts")
        
        # âœ… UPDATE USER STATS
        user_data = get_user(user_id)
        user_data["orders_count"] += 1
        user_data["total_spent"] += order["final_price"]
        
        if order.get("promo_code"):
            promo_upper = order["promo_code"].upper()
            if promo_upper not in user_data["used_promos"]:
                user_data["used_promos"].append(promo_upper)
        
        # âœ… SAVE ORDER
        order["status"] = "completed"
        order["completed_at"] = datetime.now().isoformat()
        order["file_format"] = file_format
        order["file_size"] = file_size
        orders_db[order_id] = order
        del pending_payments[order_id]
        
        # âœ… UPDATE ADMIN MESSAGE
        await query.edit_message_caption(
            f"""âœ… *Ğ—ĞĞšĞĞ— Ğ’Ğ«ĞŸĞĞ›ĞĞ•Ğ*

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“‹ ID: `{order_id}`
ğŸ“ Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚: {file_format}
ğŸ’¾ Ğ Ğ°Ğ·Ğ¼ĞµÑ€: {file_size // 1024} KB
â° Ğ’Ñ€ĞµĞ¼Ñ: {datetime.now().strftime('%H:%M:%S')}

âœ… Ğ¤Ğ°Ğ¹Ğ» Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½ ĞºĞ»Ğ¸ĞµĞ½Ñ‚Ñƒ!""",
            parse_mode='Markdown'
        )
        
        logger.info(f"[{order_id}] âœ…âœ…âœ… ORDER COMPLETED SUCCESSFULLY âœ…âœ…âœ…")
        
    except Exception as e:
        logger.error(f"[{order_id}] âŒ CRITICAL ERROR: {str(e)}", exc_info=True)
        
        # âœ… NOTIFY CUSTOMER ABOUT ERROR
        error_msg = f"""âŒ *Ğ¢Ğ•Ğ¥ĞĞ˜Ğ§Ğ•Ğ¡ĞšĞĞ¯ ĞĞ¨Ğ˜Ğ‘ĞšĞ*

ğŸ“‹ Ğ—Ğ°ĞºĞ°Ğ·: `{order_id}`

ğŸ”§ Ğ’Ğ°ÑˆĞ° Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ° Ğ±ÑƒĞ´ĞµÑ‚ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ° Ğ²Ñ€ÑƒÑ‡Ğ½ÑƒÑ Ğ°Ğ´Ğ¼Ğ¸Ğ½Ğ¸ÑÑ‚Ñ€Ğ°Ñ‚Ğ¾Ñ€Ğ¾Ğ¼
â±ï¸ Ğ”Ğ¾ÑÑ‚Ğ°Ğ²ĞºĞ° Ğ² Ñ‚ĞµÑ‡ĞµĞ½Ğ¸Ğµ 1-3 Ñ‡Ğ°ÑĞ¾Ğ²
ğŸ’° ĞĞ¿Ğ»Ğ°Ñ‚Ğ° ÑƒÑ‡Ñ‚ĞµĞ½Ğ° Ğ¸ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ°

ĞŸÑ€Ğ¸Ğ½Ğ¾ÑĞ¸Ğ¼ Ğ¸Ğ·Ğ²Ğ¸Ğ½ĞµĞ½Ğ¸Ñ Ğ·Ğ° Ğ·Ğ°Ğ´ĞµÑ€Ğ¶ĞºÑƒ!"""
        
        try:
            await context.bot.send_message(user_id, error_msg, parse_mode='Markdown')
        except:
            pass
        
        # âœ… NOTIFY ADMIN
        admin_error = f"""âŒ *ĞĞ¨Ğ˜Ğ‘ĞšĞ ĞĞ‘Ğ ĞĞ‘ĞĞ¢ĞšĞ˜*

ğŸ“‹ Order: `{order_id}`
ğŸ‘¤ User: {order['full_name']} (@{order.get('username', 'N/A')})
ğŸ“ Type: {work_type}
ğŸ’µ Price: {order['final_price']} {currency}

âŒ Error: {str(e)[:500]}

âš ï¸ Ğ¢Ñ€ĞµĞ±ÑƒĞµÑ‚ÑÑ Ñ€ÑƒÑ‡Ğ½Ğ°Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°!"""
        
        try:
            await context.bot.send_message(ADMIN_ID, admin_error, parse_mode='Markdown')
        except:
            pass
        
        # âœ… UPDATE ADMIN MESSAGE
        try:
            await query.edit_message_caption(
                f"âŒ *ĞĞ¨Ğ˜Ğ‘ĞšĞ*\n\nĞ—Ğ°ĞºĞ°Ğ·: `{order_id}`\n\nâš ï¸ Ğ¢Ñ€ĞµĞ±ÑƒĞµÑ‚ÑÑ Ñ€ÑƒÑ‡Ğ½Ğ°Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°!",
                parse_mode='Markdown'
            )
        except:
            pass


# ============== AI GENERATION - GROQ ONLY ==============

def generate_ai_content(order_data: dict, work_type: str) -> Optional[str]:
    """âœ… TÃ¤zelenen we durnukly AI generatory. 
    LimitleriÅˆ dolmazlygy we referatlaryÅˆ Ã½itmezligi Ã¼Ã§in optimizirlenen."""
    
    try:
        url = "https://api.groq.com/openai/v1/chat/completions"
        
        pages = order_data['pages']
        topic = order_data['topic']
        subject = order_data['subject']
        university = order_data.get('university', '')
        
        # âš ï¸ MÃ–HÃœM: AI-dan bir gezekde 1500-den kÃ¶p sÃ¶z soramaÅˆ, Ã½ogsam Ã½azyp bilmez.
        # Galan sahypalary "extend_content_to_required_pages" funksiÃ½asy doldurar.
        target_words = 1500 

        # --- IÅ GÃ–RNÃœÅINE GÃ–RÃ„ PROMTLAR ---
        
        if work_type in ["referat", "kursovaya"]:
            prompt = f"""ĞĞ°Ğ¿Ğ¸ÑˆĞ¸ Ğ°ĞºĞ°Ğ´ĞµĞ¼Ğ¸Ñ‡ĞµÑĞºÑƒÑ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñƒ Ğ½Ğ° Ñ‚ĞµĞ¼Ñƒ: "{order_data['topic']}"
ĞŸÑ€ĞµĞ´Ğ¼ĞµÑ‚: {order_data['subject']}

Ğ¡Ğ¢Ğ Ğ£ĞšĞ¢Ğ£Ğ Ğ: Ğ’Ğ²ĞµĞ´ĞµĞ½Ğ¸Ğµ, Ğ“Ğ»Ğ°Ğ²Ğ° 1, Ğ“Ğ»Ğ°Ğ²Ğ° 2, Ğ—Ğ°ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ.

ĞĞ‘Ğ¯Ğ—ĞĞ¢Ğ•Ğ›Ğ¬ĞĞ Ğ”ĞĞ‘ĞĞ’Ğ¬ Ğ’ Ğ¢Ğ•ĞšĞ¡Ğ¢:
1. ĞœĞ¸Ğ½Ğ¸Ğ¼ÑƒĞ¼ 2 Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñ‹ Ğ² Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğµ Markdown (Ğ½Ğ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€: | Ğ—Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²Ğ¾Ğº | Ğ—Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ |).
2. Ğ£ĞºĞ°Ğ¶Ğ¸ Ğ¼ĞµÑÑ‚Ğ° Ğ´Ğ»Ñ 2-3 Ğ¸Ğ»Ğ»ÑÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ğ¹ Ñ‚ĞµĞ³Ğ¾Ğ¼: [IMAGE: Ğ¿Ğ¾Ğ´Ñ€Ğ¾Ğ±Ğ½Ğ¾Ğµ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ ĞºĞ°Ñ€Ñ‚Ğ¸Ğ½ĞºĞ¸ Ğ½Ğ° Ğ°Ğ½Ğ³Ğ»Ğ¸Ğ¹ÑĞºĞ¾Ğ¼].
3. Ğ£ĞºĞ°Ğ¶Ğ¸ Ğ¼ĞµÑÑ‚Ğ¾ Ğ´Ğ»Ñ 1 Ğ»Ğ¾Ğ³Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¹ ÑÑ…ĞµĞ¼Ñ‹ Ñ‚ĞµĞ³Ğ¾Ğ¼: [SCHEMA: Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ ÑÑ…ĞµĞ¼Ñ‹ Ğ½Ğ° Ñ€ÑƒÑÑĞºĞ¾Ğ¼].

Ğ¢Ğ Ğ•Ğ‘ĞĞ’ĞĞĞ˜Ğ¯:
- Ğ¡Ñ‚Ğ¸Ğ»ÑŒ: ĞĞ°ÑƒÑ‡Ğ½Ñ‹Ğ¹.
- Ğ¢ĞµĞºÑÑ‚: Ğ¢Ğ¾Ğ»ÑŒĞºĞ¾ Ñ€ÑƒÑÑĞºĞ¸Ğ¹.
- Ğ‘ĞµĞ· ÑĞ¿Ğ¸ÑĞºĞ¾Ğ², Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ğµ Ğ¸ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğµ Ğ°Ğ±Ğ·Ğ°Ñ†Ñ‹."""

        elif work_type == "presentation":
            prompt = f"""ĞĞ°Ğ¿Ğ¸ÑˆĞ¸ ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚ Ğ´Ğ»Ñ Ğ¿Ñ€ĞµĞ·ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ğ¸ Ğ½Ğ° Ñ‚ĞµĞ¼Ñƒ: "{topic}"
ĞšĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ ÑĞ»Ğ°Ğ¹Ğ´Ğ¾Ğ²: {pages}
Ğ”Ğ»Ñ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾ ÑĞ»Ğ°Ğ¹Ğ´Ğ° Ğ½Ğ°Ğ¿Ğ¸ÑˆĞ¸ 4-5 Ğ¿Ğ¾Ğ´Ñ€Ğ¾Ğ±Ğ½Ñ‹Ñ… Ğ¿ÑƒĞ½ĞºÑ‚Ğ¾Ğ² Ğ¸ IMAGE_KEYWORD: [ĞºĞ»ÑÑ‡ĞµĞ²Ğ¾Ğµ ÑĞ»Ğ¾Ğ²Ğ¾ Ğ½Ğ° Ğ°Ğ½Ğ³Ğ»Ğ¸Ğ¹ÑĞºĞ¾Ğ¼]."""

        elif work_type == "esse":
            prompt = f"""ĞĞ°Ğ¿Ğ¸ÑˆĞ¸ Ğ¿Ğ¾Ğ´Ñ€Ğ¾Ğ±Ğ½Ğ¾Ğµ ÑÑÑĞµ Ğ½Ğ° Ñ‚ĞµĞ¼Ñƒ: "{topic}". ĞœĞ¸Ğ½Ğ¸Ğ¼ÑƒĞ¼ 800 ÑĞ»Ğ¾Ğ². ĞĞºĞ°Ğ´ĞµĞ¼Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ ÑÑ‚Ğ¸Ğ»ÑŒ."""

        elif work_type == "doklad":
            prompt = f"""ĞĞ°Ğ¿Ğ¸ÑˆĞ¸ Ğ´Ğ¾ĞºĞ»Ğ°Ğ´ Ğ½Ğ° Ñ‚ĞµĞ¼Ñƒ: "{topic}". ĞœĞ¸Ğ½Ğ¸Ğ¼ÑƒĞ¼ 1000 ÑĞ»Ğ¾Ğ². Ğ¢Ğ¾Ğ»ÑŒĞºĞ¾ ÑÑƒÑ‚ÑŒ Ğ±ĞµĞ· Ğ²ÑÑ‚ÑƒĞ¿Ğ»ĞµĞ½Ğ¸Ğ¹."""

        elif work_type == "kursovaya":
            prompt = f"""ĞĞ°Ğ¿Ğ¸ÑˆĞ¸ ĞºÑƒÑ€ÑĞ¾Ğ²ÑƒÑ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñƒ Ğ½Ğ° Ñ‚ĞµĞ¼Ñƒ: "{topic}". ĞŸÑ€ĞµĞ´Ğ¼ĞµÑ‚: {subject}. 
            ĞœĞ°ĞºÑĞ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾ Ğ¿Ğ¾Ğ´Ñ€Ğ¾Ğ±Ğ½Ğ¾ Ñ€Ğ°Ğ·Ğ¿Ğ¸ÑˆĞ¸ Ñ‚ĞµĞ¾Ñ€Ğ¸Ñ Ğ¸ Ğ¿Ñ€Ğ°ĞºÑ‚Ğ¸ĞºÑƒ. ĞœĞ¸Ğ½Ğ¸Ğ¼ÑƒĞ¼ 2000 ÑĞ»Ğ¾Ğ²."""

        else:
            prompt = f"""ĞĞ°Ğ¿Ğ¸ÑˆĞ¸ Ğ¿Ğ¾Ğ´Ñ€Ğ¾Ğ±Ğ½ÑƒÑ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñƒ Ğ½Ğ° Ñ‚ĞµĞ¼Ñƒ: "{topic}". ĞœĞ¸Ğ½Ğ¸Ğ¼ÑƒĞ¼ 1000 ÑĞ»Ğ¾Ğ²."""
        
        # --- API Ã‡AGYRYÅY (HAS DURNUKLY MODEL BILEN) ---
        
        headers = {
            "Authorization": f"Bearer {GROQ_API_KEY}",
            "Content-Type": "application/json"
        }
        
        payload = {
            # "llama-3.1-8b-instant" has Ã§alt we limitleri has uly
            "model": "llama-3.1-8b-instant", 
            "messages": [{"role": "user", "content": prompt}],
            "temperature": 0.7,
            "max_tokens": 8000, # AI-yÅˆ jogap berip biljek max Ã½eri
            "top_p": 0.9
        }
        
        logger.info(f"ğŸ¤– AI generirleÃ½Ã¤r: {work_type.upper()} (Model: llama-3.1-8b)")
        
        response = requests.post(url, json=payload, headers=headers, timeout=300)
        
        if response.status_code == 200:
            data = response.json()
            content = data["choices"][0]["message"]["content"]
            
            if not content or len(content.split()) < 50:
                logger.error("âŒ AI gaty gysga jogap berdi!")
                return None
                
            logger.info(f"âœ… AI Jogap berdi: {len(content.split())} sÃ¶z.")
            return content
        else:
            logger.error(f"âŒ GROQ Error {response.status_code}: {response.text}")
            return None
            
    except Exception as e:
        logger.error(f"âŒ generate_ai_content iÃ§inde Ã½alÅˆyÅŸlyk: {str(e)}")
        return None
    
    # âœ… EXCEPT BLOKY (MANDATORY!)
    except Exception as e:
        logger.error(f"âŒ Generation exception for {work_type}: {str(e)}")
        return None

async def admin_reject_payment(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    
    if query.from_user.id != ADMIN_ID:
        await query.answer("â›” Ğ”Ğ¾ÑÑ‚ÑƒĞ¿ Ğ·Ğ°Ğ¿Ñ€ĞµÑ‰ĞµĞ½!", show_alert=True)
        return
    
    order_id = query.data.split("_", 1)[1]
    
    if order_id not in pending_payments:
        await query.answer("âŒ Ğ—Ğ°ĞºĞ°Ğ· Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½!", show_alert=True)
        return
    
    order = pending_payments.pop(order_id)
    lang = order["language"]
    
    msg = f"âŒ *ĞĞŸĞ›ĞĞ¢Ğ ĞĞ• ĞŸĞĞ”Ğ¢Ğ’Ğ•Ğ Ğ–Ğ”Ğ•ĞĞ*\n\nğŸ“‹ ID: `{order_id}`\n\nĞŸĞ¾Ğ¿Ñ€Ğ¾Ğ±ÑƒĞ¹Ñ‚Ğµ ÑĞ½Ğ¾Ğ²Ğ°: /start"
    await context.bot.send_message(order["user_id"], msg, parse_mode='Markdown')
    
    await query.edit_message_caption(f"âŒ *ĞĞ¢ĞšĞ›ĞĞĞ•ĞĞ*\n\nĞ—Ğ°ĞºĞ°Ğ·: {order_id}", parse_mode='Markdown')
    await query.answer("âŒ Ğ—Ğ°ĞºĞ°Ğ· Ğ¾Ñ‚ĞºĞ»Ğ¾Ğ½ĞµĞ½")

async def show_promotions(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    await query.answer()
    
    user_id = query.from_user.id
    lang = get_user(user_id).get("language", "ru")
    
    text = """ğŸ *ĞĞšĞ¦Ğ˜Ğ˜*

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ *8-Ğ¹ Ğ·Ğ°ĞºĞ°Ğ· Ğ‘Ğ•Ğ¡ĞŸĞ›ĞĞ¢ĞĞ!*
â˜€ï¸ *Ğ£Ñ‚Ñ€Ğ¾ (06:00-07:00): -10%*
ğŸ‘¥ *ĞŸÑ€Ğ¸Ğ²ĞµĞ´Ğ¸ Ğ´Ñ€ÑƒĞ³Ğ°: -30% ĞĞ‘ĞĞ˜Ğœ!*
ğŸ‰ *Ğ’Ñ‹Ñ…Ğ¾Ğ´Ğ½Ñ‹Ğµ: -10%*
ğŸ·ï¸ *ĞŸÑ€Ğ¾Ğ¼Ğ¾ĞºĞ¾Ğ´Ñ‹: Ğ´Ğ¾ -30%*

ğŸ’¡ Ğ¡ĞºĞ¸Ğ´ĞºĞ¸ ÑÑƒĞ¼Ğ¼Ğ¸Ñ€ÑƒÑÑ‚ÑÑ!
*ĞœĞ°ĞºÑĞ¸Ğ¼ÑƒĞ¼ 50%*
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"""
    
    keyboard = [
        [InlineKeyboardButton(TEXTS[lang]["new_order"], callback_data="new_order")],
        [InlineKeyboardButton(TEXTS[lang]["back"], callback_data="main_menu")]
    ]
    
    await query.edit_message_text(text, reply_markup=InlineKeyboardMarkup(keyboard), parse_mode='Markdown')

async def show_account(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    await query.answer()
    
    user_id = query.from_user.id
    user = get_user(user_id)
    lang = user.get("language", "ru")
    
    orders_to_free = 8 - (user["orders_count"] % 8)
    if orders_to_free == 8 and user["orders_count"] > 0:
        orders_to_free = 0
    
    progress = "ğŸŸ¢" * (user["orders_count"] % 8) + "âšª" * orders_to_free
    
    text = f"""ğŸ“Š *ĞœĞĞ™ ĞĞšĞšĞĞ£ĞĞ¢*

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ‘¤ ID: `{user_id}`

ğŸ“ˆ *Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ°:*
â€¢ Ğ—Ğ°ĞºĞ°Ğ·Ğ¾Ğ²: {user['orders_count']}
â€¢ ĞŸĞ¾Ñ‚Ñ€Ğ°Ñ‡ĞµĞ½Ğ¾: {user['total_spent']}
â€¢ Ğ ĞµÑ„ĞµÑ€Ğ°Ğ»Ğ¾Ğ²: {len(user['referrals'])}

ğŸ *Ğ”Ğ¾ Ğ±ĞµÑĞ¿Ğ»Ğ°Ñ‚Ğ½Ğ¾Ğ³Ğ¾:*
{progress}
â€¢ {user['orders_count'] % 8}/7
â€¢ ĞÑÑ‚Ğ°Ğ»Ğ¾ÑÑŒ: {orders_to_free if orders_to_free > 0 else 'ğŸ‰ Ğ¡Ğ›Ğ•Ğ”Ğ£Ğ®Ğ©Ğ˜Ğ™ Ğ‘Ğ•Ğ¡ĞŸĞ›ĞĞ¢ĞĞ!'}
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"""
    
    keyboard = [
        [InlineKeyboardButton(TEXTS[lang]["new_order"], callback_data="new_order")],
        [InlineKeyboardButton(TEXTS[lang]["back"], callback_data="main_menu")]
    ]
    
    await query.edit_message_text(text, reply_markup=InlineKeyboardMarkup(keyboard), parse_mode='Markdown')

async def show_referral(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    await query.answer()
    
    user_id = query.from_user.id
    user = get_user(user_id)
    lang = user.get("language", "ru")
    
    bot_info = await context.bot.get_me()
    ref_link = f"https://t.me/{bot_info.username}?start={user_id}"
    
    text = f"""ğŸ‘¥ *Ğ Ğ•Ğ¤Ğ•Ğ ĞĞ›Ğ¬ĞĞĞ¯ ĞŸĞ ĞĞ“Ğ ĞĞœĞœĞ*

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ *ĞšĞ°Ğº Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚:*
1ï¸âƒ£ ĞŸĞ¾Ğ´ĞµĞ»Ğ¸Ñ‚ĞµÑÑŒ ÑÑÑ‹Ğ»ĞºĞ¾Ğ¹
2ï¸âƒ£ Ğ”Ñ€ÑƒĞ³ Ñ€ĞµĞ³Ğ¸ÑÑ‚Ñ€Ğ¸Ñ€ÑƒĞµÑ‚ÑÑ
3ï¸âƒ£ *ĞĞ±Ğ° Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ°ĞµÑ‚Ğµ -30%!* ğŸ‰

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ”— *Ğ’Ğ°ÑˆĞ° ÑÑÑ‹Ğ»ĞºĞ°:*
`{ref_link}`

ğŸ“Š *Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ°:*
â€¢ Ğ ĞµÑ„ĞµÑ€Ğ°Ğ»Ğ¾Ğ²: {len(user['referrals'])}
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"""
    
    keyboard = [[InlineKeyboardButton(TEXTS[lang]["back"], callback_data="main_menu")]]
    
    await query.edit_message_text(text, reply_markup=InlineKeyboardMarkup(keyboard), parse_mode='Markdown')

async def enter_promo(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    await query.answer()
    
    user_id = query.from_user.id
    lang = get_user(user_id).get("language", "ru")
    
    text = """ğŸ·ï¸ *ĞŸĞ ĞĞœĞĞšĞĞ”*

Ğ’Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ ĞºĞ¾Ğ´:

*Ğ”Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹Ğµ:*
â€¢ WELCOME â€” 20%
â€¢ STUDENT â€” 15%
â€¢ FIRST â€” 25%
â€¢ VIP2025 â€” 30%"""
    
    keyboard = [[InlineKeyboardButton(TEXTS[lang]["cancel"], callback_data="main_menu")]]
    
    await query.edit_message_text(text, reply_markup=InlineKeyboardMarkup(keyboard), parse_mode='Markdown')
    context.user_data["waiting_promo"] = True

async def handle_promo_input(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not context.user_data.get("waiting_promo"): return
    code = update.message.text.strip().upper()
    user_id = update.effective_user.id
    user = get_user(user_id)
    context.user_data["waiting_promo"] = False
    
    today = datetime.now().strftime("%m-%d") # HÃ¤zirki sene
    
    if code in HOLIDAY_PROMOS:
        promo = HOLIDAY_PROMOS[code]
        if promo["date"] == today: # âœ… DiÅˆe baÃ½ram gÃ¼nÃ¼nde
            if code in user["used_promos"]:
                await update.message.reply_text(f"âŒ ĞšĞ¾Ğ´ {code} ÑƒĞ¶Ğµ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½!")
            else:
                context.user_data["promo_code"] = code
                await update.message.reply_text(f"ğŸ‰ Ğ¡ĞºĞ¸Ğ´ĞºĞ° {promo['discount']}% Ğ¿Ñ€Ğ¸Ğ½ÑÑ‚Ğ° Ğ² Ñ‡ĞµÑÑ‚ÑŒ Ğ¿Ñ€Ğ°Ğ·Ğ´Ğ½Ğ¸ĞºĞ°: {promo['name']}!")
        else:
            d = promo["date"].split("-")
            await update.message.reply_text(f"âš ï¸ ĞšĞ¾Ğ´ {code} Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ {d[1]}.{d[0]} ({promo['name']})!")
    else:
        await update.message.reply_text("âŒ ĞĞµĞ²ĞµÑ€Ğ½Ñ‹Ğ¹ Ğ¸Ğ»Ğ¸ Ğ½ĞµĞ°ĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹ ĞºĞ¾Ğ´.")


async def show_help(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    await query.answer()
    
    user_id = query.from_user.id
    lang = get_user(user_id).get("language", "ru")
    
    text = """â“ *ĞŸĞĞœĞĞ©Ğ¬*

1ï¸âƒ£ ĞĞ°Ğ¶Ğ¼Ğ¸Ñ‚Ğµ "ĞĞ¾Ğ²Ñ‹Ğ¹ Ğ·Ğ°ĞºĞ°Ğ·"
2ï¸âƒ£ Ğ’Ñ‹Ğ±ĞµÑ€Ğ¸Ñ‚Ğµ ÑÑ‚Ñ€Ğ°Ğ½Ñƒ
3ï¸âƒ£ Ğ’Ñ‹Ğ±ĞµÑ€Ğ¸Ñ‚Ğµ Ñ‚Ğ¸Ğ¿ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹
4ï¸âƒ£ Ğ—Ğ°Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ
5ï¸âƒ£ ĞĞ¿Ğ»Ğ°Ñ‚Ğ¸Ñ‚Ğµ
6ï¸âƒ£ ĞÑ‚Ğ¿Ñ€Ğ°Ğ²ÑŒÑ‚Ğµ ÑĞºÑ€Ğ¸Ğ½ÑˆĞ¾Ñ‚
7ï¸âƒ£ ĞŸĞ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚Ğµ Ñ„Ğ°Ğ¹Ğ»! ğŸ‰

*ĞšĞ¾Ğ¼Ğ°Ğ½Ğ´Ñ‹:*
/start â€” Ğ“Ğ»Ğ°Ğ²Ğ½Ğ¾Ğµ Ğ¼ĞµĞ½Ñ
/help â€” ĞŸĞ¾Ğ¼Ğ¾Ñ‰ÑŒ
/cancel â€” ĞÑ‚Ğ¼ĞµĞ½Ğ°"""
    
    keyboard = [[InlineKeyboardButton(TEXTS[lang]["back"], callback_data="main_menu")]]
    
    await query.edit_message_text(text, reply_markup=InlineKeyboardMarkup(keyboard), parse_mode='Markdown')

async def admin_panel(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    
    if query.from_user.id != ADMIN_ID:
        await query.answer("â›” Ğ”Ğ¾ÑÑ‚ÑƒĞ¿ Ğ·Ğ°Ğ¿Ñ€ĞµÑ‰ĞµĞ½!", show_alert=True)
        return
    
    await query.answer()
    
    total_users = len(users_db)
    total_pending = len(pending_payments)
    total_completed = len(orders_db)
    total_revenue_by = sum(o.get("final_price", 0) for o in orders_db.values() if o.get("country") == "BY")
    total_revenue_ru = sum(o.get("final_price", 0) for o in orders_db.values() if o.get("country") == "RU")
    
    text = f"""ğŸ” *ADMIN PANEL*

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“Š *Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ°:*
â€¢ ĞŸĞ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¹: {total_users}
â€¢ ĞĞ¶Ğ¸Ğ´Ğ°ÑÑ‚: {total_pending}
â€¢ Ğ’Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¾: {total_completed}

ğŸ’° *Ğ”Ğ¾Ñ…Ğ¾Ğ´:*
â€¢ ğŸ‡§ğŸ‡¾ BY: {total_revenue_by} BYN
â€¢ ğŸ‡·ğŸ‡º RU: {total_revenue_ru} â‚½
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"""
    
    keyboard = [
        [InlineKeyboardButton(f"â³ ĞĞ¶Ğ¸Ğ´Ğ°ÑÑ‰Ğ¸Ğµ ({total_pending})", callback_data="admin_pending")],
        [InlineKeyboardButton("ğŸ”™ ĞĞ°Ğ·Ğ°Ğ´", callback_data="main_menu")]
    ]
    
    await query.edit_message_text(text, reply_markup=InlineKeyboardMarkup(keyboard), parse_mode='Markdown')

async def admin_pending(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    
    if query.from_user.id != ADMIN_ID:
        await query.answer("â›” Ğ”Ğ¾ÑÑ‚ÑƒĞ¿ Ğ·Ğ°Ğ¿Ñ€ĞµÑ‰ĞµĞ½!", show_alert=True)
        return
    
    await query.answer()
    
    if not pending_payments:
        text = "âœ… ĞĞµÑ‚ Ğ¾Ğ¶Ğ¸Ğ´Ğ°ÑÑ‰Ğ¸Ñ… Ğ·Ğ°ĞºĞ°Ğ·Ğ¾Ğ²!"
    else:
        text = "â³ *ĞĞ–Ğ˜Ğ”ĞĞ®Ğ©Ğ˜Ğ•:*\n\n"
        for order_id, order in pending_payments.items():
            currency = get_currency_symbol(order["country"])
            flag = "ğŸ‡§ğŸ‡¾" if order["country"] == "BY" else "ğŸ‡·ğŸ‡º"
            text += f"ğŸ“‹ `{order_id}` {flag}\nâ€¢ {order['full_name']}\nâ€¢ {order['topic'][:30]}...\nâ€¢ {order['final_price']} {currency}\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
    
    keyboard = [[InlineKeyboardButton("ğŸ”™ ĞĞ°Ğ·Ğ°Ğ´", callback_data="admin")]]
    
    await query.edit_message_text(text, reply_markup=InlineKeyboardMarkup(keyboard), parse_mode='Markdown')

async def change_language(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    await query.answer()
    
    text = "ğŸŒ *Ğ’Ñ‹Ğ±ĞµÑ€Ğ¸Ñ‚Ğµ ÑĞ·Ñ‹Ğº / Select language:*"
    keyboard = [[InlineKeyboardButton("ğŸ‡·ğŸ‡º Ğ ÑƒÑÑĞºĞ¸Ğ¹", callback_data="lang_ru"), InlineKeyboardButton("ğŸ‡¬ğŸ‡§ English", callback_data="lang_en")]]
    
    await query.edit_message_text(text, reply_markup=InlineKeyboardMarkup(keyboard), parse_mode='Markdown')

async def cancel_order(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    await query.answer()
    
    user_id = query.from_user.id
    lang = get_user(user_id).get("language", "ru")
    
    context.user_data.clear()
    
    msg = "âŒ *Ğ—Ğ°ĞºĞ°Ğ· Ğ¾Ñ‚Ğ¼ĞµĞ½ĞµĞ½*\n\n/start"
    await query.edit_message_text(msg, parse_mode='Markdown')
    return ConversationHandler.END

async def main_menu_callback(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    await query.answer()
    await show_main_menu(update, context)

async def cancel_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    context.user_data.clear()
    user_id = update.effective_user.id
    lang = get_user(user_id).get("language", "ru")
    msg = "âŒ ĞÑ‚Ğ¼ĞµĞ½ĞµĞ½Ğ¾. /start"
    await update.message.reply_text(msg)
    return ConversationHandler.END

async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    lang = get_user(user_id).get("language", "ru")
    text = "/start Ğ´Ğ»Ñ Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ°"
    await update.message.reply_text(text)

async def handle_text_messages(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if context.user_data.get("waiting_promo"):
        await handle_promo_input(update, context)
        return
    
    user_id = update.effective_user.id
    lang = get_user(user_id).get("language", "ru")
    await update.message.reply_text("Ğ”Ğ»Ñ Ğ·Ğ°ĞºĞ°Ğ·Ğ°: /start\nĞŸĞ¾Ğ¼Ğ¾Ñ‰ÑŒ: /help")

# ============== MAIN ==============

def main():
    app = Application.builder().token(BOT_TOKEN).build()
    
    order_conv = ConversationHandler(
    entry_points=[CallbackQueryHandler(new_order, pattern="^new_order$")],
    states={
        SELECT_COUNTRY: [CallbackQueryHandler(select_country, pattern="^country_")],
        SELECT_WORK_TYPE: [CallbackQueryHandler(select_work_type, pattern="^work_")],
        SELECT_PAGES: [CallbackQueryHandler(select_pages, pattern="^pages_")],
        
        # âŒ UPLOAD_TABLE_TASK AÃRYLDY!
        
        ENTER_TOPIC: [MessageHandler(filters.TEXT & ~filters.COMMAND, receive_topic)],
        ENTER_UNIVERSITY: [MessageHandler(filters.TEXT & ~filters.COMMAND, receive_university)],
        ENTER_FACULTY: [MessageHandler(filters.TEXT & ~filters.COMMAND, receive_faculty)],
        ENTER_SUBJECT: [MessageHandler(filters.TEXT & ~filters.COMMAND, receive_subject)],
        ENTER_FULLNAME: [MessageHandler(filters.TEXT & ~filters.COMMAND, receive_fullname)],
        ENTER_COURSE: [MessageHandler(filters.TEXT & ~filters.COMMAND, receive_course)],
        ENTER_GROUP: [MessageHandler(filters.TEXT & ~filters.COMMAND, receive_group)],
        ENTER_TEACHER: [MessageHandler(filters.TEXT & ~filters.COMMAND, receive_teacher)],
        ENTER_CITY: [MessageHandler(filters.TEXT & ~filters.COMMAND, receive_city)],
        ENTER_PHONE: [MessageHandler(filters.TEXT & ~filters.COMMAND, receive_phone)],
        
        UPLOAD_ZADANIE: [
            MessageHandler(filters.PHOTO, receive_zadanie),
            CallbackQueryHandler(skip_zadanie, pattern="^skip_zadanie$")
        ],
        
        PAYMENT_PHOTO: [
            MessageHandler(filters.PHOTO, receive_payment_photo),
            CallbackQueryHandler(cancel_order, pattern="^cancel_order$")
        ]
    },
    fallbacks=[
        CommandHandler("cancel", cancel_command),
        CallbackQueryHandler(cancel_order, pattern="^cancel_order$"),
        CallbackQueryHandler(main_menu_callback, pattern="^main_menu$")
    ],
    per_message=False
)
    
    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("help", help_command))
    app.add_handler(CommandHandler("cancel", cancel_command))
    app.add_handler(CallbackQueryHandler(select_language, pattern="^lang_"))
    app.add_handler(CallbackQueryHandler(change_language, pattern="^change_lang$"))
    app.add_handler(order_conv)
    app.add_handler(CallbackQueryHandler(main_menu_callback, pattern="^main_menu$"))
    app.add_handler(CallbackQueryHandler(show_promotions, pattern="^promotions$"))
    app.add_handler(CallbackQueryHandler(show_account, pattern="^account$"))
    app.add_handler(CallbackQueryHandler(show_referral, pattern="^referral$"))
    app.add_handler(CallbackQueryHandler(enter_promo, pattern="^enter_promo$"))
    app.add_handler(CallbackQueryHandler(show_help, pattern="^help$"))
    app.add_handler(CallbackQueryHandler(admin_panel, pattern="^admin$"))
    app.add_handler(CallbackQueryHandler(admin_pending, pattern="^admin_pending$"))
    app.add_handler(CallbackQueryHandler(admin_confirm_payment, pattern="^confirm_"))
    app.add_handler(CallbackQueryHandler(admin_reject_payment, pattern="^reject_"))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_text_messages))
    
    print("ğŸš€ Bot iÅŸleÃ½Ã¤r...")
    app.run_polling(allowed_updates=Update.ALL_TYPES)

if __name__ == "__main__":
    main()
